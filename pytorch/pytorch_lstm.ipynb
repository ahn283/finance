{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB Movie Review Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습 목표\n",
    "\n",
    "- 자연어 처리를 위한 주요 신경망의 사용법을 이해한다.\n",
    "- 영화 리뷰평의 긍정/부정을 판단하기 위한 감정분석 분류 모델을 생성한다.\n",
    "- 데이터셋: [imdb](https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews) 전처리 완료 데이터"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제 정의\n",
    "\n",
    "- binary classifier(positive or negative)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 주요 코드"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. RNN의 유형"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![RNN-Relations](https://raw.githubusercontent.com/fhrzn/all-about-rnn/master/sentiment-analysis/notebook/images/diags.jpeg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **many to one**\n",
    "    - 영화 리뷰 텍스트(many)를 입력으로 받아 긍정 또는 부정(one)을 출력하는 구조\n",
    "    - **Embedding**: 영화 리뷰(text)를 벡터로 변환하는 연산\n",
    "    - **LSTM**: 시계열 데이터를 처리하기 위한 구조\n",
    "    - **Linear**: 결과 출력"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**모델 구조 미리보기**\n",
    "```\n",
    "LSTMClassifier(\n",
    "  (embedding): Embedding(121301, 256)\n",
    "  (lstm): LSTM(256, 512, num_layers=2, batch_first=True, dropout=0.25)\n",
    "  (dropout): Dropout(p=0.3, inplace=False)\n",
    "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
    "  (sigmoid): Sigmoid()\n",
    ")\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**torch.nn.LSTM**\n",
    "* Parameters\n",
    "    * input_size\n",
    "    * hidden_size\n",
    "    * num_layers\n",
    "    * dropout\n",
    "    * batch_first\n",
    "    * bidirectional\n",
    "* Inputs: input, (h_0, c_0)\n",
    "    * input shape\n",
    "        * (L, N, H_in) : `batch_size=False`\n",
    "        * (N, L, H_in) : `batch_size=True`\n",
    "\n",
    "* Outputs: output, (h_n, c_n)\n",
    "    * output shape\n",
    "        * (L, N, D*H_out) : `batch_size=False`\n",
    "        * (N, L, D*H_out) : `batch_size=True`\n",
    "\n",
    "----\n",
    "- **N**: batch size\n",
    "- **L**: sequence length\n",
    "- **D**: 2(bidirectional) or 1\n",
    "- **H_in**: input_size\n",
    "- **H_cell**: hidden_size\n",
    "- **H_out**: proj_size or hidden_size"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size=400):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.lstm = nn.LSTM(embedding_size, 512, 2, dropout=0.25, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc = nn.Linear(512, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.long()\n",
    "        x = self.embedding(x)\n",
    "        o, _ =  self.lstm(x)\n",
    "        o = o[:, -1, :]\n",
    "        o = self.dropout(o)\n",
    "        o = self.fc(o)\n",
    "        o = self.sigmoid(o)\n",
    "\n",
    "        return o\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 텍스트 데이터 전처리"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텍스트를 벡터로 변환하는 작업\n",
    "0. 원본\n",
    "    - one reviewer mentioned watching oz episode hooked \n",
    "1. **사전 생성**\n",
    "    - 리뷰 문장에 들어있는 단어들을 추출하고, 각각의 단어에 숫자를 부여하는 작업\n",
    "    - ['one', 'reviewer', 'mentioned', 'watching', 'oz', 'episode', 'hooked']\n",
    "\n",
    "2. 리뷰**인코딩**\n",
    "    - 리뷰에 포함된 단어를 숫자형태로 변환하는 작업\n",
    "    -  {'i': 1, 'movie': 2, 'film': 3, 'the': 4, 'one': 5, 'like': 6, 'it': 7, 'time': 8, 'this': 9, 'good': 10, 'character': 11,...}    \n",
    "    - [5, 1095, 972, 74, 2893, 186, 2982, 119, 114, 538]\n",
    "3. **길이 맞춰주기**: padding or trim\n",
    "    - 신경망의 입력으로 사용하기 위에 일정 길이만큼 맞춰주는 작업\n",
    "    - 길이가 긴 문장은 잘라주고(trim), 길이가 짧은 문장은 채워주는(padding) 작업\n",
    "    - [[  191,  1083,   930,    81,  3724,   186,  3030,     1,   118, 114],<br>\n",
    "       [   47,   328,    59,   244,     1,     7,  1267,  1608, 17875, 4],<br>\n",
    "       [    3,    95,   328,    30,  1041,    13,   845,  1774,  2633, 2],...]\n",
    "\n",
    "4. **학습용, 테스트용 분할**\n",
    "5. **데이터 로더 생성**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. tqdm\n",
    "\n",
    "- iterable을 감싸서 진행률을 표시할 때 사용\n",
    "- 학습 과정의 iteration에서 진행률을 표시할 때 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:05<00:00, 18.46it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    time.sleep(0.05)\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**tqdm parameter**\n",
    "* itereable: 반복자\n",
    "* desc: 진행바 앞에 텍스트 출력\n",
    "* leave: 진행상태를 남겨둘지 여부\n",
    "\n",
    "```\n",
    "# train loop\n",
    "epochloop = tqdm(range(epochs), desc='Training')\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Early stop"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](data:image/png;base64,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)\n",
    "```\n",
    "es_trigger = 0\n",
    "es_limit = 5\n",
    "\n",
    "for e in epochloop:\n",
    "    train_loss, train_acc = train(model, trainloader)\n",
    "    val_loss, val_acc = validation(model, valloader)\n",
    "    \n",
    "    # save model if validation loss decrease\n",
    "    if val_loss / len(valloader) <= val_loss_min:\n",
    "        torch.save(model.state_dict(), './sentiment_lstm.pt')\n",
    "        val_loss_min = val_loss / len(valloader)\n",
    "        es_trigger = 0\n",
    "    else:       \n",
    "        es_trigger += 1\n",
    "\n",
    "    # early stop\n",
    "    if es_trigger >= es_limit:\n",
    "        break\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentimental Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Step1] Load libraries & Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()   # progress_apply\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>processed</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One reviewer mentioned watching Oz episode hoo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production . The filming te...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought wonderful way spend time hot summer ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically family little boy Jake think zombie ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei Love Time Money visually stunnin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           processed  label\n",
       "0  One reviewer mentioned watching Oz episode hoo...      1\n",
       "1  A wonderful little production . The filming te...      1\n",
       "2  I thought wonderful way spend time hot summer ...      1\n",
       "3  Basically family little boy Jake think zombie ...      0\n",
       "4  Petter Mattei Love Time Money visually stunnin...      1"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./data/exercise4.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['processed'] = data['processed'].str.lower().replace(r\"[^a-zA-X]\", \" \", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one reviewer mentioned watching oz episode hooked   they right   exactly happened   the first thing struck oz brutality unflinching scene violence   set right word go   trust   show faint hearted timid   this show pull punch regard drug   sex violence   its hardcore   classic use word   it called oz nickname given oswald maximum security state penitentary   it focus mainly emerald city   experimental section prison cell glass front face inwards   privacy high agenda   em city home many     aryans   muslims   gangsta   latinos   christians   italians   irish         scuffle   death stare   dodgy dealing shady agreement never far away   i would say main appeal show due fact go show dare   forget pretty picture painted mainstream audience   forget charm   forget romance       oz mess around   the first episode i ever saw struck nasty surreal   i say i ready   i watched   i developed taste oz   got accustomed high level graphic violence   not violence   injustice crooked guard sold nickel   inmate kill order get away   well mannered   middle class inmate turned prison bitch due lack street skill prison experience watching oz   may become comfortable uncomfortable viewing         thats get touch darker side  '"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['processed'][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 사전생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one',\n",
       " 'reviewer',\n",
       " 'mentioned',\n",
       " 'watching',\n",
       " 'oz',\n",
       " 'episode',\n",
       " 'hooked',\n",
       " 'they',\n",
       " 'right',\n",
       " 'exactly']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장에 포함된 단어 토큰화\n",
    "reviews = data['processed'].values\n",
    "words = ' '.join(reviews).split()\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'i': 1,\n",
       " 'movie': 2,\n",
       " 'film': 3,\n",
       " 'the': 4,\n",
       " 'one': 5,\n",
       " 'like': 6,\n",
       " 'it': 7,\n",
       " 'time': 8,\n",
       " 'this': 9,\n",
       " 'good': 10,\n",
       " 'character': 11,\n",
       " 'story': 12,\n",
       " 'even': 13,\n",
       " 'get': 14,\n",
       " 'would': 15,\n",
       " 'make': 16,\n",
       " 'see': 17,\n",
       " 'really': 18,\n",
       " 'scene': 19,\n",
       " 'well': 20,\n",
       " 'much': 21,\n",
       " 'bad': 22,\n",
       " 'people': 23,\n",
       " 'great': 24,\n",
       " 'also': 25,\n",
       " 'first': 26,\n",
       " 'show': 27,\n",
       " 'way': 28,\n",
       " 'made': 29,\n",
       " 'thing': 30,\n",
       " 'could': 31,\n",
       " 'life': 32,\n",
       " 'think': 33,\n",
       " 'go': 34,\n",
       " 'but': 35,\n",
       " 'know': 36,\n",
       " 'watch': 37,\n",
       " 'and': 38,\n",
       " 'love': 39,\n",
       " 'plot': 40,\n",
       " 'two': 41,\n",
       " 'actor': 42,\n",
       " 'many': 43,\n",
       " 'seen': 44,\n",
       " 'a': 45,\n",
       " 'say': 46,\n",
       " 'year': 47,\n",
       " 'never': 48,\n",
       " 'end': 49,\n",
       " 'acting': 50,\n",
       " 'look': 51,\n",
       " 'best': 52,\n",
       " 'little': 53,\n",
       " 'in': 54,\n",
       " 'there': 55,\n",
       " 'ever': 56,\n",
       " 'man': 57,\n",
       " 'better': 58,\n",
       " 'take': 59,\n",
       " 'if': 60,\n",
       " 'come': 61,\n",
       " 'work': 62,\n",
       " 'still': 63,\n",
       " 'he': 64,\n",
       " 'part': 65,\n",
       " 'something': 66,\n",
       " 'find': 67,\n",
       " 'director': 68,\n",
       " 'want': 69,\n",
       " 'back': 70,\n",
       " 'give': 71,\n",
       " 'lot': 72,\n",
       " 'real': 73,\n",
       " 'watching': 74,\n",
       " 'guy': 75,\n",
       " 'performance': 76,\n",
       " 'play': 77,\n",
       " 'old': 78,\n",
       " 'funny': 79,\n",
       " 'though': 80,\n",
       " 'woman': 81,\n",
       " 'another': 82,\n",
       " 'actually': 83,\n",
       " 'nothing': 84,\n",
       " 'role': 85,\n",
       " 'going': 86,\n",
       " 'new': 87,\n",
       " 'every': 88,\n",
       " 'point': 89,\n",
       " 'world': 90,\n",
       " 'girl': 91,\n",
       " 'day': 92,\n",
       " 'cast': 93,\n",
       " 'horror': 94,\n",
       " 'comedy': 95,\n",
       " 'minute': 96,\n",
       " 'thought': 97,\n",
       " 'u': 98,\n",
       " 'feel': 99,\n",
       " 'fact': 100,\n",
       " 'quite': 101,\n",
       " 'pretty': 102,\n",
       " 'got': 103,\n",
       " 'around': 104,\n",
       " 'action': 105,\n",
       " 'seems': 106,\n",
       " 'young': 107,\n",
       " 'you': 108,\n",
       " 'star': 109,\n",
       " 'big': 110,\n",
       " 'however': 111,\n",
       " 'enough': 112,\n",
       " 'long': 113,\n",
       " 'right': 114,\n",
       " 'line': 115,\n",
       " 'what': 116,\n",
       " 'may': 117,\n",
       " 'as': 118,\n",
       " 'they': 119,\n",
       " 'bit': 120,\n",
       " 'series': 121,\n",
       " 'must': 122,\n",
       " 'fan': 123,\n",
       " 'music': 124,\n",
       " 'set': 125,\n",
       " 'without': 126,\n",
       " 'friend': 127,\n",
       " 'original': 128,\n",
       " 'saw': 129,\n",
       " 'family': 130,\n",
       " 'always': 131,\n",
       " 'almost': 132,\n",
       " 'script': 133,\n",
       " 'interesting': 134,\n",
       " 'done': 135,\n",
       " 'whole': 136,\n",
       " 'least': 137,\n",
       " 'try': 138,\n",
       " 'far': 139,\n",
       " 'shot': 140,\n",
       " 'kind': 141,\n",
       " 'kid': 142,\n",
       " 'last': 143,\n",
       " 'making': 144,\n",
       " 'might': 145,\n",
       " 'anything': 146,\n",
       " 'effect': 147,\n",
       " 'since': 148,\n",
       " 'reason': 149,\n",
       " 'tv': 150,\n",
       " 'start': 151,\n",
       " 'book': 152,\n",
       " 'probably': 153,\n",
       " 'that': 154,\n",
       " 'so': 155,\n",
       " 'put': 156,\n",
       " 'place': 157,\n",
       " 'away': 158,\n",
       " 'yet': 159,\n",
       " 'moment': 160,\n",
       " 'fun': 161,\n",
       " 'anyone': 162,\n",
       " 'she': 163,\n",
       " 'worst': 164,\n",
       " 'not': 165,\n",
       " 'child': 166,\n",
       " 'let': 167,\n",
       " 'sure': 168,\n",
       " 'rather': 169,\n",
       " 'hard': 170,\n",
       " 'idea': 171,\n",
       " 'audience': 172,\n",
       " 'played': 173,\n",
       " 'screen': 174,\n",
       " 'found': 175,\n",
       " 'need': 176,\n",
       " 'tell': 177,\n",
       " 'looking': 178,\n",
       " 'turn': 179,\n",
       " 'although': 180,\n",
       " 'especially': 181,\n",
       " 'believe': 182,\n",
       " 'dvd': 183,\n",
       " 'ending': 184,\n",
       " 'course': 185,\n",
       " 'episode': 186,\n",
       " 'trying': 187,\n",
       " 'when': 188,\n",
       " 'mean': 189,\n",
       " 'everything': 190,\n",
       " 'job': 191,\n",
       " 'maybe': 192,\n",
       " 'three': 193,\n",
       " 'worth': 194,\n",
       " 'different': 195,\n",
       " 'someone': 196,\n",
       " 'war': 197,\n",
       " 'main': 198,\n",
       " 'sense': 199,\n",
       " 'american': 200,\n",
       " 'problem': 201,\n",
       " 'version': 202,\n",
       " 'money': 203,\n",
       " 'true': 204,\n",
       " 'watched': 205,\n",
       " 'keep': 206,\n",
       " 'everyone': 207,\n",
       " 'second': 208,\n",
       " 'all': 209,\n",
       " 'together': 210,\n",
       " 'help': 211,\n",
       " 'night': 212,\n",
       " 'high': 213,\n",
       " 'for': 214,\n",
       " 'mind': 215,\n",
       " 'half': 216,\n",
       " 'instead': 217,\n",
       " 'death': 218,\n",
       " 'said': 219,\n",
       " 'black': 220,\n",
       " 'boy': 221,\n",
       " 'special': 222,\n",
       " 'later': 223,\n",
       " 'house': 224,\n",
       " 'laugh': 225,\n",
       " 'hour': 226,\n",
       " 'wife': 227,\n",
       " 'john': 228,\n",
       " 'my': 229,\n",
       " 'seem': 230,\n",
       " 'beautiful': 231,\n",
       " 'left': 232,\n",
       " 'seeing': 233,\n",
       " 'short': 234,\n",
       " 'lead': 235,\n",
       " 'we': 236,\n",
       " 'excellent': 237,\n",
       " 'name': 238,\n",
       " 'le': 239,\n",
       " 'classic': 240,\n",
       " 'father': 241,\n",
       " 'sound': 242,\n",
       " 'else': 243,\n",
       " 'budget': 244,\n",
       " 'read': 245,\n",
       " 'face': 246,\n",
       " 'production': 247,\n",
       " 'viewer': 248,\n",
       " 'top': 249,\n",
       " 'piece': 250,\n",
       " 'used': 251,\n",
       " 'nice': 252,\n",
       " 'simply': 253,\n",
       " 'poor': 254,\n",
       " 'completely': 255,\n",
       " 'men': 256,\n",
       " 'eye': 257,\n",
       " 'home': 258,\n",
       " 'camera': 259,\n",
       " 'along': 260,\n",
       " 'human': 261,\n",
       " 'video': 262,\n",
       " 'dead': 263,\n",
       " 'no': 264,\n",
       " 'head': 265,\n",
       " 'song': 266,\n",
       " 'hollywood': 267,\n",
       " 'either': 268,\n",
       " 'school': 269,\n",
       " 'couple': 270,\n",
       " 'boring': 271,\n",
       " 'word': 272,\n",
       " 'low': 273,\n",
       " 'wrong': 274,\n",
       " 'picture': 275,\n",
       " 'hand': 276,\n",
       " 'enjoy': 277,\n",
       " 'use': 278,\n",
       " 'given': 279,\n",
       " 'full': 280,\n",
       " 'rest': 281,\n",
       " 'stupid': 282,\n",
       " 'next': 283,\n",
       " 'sex': 284,\n",
       " 'truly': 285,\n",
       " 'of': 286,\n",
       " 'writer': 287,\n",
       " 'awful': 288,\n",
       " 'hope': 289,\n",
       " 'run': 290,\n",
       " 'kill': 291,\n",
       " 'to': 292,\n",
       " 'person': 293,\n",
       " 'recommend': 294,\n",
       " 'style': 295,\n",
       " 'terrible': 296,\n",
       " 'game': 297,\n",
       " 'remember': 298,\n",
       " 'at': 299,\n",
       " 'title': 300,\n",
       " 'mother': 301,\n",
       " 'getting': 302,\n",
       " 'sort': 303,\n",
       " 'came': 304,\n",
       " 'understand': 305,\n",
       " 'case': 306,\n",
       " 'dialogue': 307,\n",
       " 'perhaps': 308,\n",
       " 'flick': 309,\n",
       " 'act': 310,\n",
       " 'wonderful': 311,\n",
       " 'playing': 312,\n",
       " 'care': 313,\n",
       " 'joke': 314,\n",
       " 'after': 315,\n",
       " 'small': 316,\n",
       " 'attempt': 317,\n",
       " 'others': 318,\n",
       " 'perfect': 319,\n",
       " 'sequence': 320,\n",
       " 'early': 321,\n",
       " 'often': 322,\n",
       " 'review': 323,\n",
       " 'fall': 324,\n",
       " 'written': 325,\n",
       " 'definitely': 326,\n",
       " 'drama': 327,\n",
       " 'art': 328,\n",
       " 'actress': 329,\n",
       " 'cinema': 330,\n",
       " 'quality': 331,\n",
       " 'example': 332,\n",
       " 'went': 333,\n",
       " 'finally': 334,\n",
       " 'feeling': 335,\n",
       " 'yes': 336,\n",
       " 'absolutely': 337,\n",
       " 'live': 338,\n",
       " 'killer': 339,\n",
       " 'oh': 340,\n",
       " 'certainly': 341,\n",
       " 'don': 342,\n",
       " 'lost': 343,\n",
       " 'liked': 344,\n",
       " 'become': 345,\n",
       " 'entertaining': 346,\n",
       " 'worse': 347,\n",
       " 'side': 348,\n",
       " 'loved': 349,\n",
       " 'car': 350,\n",
       " 'called': 351,\n",
       " 'waste': 352,\n",
       " 'white': 353,\n",
       " 'mr': 354,\n",
       " 'felt': 355,\n",
       " 'overall': 356,\n",
       " 'matter': 357,\n",
       " 'based': 358,\n",
       " 'entire': 359,\n",
       " 'supposed': 360,\n",
       " 'several': 361,\n",
       " 'direction': 362,\n",
       " 'son': 363,\n",
       " 'his': 364,\n",
       " 'beginning': 365,\n",
       " 'lack': 366,\n",
       " 'feature': 367,\n",
       " 'heart': 368,\n",
       " 'comment': 369,\n",
       " 'favorite': 370,\n",
       " 'dark': 371,\n",
       " 'fight': 372,\n",
       " 'why': 373,\n",
       " 'type': 374,\n",
       " 'then': 375,\n",
       " 'totally': 376,\n",
       " 'begin': 377,\n",
       " 'evil': 378,\n",
       " 'humor': 379,\n",
       " 'wanted': 380,\n",
       " 'murder': 381,\n",
       " 'seemed': 382,\n",
       " 'hero': 383,\n",
       " 'despite': 384,\n",
       " 'guess': 385,\n",
       " 'brother': 386,\n",
       " 'final': 387,\n",
       " 'voice': 388,\n",
       " 'while': 389,\n",
       " 'already': 390,\n",
       " 'change': 391,\n",
       " 'throughout': 392,\n",
       " 'now': 393,\n",
       " 'becomes': 394,\n",
       " 'relationship': 395,\n",
       " 'hit': 396,\n",
       " 'genre': 397,\n",
       " 'unfortunately': 398,\n",
       " 'able': 399,\n",
       " 'number': 400,\n",
       " 'meet': 401,\n",
       " 'history': 402,\n",
       " 'experience': 403,\n",
       " 'b': 404,\n",
       " 'some': 405,\n",
       " 'cut': 406,\n",
       " 'stop': 407,\n",
       " 'town': 408,\n",
       " 'today': 409,\n",
       " 'writing': 410,\n",
       " 'daughter': 411,\n",
       " 'fine': 412,\n",
       " 'michael': 413,\n",
       " 'god': 414,\n",
       " 'horrible': 415,\n",
       " 'close': 416,\n",
       " 'amazing': 417,\n",
       " 'city': 418,\n",
       " 'age': 419,\n",
       " 'group': 420,\n",
       " 'how': 421,\n",
       " 'move': 422,\n",
       " 'talent': 423,\n",
       " 'past': 424,\n",
       " 'call': 425,\n",
       " 'etc': 426,\n",
       " 'stuff': 427,\n",
       " 'enjoyed': 428,\n",
       " 'brilliant': 429,\n",
       " 'behind': 430,\n",
       " 'gave': 431,\n",
       " 'with': 432,\n",
       " 'event': 433,\n",
       " 'directed': 434,\n",
       " 'level': 435,\n",
       " 'late': 436,\n",
       " 'credit': 437,\n",
       " 'add': 438,\n",
       " 'situation': 439,\n",
       " 'theme': 440,\n",
       " 'save': 441,\n",
       " 'expect': 442,\n",
       " 'stand': 443,\n",
       " 'soon': 444,\n",
       " 'wonder': 445,\n",
       " 'power': 446,\n",
       " 'body': 447,\n",
       " 'on': 448,\n",
       " 'obviously': 449,\n",
       " 'score': 450,\n",
       " 'self': 451,\n",
       " 'sometimes': 452,\n",
       " 'chance': 453,\n",
       " 'thinking': 454,\n",
       " 'killed': 455,\n",
       " 'just': 456,\n",
       " 'decent': 457,\n",
       " 'view': 458,\n",
       " 'highly': 459,\n",
       " 'question': 460,\n",
       " 'blood': 461,\n",
       " 'anyway': 462,\n",
       " 'light': 463,\n",
       " 'known': 464,\n",
       " 'took': 465,\n",
       " 'heard': 466,\n",
       " 'happens': 467,\n",
       " 'except': 468,\n",
       " 'coming': 469,\n",
       " 'country': 470,\n",
       " 'wish': 471,\n",
       " 'element': 472,\n",
       " 'slow': 473,\n",
       " 'career': 474,\n",
       " 'documentary': 475,\n",
       " 'talk': 476,\n",
       " 'novel': 477,\n",
       " 'rating': 478,\n",
       " 'leave': 479,\n",
       " 'order': 480,\n",
       " 'police': 481,\n",
       " 'told': 482,\n",
       " 'interest': 483,\n",
       " 'monster': 484,\n",
       " 'extremely': 485,\n",
       " 'husband': 486,\n",
       " 'violence': 487,\n",
       " 'involved': 488,\n",
       " 'reality': 489,\n",
       " 'strong': 490,\n",
       " 'ok': 491,\n",
       " 'hilarious': 492,\n",
       " 'crap': 493,\n",
       " 'effort': 494,\n",
       " 'hell': 495,\n",
       " 'happen': 496,\n",
       " 'living': 497,\n",
       " 'particularly': 498,\n",
       " 'including': 499,\n",
       " 'looked': 500,\n",
       " 'cool': 501,\n",
       " 'opinion': 502,\n",
       " 'david': 503,\n",
       " 'us': 504,\n",
       " 'simple': 505,\n",
       " 'please': 506,\n",
       " 'musical': 507,\n",
       " 'is': 508,\n",
       " 'twist': 509,\n",
       " 'obvious': 510,\n",
       " 'happened': 511,\n",
       " 'complete': 512,\n",
       " 'gore': 513,\n",
       " 'serious': 514,\n",
       " 'sequel': 515,\n",
       " 'james': 516,\n",
       " 'deal': 517,\n",
       " 'room': 518,\n",
       " 'ago': 519,\n",
       " 'theater': 520,\n",
       " 'taken': 521,\n",
       " 'female': 522,\n",
       " 'shown': 523,\n",
       " 'robert': 524,\n",
       " 'english': 525,\n",
       " 'thriller': 526,\n",
       " 'seriously': 527,\n",
       " 'released': 528,\n",
       " 'lady': 529,\n",
       " 'opening': 530,\n",
       " 'value': 531,\n",
       " 'across': 532,\n",
       " 'alone': 533,\n",
       " 'none': 534,\n",
       " 'miss': 535,\n",
       " 'sad': 536,\n",
       " 'possible': 537,\n",
       " 'exactly': 538,\n",
       " 'saying': 539,\n",
       " 'sister': 540,\n",
       " 'cop': 541,\n",
       " 'usually': 542,\n",
       " 'cinematography': 543,\n",
       " 'dialog': 544,\n",
       " 'annoying': 545,\n",
       " 'running': 546,\n",
       " 'dream': 547,\n",
       " 'huge': 548,\n",
       " 'class': 549,\n",
       " 'open': 550,\n",
       " 'whose': 551,\n",
       " 'taking': 552,\n",
       " 'comic': 553,\n",
       " 'ridiculous': 554,\n",
       " 'stay': 555,\n",
       " 'major': 556,\n",
       " 'local': 557,\n",
       " 'middle': 558,\n",
       " 'important': 559,\n",
       " 'four': 560,\n",
       " 'dog': 561,\n",
       " 'started': 562,\n",
       " 'jack': 563,\n",
       " 'message': 564,\n",
       " 'zombie': 565,\n",
       " 'turned': 566,\n",
       " 'producer': 567,\n",
       " 'scary': 568,\n",
       " 'mostly': 569,\n",
       " 'team': 570,\n",
       " 'usual': 571,\n",
       " 'happy': 572,\n",
       " 'beyond': 573,\n",
       " 'silly': 574,\n",
       " 'hate': 575,\n",
       " 'attention': 576,\n",
       " 'somewhat': 577,\n",
       " 'talking': 578,\n",
       " 'knew': 579,\n",
       " 'rock': 580,\n",
       " 'disappointed': 581,\n",
       " 'surprise': 582,\n",
       " 'single': 583,\n",
       " 'strange': 584,\n",
       " 'apparently': 585,\n",
       " 'non': 586,\n",
       " 'television': 587,\n",
       " 'upon': 588,\n",
       " 'modern': 589,\n",
       " 'due': 590,\n",
       " 'basically': 591,\n",
       " 'cheap': 592,\n",
       " 'release': 593,\n",
       " 'figure': 594,\n",
       " 'from': 595,\n",
       " 'mention': 596,\n",
       " 'earth': 597,\n",
       " 'result': 598,\n",
       " 'member': 599,\n",
       " 'king': 600,\n",
       " 'image': 601,\n",
       " 'tale': 602,\n",
       " 'subject': 603,\n",
       " 'street': 604,\n",
       " 'crime': 605,\n",
       " 'clearly': 606,\n",
       " 'space': 607,\n",
       " 'parent': 608,\n",
       " 'ten': 609,\n",
       " 'season': 610,\n",
       " 'five': 611,\n",
       " 'british': 612,\n",
       " 'return': 613,\n",
       " 'drug': 614,\n",
       " 'french': 615,\n",
       " 'moving': 616,\n",
       " 'entertainment': 617,\n",
       " 'filmmaker': 618,\n",
       " 'fast': 619,\n",
       " 'straight': 620,\n",
       " 'mystery': 621,\n",
       " 'soundtrack': 622,\n",
       " 'predictable': 623,\n",
       " 'future': 624,\n",
       " 'die': 625,\n",
       " 'form': 626,\n",
       " 'viewing': 627,\n",
       " 'hold': 628,\n",
       " 'whether': 629,\n",
       " 'villain': 630,\n",
       " 'doubt': 631,\n",
       " 'george': 632,\n",
       " 'gun': 633,\n",
       " 'killing': 634,\n",
       " 'romantic': 635,\n",
       " 'easily': 636,\n",
       " 'enjoyable': 637,\n",
       " 'near': 638,\n",
       " 'appears': 639,\n",
       " 'break': 640,\n",
       " 'buy': 641,\n",
       " 's': 642,\n",
       " 'bring': 643,\n",
       " 'giving': 644,\n",
       " 'aspect': 645,\n",
       " 'similar': 646,\n",
       " 'supporting': 647,\n",
       " 'working': 648,\n",
       " 'clear': 649,\n",
       " 'within': 650,\n",
       " 'filmed': 651,\n",
       " 'showing': 652,\n",
       " 'bunch': 653,\n",
       " 'adult': 654,\n",
       " 'note': 655,\n",
       " 'dull': 656,\n",
       " 'western': 657,\n",
       " 'suspense': 658,\n",
       " 'doctor': 659,\n",
       " 'emotion': 660,\n",
       " 'storyline': 661,\n",
       " 'surprised': 662,\n",
       " 'easy': 663,\n",
       " 'sorry': 664,\n",
       " 'tried': 665,\n",
       " 'certain': 666,\n",
       " 'among': 667,\n",
       " 'setting': 668,\n",
       " 'named': 669,\n",
       " 'dance': 670,\n",
       " 'standard': 671,\n",
       " 'present': 672,\n",
       " 'period': 673,\n",
       " 'gone': 674,\n",
       " 'check': 675,\n",
       " 'force': 676,\n",
       " 'victim': 677,\n",
       " 'soldier': 678,\n",
       " 'general': 679,\n",
       " 'dr': 680,\n",
       " 'student': 681,\n",
       " 'using': 682,\n",
       " 'typical': 683,\n",
       " 'rent': 684,\n",
       " 'an': 685,\n",
       " 'oscar': 686,\n",
       " 'editing': 687,\n",
       " 'avoid': 688,\n",
       " 'th': 689,\n",
       " 'peter': 690,\n",
       " 'material': 691,\n",
       " 'richard': 692,\n",
       " 'fantastic': 693,\n",
       " 'who': 694,\n",
       " 'kept': 695,\n",
       " 'nearly': 696,\n",
       " 'realistic': 697,\n",
       " 'detail': 698,\n",
       " 'cartoon': 699,\n",
       " 'okay': 700,\n",
       " 'battle': 701,\n",
       " 'greatest': 702,\n",
       " 'its': 703,\n",
       " 'red': 704,\n",
       " 'famous': 705,\n",
       " 'animation': 706,\n",
       " 'imagine': 707,\n",
       " 'paul': 708,\n",
       " 'actual': 709,\n",
       " 'follow': 710,\n",
       " 'premise': 711,\n",
       " 'issue': 712,\n",
       " 'mark': 713,\n",
       " 'believable': 714,\n",
       " 'tom': 715,\n",
       " 'box': 716,\n",
       " 'brought': 717,\n",
       " 'wait': 718,\n",
       " 'truth': 719,\n",
       " 'romance': 720,\n",
       " 'somehow': 721,\n",
       " 'forget': 722,\n",
       " 'masterpiece': 723,\n",
       " 'male': 724,\n",
       " 'fit': 725,\n",
       " 'third': 726,\n",
       " 'copy': 727,\n",
       " 'offer': 728,\n",
       " 'most': 729,\n",
       " 'average': 730,\n",
       " 'america': 731,\n",
       " 'weak': 732,\n",
       " 'hear': 733,\n",
       " 'background': 734,\n",
       " 'sit': 735,\n",
       " 'escape': 736,\n",
       " 'pay': 737,\n",
       " 'stage': 738,\n",
       " 'society': 739,\n",
       " 'atmosphere': 740,\n",
       " 'deep': 741,\n",
       " 'york': 742,\n",
       " 'cover': 743,\n",
       " 'o': 744,\n",
       " 'cause': 745,\n",
       " 'fi': 746,\n",
       " 'her': 747,\n",
       " 'eventually': 748,\n",
       " 'gay': 749,\n",
       " 'learn': 750,\n",
       " 'sci': 751,\n",
       " 'imdb': 752,\n",
       " 'whatever': 753,\n",
       " 'expected': 754,\n",
       " 'particular': 755,\n",
       " 'lame': 756,\n",
       " 'indeed': 757,\n",
       " 'de': 758,\n",
       " 'poorly': 759,\n",
       " 'shame': 760,\n",
       " 'these': 761,\n",
       " 'free': 762,\n",
       " 'hot': 763,\n",
       " 'rate': 764,\n",
       " 'baby': 765,\n",
       " 'crew': 766,\n",
       " 'choice': 767,\n",
       " 'walk': 768,\n",
       " 'state': 769,\n",
       " 'by': 770,\n",
       " 'secret': 771,\n",
       " 'decided': 772,\n",
       " 'leaf': 773,\n",
       " 'party': 774,\n",
       " 'screenplay': 775,\n",
       " 'reading': 776,\n",
       " 'fire': 777,\n",
       " 'air': 778,\n",
       " 'difficult': 779,\n",
       " 'lee': 780,\n",
       " 'week': 781,\n",
       " 'needed': 782,\n",
       " 'beauty': 783,\n",
       " 'girlfriend': 784,\n",
       " 'footage': 785,\n",
       " 'focus': 786,\n",
       " 'acted': 787,\n",
       " 'unless': 788,\n",
       " 'emotional': 789,\n",
       " 'possibly': 790,\n",
       " 'island': 791,\n",
       " 'here': 792,\n",
       " 'sexual': 793,\n",
       " 'write': 794,\n",
       " 'accent': 795,\n",
       " 'alien': 796,\n",
       " 'forced': 797,\n",
       " 'became': 798,\n",
       " 'memorable': 799,\n",
       " 'e': 800,\n",
       " 'vampire': 801,\n",
       " 'd': 802,\n",
       " 'do': 803,\n",
       " 'otherwise': 804,\n",
       " 'nature': 805,\n",
       " 'forward': 806,\n",
       " 'plus': 807,\n",
       " 'match': 808,\n",
       " 'very': 809,\n",
       " 'touch': 810,\n",
       " 'lover': 811,\n",
       " 'bill': 812,\n",
       " 'cheesy': 813,\n",
       " 'location': 814,\n",
       " 'water': 815,\n",
       " 'or': 816,\n",
       " 'superb': 817,\n",
       " 'fantasy': 818,\n",
       " 'inside': 819,\n",
       " 'interested': 820,\n",
       " 'development': 821,\n",
       " 'perfectly': 822,\n",
       " 'animal': 823,\n",
       " 'weird': 824,\n",
       " 'previous': 825,\n",
       " 'badly': 826,\n",
       " 'adventure': 827,\n",
       " 'japanese': 828,\n",
       " 'mess': 829,\n",
       " 'crazy': 830,\n",
       " 'personal': 831,\n",
       " 't': 832,\n",
       " 'pick': 833,\n",
       " 'quickly': 834,\n",
       " 'total': 835,\n",
       " 'maker': 836,\n",
       " 'business': 837,\n",
       " 'towards': 838,\n",
       " 'disney': 839,\n",
       " 'spoiler': 840,\n",
       " 'front': 841,\n",
       " 'plan': 842,\n",
       " 'win': 843,\n",
       " 'company': 844,\n",
       " 'remake': 845,\n",
       " 'joe': 846,\n",
       " 'rich': 847,\n",
       " 'cry': 848,\n",
       " 'worked': 849,\n",
       " 'earlier': 850,\n",
       " 'incredibly': 851,\n",
       " 'shoot': 852,\n",
       " 'teen': 853,\n",
       " 'fear': 854,\n",
       " 'dumb': 855,\n",
       " 'studio': 856,\n",
       " 'brain': 857,\n",
       " 'unique': 858,\n",
       " 'realize': 859,\n",
       " 'project': 860,\n",
       " 'powerful': 861,\n",
       " 'list': 862,\n",
       " 'dramatic': 863,\n",
       " 'older': 864,\n",
       " 'era': 865,\n",
       " 'following': 866,\n",
       " 'success': 867,\n",
       " 'plenty': 868,\n",
       " 'directing': 869,\n",
       " 'amount': 870,\n",
       " 'ask': 871,\n",
       " 'creepy': 872,\n",
       " 'various': 873,\n",
       " 'cat': 874,\n",
       " 'appear': 875,\n",
       " 'term': 876,\n",
       " 'brings': 877,\n",
       " 'band': 878,\n",
       " 'century': 879,\n",
       " 'costume': 880,\n",
       " 'admit': 881,\n",
       " 'political': 882,\n",
       " 'apart': 883,\n",
       " 'store': 884,\n",
       " 'leading': 885,\n",
       " 'fairly': 886,\n",
       " 'memory': 887,\n",
       " 'portrayed': 888,\n",
       " 'spent': 889,\n",
       " 'wood': 890,\n",
       " 'co': 891,\n",
       " 'telling': 892,\n",
       " 'law': 893,\n",
       " 'trouble': 894,\n",
       " 'outside': 895,\n",
       " 'train': 896,\n",
       " 'fighting': 897,\n",
       " 'wasted': 898,\n",
       " 'william': 899,\n",
       " 'fails': 900,\n",
       " 'deserves': 901,\n",
       " 'portrayal': 902,\n",
       " 'throw': 903,\n",
       " 'chase': 904,\n",
       " 'c': 905,\n",
       " 'office': 906,\n",
       " 'meant': 907,\n",
       " 'concept': 908,\n",
       " 'drive': 909,\n",
       " 'creature': 910,\n",
       " 'create': 911,\n",
       " 'plain': 912,\n",
       " 'expecting': 913,\n",
       " 'missing': 914,\n",
       " 'ability': 915,\n",
       " 'spirit': 916,\n",
       " 'ended': 917,\n",
       " 'german': 918,\n",
       " 'manages': 919,\n",
       " 'language': 920,\n",
       " 'mistake': 921,\n",
       " 'agree': 922,\n",
       " 'cute': 923,\n",
       " 'player': 924,\n",
       " 'appearance': 925,\n",
       " 'stick': 926,\n",
       " 'recently': 927,\n",
       " 'channel': 928,\n",
       " 'attack': 929,\n",
       " 'talented': 930,\n",
       " 'caught': 931,\n",
       " 'odd': 932,\n",
       " 'large': 933,\n",
       " 'unlike': 934,\n",
       " 'depth': 935,\n",
       " 'hardly': 936,\n",
       " 'produced': 937,\n",
       " 'pace': 938,\n",
       " 'clever': 939,\n",
       " 'laughing': 940,\n",
       " 'italian': 941,\n",
       " 'award': 942,\n",
       " 'nudity': 943,\n",
       " 'public': 944,\n",
       " 'flat': 945,\n",
       " 'potential': 946,\n",
       " 'tension': 947,\n",
       " 'casting': 948,\n",
       " 'culture': 949,\n",
       " 'created': 950,\n",
       " 'color': 951,\n",
       " 'ghost': 952,\n",
       " 'missed': 953,\n",
       " 'pull': 954,\n",
       " 'master': 955,\n",
       " 'married': 956,\n",
       " 'wrote': 957,\n",
       " 'hole': 958,\n",
       " 'pure': 959,\n",
       " 'soul': 960,\n",
       " 'waiting': 961,\n",
       " 'control': 962,\n",
       " 'door': 963,\n",
       " 'van': 964,\n",
       " 'blue': 965,\n",
       " 'filled': 966,\n",
       " 'scott': 967,\n",
       " 'cold': 968,\n",
       " 'science': 969,\n",
       " 'respect': 970,\n",
       " 'incredible': 971,\n",
       " 'mentioned': 972,\n",
       " 'sadly': 973,\n",
       " 'visual': 974,\n",
       " 'familiar': 975,\n",
       " 'slightly': 976,\n",
       " 'speak': 977,\n",
       " 'considering': 978,\n",
       " 'died': 979,\n",
       " 'only': 980,\n",
       " 'sweet': 981,\n",
       " 'hair': 982,\n",
       " 'popular': 983,\n",
       " 'answer': 984,\n",
       " 'catch': 985,\n",
       " 'purpose': 986,\n",
       " 'post': 987,\n",
       " 'million': 988,\n",
       " 'la': 989,\n",
       " 'extra': 990,\n",
       " 'anti': 991,\n",
       " 'meaning': 992,\n",
       " 'gang': 993,\n",
       " 'decides': 994,\n",
       " 'social': 995,\n",
       " 'convincing': 996,\n",
       " 'college': 997,\n",
       " 'jane': 998,\n",
       " 'track': 999,\n",
       " 'taste': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = Counter(words)\n",
    "vocab = sorted(counter, key=counter.get, reverse=True)\n",
    "int2word = dict(enumerate(vocab, 1))\n",
    "int2word[0] = '<PAD>'   # padding for short sentences\n",
    "word2int = {word: idx for idx, word in int2word.items()}\n",
    "word2int"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 리뷰 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:00<00:00, 59223.38it/s]\n"
     ]
    }
   ],
   "source": [
    "reviews_enc = [[word2int[word] for word in review.split()] for review in tqdm(reviews)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 1095, 972, 74, 2893, 186, 2982, 119, 114, 538]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_enc[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one reviewer mentioned watching oz episode hooked   they right   exactly happened   the first thing struck oz brutality unflinching scene violence   set right word go   trust   show faint hearted timid   this show pull punch regard drug   sex violence   its hardcore   classic use word   it called oz nickname given oswald maximum security state penitentary   it focus mainly emerald city   experimental section prison cell glass front face inwards   privacy high agenda   em city home many     aryans   muslims   gangsta   latinos   christians   italians   irish         scuffle   death stare   dodgy dealing shady agreement never far away   i would say main appeal show due fact go show dare   forget pretty picture painted mainstream audience   forget charm   forget romance       oz mess around   the first episode i ever saw struck nasty surreal   i say i ready   i watched   i developed taste oz   got accustomed high level graphic violence   not violence   injustice crooked guard sold nickel   inmate kill order get away   well mannered   middle class inmate turned prison bitch due lack street skill prison experience watching oz   may become comfortable uncomfortable viewing         thats get touch darker side  '"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['processed'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 1095, 972)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2int['one'], word2int['reviewer'], word2int['mentioned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['encoded'] = reviews_enc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 길이 맞춰주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_feautres(reviews, pad_id, seq_length=128):\n",
    "    features = np.full((len(reviews), seq_length), pad_id, dtype=int)   # 0으로 채워진 배열 생성 np.full((5, 3), 2)\n",
    "\n",
    "    for i, row in enumerate(reviews):\n",
    "        # if seq_length > len(row) then review will be trimmed\n",
    "        features[i, :len(row)] = np.array(row)[:seq_length]\n",
    "    \n",
    "    return features\n",
    "\n",
    "seq_length = 256\n",
    "features = pad_feautres(reviews_enc, pad_id=word2int['<PAD>'], seq_length=seq_length)\n",
    "\n",
    "assert len(features) == len(reviews_enc)\n",
    "assert len(features[0]) == seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = data['label'].to_numpy()\n",
    "labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (32000, 256), Valid shape: (8000, 256), Test shape: (10000, 256)\n",
      "Train shape: (32000,), Valid shape: (8000,), Test shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "train_size = .8\n",
    "split_id = int(len(features) * train_size)\n",
    "\n",
    "train_x, test_x, train_y, test_y = features[:split_id], features[split_id:], labels[:split_id], labels[split_id:]\n",
    "\n",
    "split_id = int(len(train_x) * train_size)\n",
    "train_x, valid_x, train_y, valid_y = train_x[:split_id], train_x[split_id:], train_y[:split_id], train_y[split_id:]\n",
    "\n",
    "print('Train shape: {}, Valid shape: {}, Test shape: {}'.format(train_x.shape, valid_x.shape, test_x.shape))\n",
    "print('Train shape: {}, Valid shape: {}, Test shape: {}'.format(train_y.shape, valid_y.shape, test_y.shape))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Step2] Create DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps:0\n"
     ]
    }
   ],
   "source": [
    "# set hyperparameter\n",
    "\n",
    "DEVICE = torch.device('mps:0' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(DEVICE)\n",
    "\n",
    "lr = 0.001\n",
    "batch_size = 128\n",
    "vocab_size = len(word2int)\n",
    "embedding_size = 256\n",
    "dropout = 0.25\n",
    "\n",
    "epochs = 8\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': [],\n",
    "    'epochs': epochs\n",
    "}\n",
    "es_limit = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "validset = TensorDataset(torch.from_numpy(valid_x), torch.from_numpy(valid_y))\n",
    "testset = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "valloader = DataLoader(validset, batch_size=batch_size, shuffle=True)\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Step3] Set Network Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size=400):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.lstm = nn.LSTM(embedding_size, 512, 2, dropout=0.5, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc = nn.Linear(512, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.long().to(DEVICE)    # torch.LongTensor\n",
    "        x = self.embedding(x)\n",
    "        o, _ = self.lstm(x) # o: [batch_size, seq_length, hidden_size], _: [num_layers, batch_size, hidden_size]\n",
    "        o = o[:, -1, :]\n",
    "        o = self.dropout(o)\n",
    "        o = self.fc(o)\n",
    "        o = self.sigmoid(o)\n",
    "\n",
    "        return o"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Step4] Create Model instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMClassifier(\n",
      "  (embedding): Embedding(96140, 256)\n",
      "  (lstm): LSTM(256, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = LSTMClassifier(vocab_size, embedding_size)\n",
    "print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Step5] Model compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()    # Binary Cross Entropy Loss\n",
    "optimizer = Adam(model.parameters(), lr=lr) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Step6] Set train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, trainloader):\n",
    "    model.train()\n",
    "\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "\n",
    "    for id, (X, y) in enumerate(trainloader):\n",
    "        X, y = X.to(DEVICE), y.to(DEVICE)        \n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X)\n",
    "        loss = criterion(y_pred.squeeze(), y.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        y_pred = torch.tensor([1 if i == True else 0 for i in y_pred > 0.5], device=DEVICE)\n",
    "        equals = y_pred == y\n",
    "        acc = torch.mean(equals.type(torch.FloatTensor))\n",
    "        train_acc += acc.item()\n",
    "\n",
    "    history['train_loss'].append(train_loss / len(trainloader))\n",
    "    history['train_acc'].append(train_acc / len(trainloader))\n",
    "\n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Step7] Set test loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, valloader):\n",
    "    model.eval()\n",
    "\n",
    "    val_loss = 0\n",
    "    val_acc = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for id, (X, y) in enumerate(valloader):            \n",
    "            X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "            y_pred = model(X)\n",
    "            loss = criterion(y_pred.squeeze(), y.float())\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            y_pred = torch.tensor([1 if i == True else 0 for i in y_pred > 0.5], device=DEVICE)\n",
    "            equals = y_pred == y\n",
    "            acc = torch.mean(equals.type(torch.FloatTensor))\n",
    "            val_acc += acc.item()\n",
    "\n",
    "        history['val_loss'].append(val_loss / len(valloader))\n",
    "        history['val_acc'].append(val_acc / len(valloader))\n",
    "\n",
    "    return val_loss, val_acc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Step8] Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/8 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Placeholder storage has not been allocated on MPS device!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[115], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m val_loss_min \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39minf\n\u001b[1;32m      8\u001b[0m \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m epochloop:\n\u001b[0;32m----> 9\u001b[0m     train_loss, train_acc \u001b[39m=\u001b[39m train(model, trainloader)\n\u001b[1;32m     10\u001b[0m     val_loss, val_acc \u001b[39m=\u001b[39m validation(model, valloader)\n\u001b[1;32m     11\u001b[0m     epochloop\u001b[39m.\u001b[39mwrite(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch[\u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mepochs\u001b[39m}\u001b[39;00m\u001b[39m] Train Loss: \u001b[39m\u001b[39m{\u001b[39;00mtrain_loss\u001b[39m \u001b[39m\u001b[39m/\u001b[39m\u001b[39m \u001b[39m\u001b[39mlen\u001b[39m(trainloader)\u001b[39m:\u001b[39;00m\u001b[39m.3f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, Train Acc: \u001b[39m\u001b[39m{\u001b[39;00mtrain_acc\u001b[39m \u001b[39m\u001b[39m/\u001b[39m\u001b[39m \u001b[39m\u001b[39mlen\u001b[39m(trainloader)\u001b[39m:\u001b[39;00m\u001b[39m.3f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, Val Loss: \u001b[39m\u001b[39m{\u001b[39;00mval_loss\u001b[39m \u001b[39m\u001b[39m/\u001b[39m\u001b[39m \u001b[39m\u001b[39mlen\u001b[39m(valloader)\u001b[39m:\u001b[39;00m\u001b[39m.3f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, Val Acc: \u001b[39m\u001b[39m{\u001b[39;00mval_acc\u001b[39m \u001b[39m\u001b[39m/\u001b[39m\u001b[39m \u001b[39m\u001b[39mlen\u001b[39m(valloader)\u001b[39m:\u001b[39;00m\u001b[39m.3f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[113], line 10\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, trainloader)\u001b[0m\n\u001b[1;32m      8\u001b[0m X, y \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mto(DEVICE), y\u001b[39m.\u001b[39mto(DEVICE)        \n\u001b[1;32m      9\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 10\u001b[0m y_pred \u001b[39m=\u001b[39m model(X)\n\u001b[1;32m     11\u001b[0m loss \u001b[39m=\u001b[39m criterion(y_pred\u001b[39m.\u001b[39msqueeze(), y\u001b[39m.\u001b[39mfloat())\n\u001b[1;32m     12\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[110], line 12\u001b[0m, in \u001b[0;36mLSTMClassifier.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     11\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mlong()\u001b[39m.\u001b[39mto(DEVICE)    \u001b[39m# torch.LongTensor\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membedding(x)\n\u001b[1;32m     13\u001b[0m     o, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlstm(x) \u001b[39m# o: [batch_size, seq_length, hidden_size], _: [num_layers, batch_size, hidden_size]\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     o \u001b[39m=\u001b[39m o[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :]\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/sparse.py:162\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 162\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49membedding(\n\u001b[1;32m    163\u001b[0m         \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding_idx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_norm,\n\u001b[1;32m    164\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm_type, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscale_grad_by_freq, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msparse)\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.11/site-packages/torch/nn/functional.py:2210\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2204\u001b[0m     \u001b[39m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2205\u001b[0m     \u001b[39m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2206\u001b[0m     \u001b[39m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2207\u001b[0m     \u001b[39m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2208\u001b[0m     \u001b[39m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2209\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[39minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2210\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49membedding(weight, \u001b[39minput\u001b[39;49m, padding_idx, scale_grad_by_freq, sparse)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Placeholder storage has not been allocated on MPS device!"
     ]
    }
   ],
   "source": [
    "# train loop\n",
    "epochloop = tqdm(range(epochs), desc='Training')\n",
    "\n",
    "# early stop trigger\n",
    "es_trigger = 0\n",
    "val_loss_min = torch.inf\n",
    "\n",
    "for e in epochloop:\n",
    "    train_loss, train_acc = train(model, trainloader)\n",
    "    val_loss, val_acc = validation(model, valloader)\n",
    "    epochloop.write(f'Epoch[{e+1}/{epochs}] Train Loss: {train_loss / len(trainloader):.3f}, Train Acc: {train_acc / len(trainloader):.3f}, Val Loss: {val_loss / len(valloader):.3f}, Val Acc: {val_acc / len(valloader):.3f}')\n",
    "\n",
    "    # save model if validation loss decrease\n",
    "    if val_loss / len(valloader) <= val_loss_min:\n",
    "        torch.save(model.state_dict(), './sentiment_lstm.pt')\n",
    "        val_loss_min = val_loss / len(valloader)\n",
    "        es_trigger = 0\n",
    "    else:       \n",
    "        es_trigger += 1\n",
    "\n",
    "    # early stop\n",
    "    if es_trigger >= es_limit:\n",
    "        epochloop.write(f'Early stopped at Epoch-{e+1}')\n",
    "        history['epochs'] = e+1\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(range(history['epochs']), history['train_acc'], label='Train Acc')\n",
    "plt.plot(range(history['epochs']), history['val_acc'], label='Val Acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(range(history['epochs']), history['train_loss'], label='Train Loss')\n",
    "plt.plot(range(history['epochs']), history['val_loss'], label='Val Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- References:\n",
    "    - [Udacity - Introduction to PyTorch](https://classroom.udacity.com/courses/ud188)\n",
    "    - [The Unreasonable Effectiveness of RNNs by Andrej Karpathy](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n",
    "    - [PyTorch Name Classification project](https://github.com/python-engineer/pytorch-examples/tree/master/rnn-name-classification)\n",
    "    - [My exploration project in RNNs](https://github.com/fhrzn/all-about-rnn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
