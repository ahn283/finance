{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGGNet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습 목표\n",
    "- VGGNet을 사용하여 이미지를 학습하고 10개의 카테고리를 갖는 이미지를 분류하는 이미지 분류기를 생성한다. (데이터셋: [CIFAR](https://pytorch.org/vision/0.9/datasets.html#cifar))\n",
    "- Pre-training 모델의 사용방법을 이해한다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제 정의\n",
    "- VGGNet 구조 살펴보기\n",
    "\n",
    "\n",
    "\n",
    "![VGG](https://miro.medium.com/max/1100/0*6VP81rFoLWp10FcG)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 주요 코드\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1. VGGNet\n",
    "\n",
    "```\n",
    "# Model\n",
    "cfg = {\n",
    "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, vgg_name):   #vgg_name 추가 변수\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = self._make_layers(cfg[vgg_name])\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 1 * 1, 360),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(360, 100),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(100, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "    # 'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    def _make_layers(self, cfg):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for x in cfg:\n",
    "            if x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
    "                           nn.BatchNorm2d(x),\n",
    "                           nn.ReLU(inplace=True)]\n",
    "                in_channels = x\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Pretrained model\n",
    "\n",
    "```\n",
    "from torchvision import models\n",
    "\n",
    "vgg16 = models.vgg16(pretrained=True)\n",
    "vgg16.to(DEVICE)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(vgg16.classifier.parameters(), lr = LEARNING_RATE, momentum=0.9)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR Classifier(VGGNet)\n",
    "\n",
    "- CIFAR 데이터셋을 사용하여 이미지에 포함된 object가 무엇인지 분류하는 이미지 분류기를 생성해봅니다.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Step1] Load libraries & Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision.transforms.functional import to_pil_image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Step2] Data preprocessing\n",
    "\n",
    "불러온 이미지의 증강을 통해 학습 정확도를 향상시키도록 합니다.\n",
    "\n",
    "* RandomCrop\n",
    "* RandomHorizontalFlip\n",
    "* Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_img = datasets.CIFAR10(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms\n",
    ")\n",
    "\n",
    "test_img = datasets.CIFAR10(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Step3] Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device: mps:0\n"
     ]
    }
   ],
   "source": [
    "EPOCH = 10\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 1e-3\n",
    "# DEVICE = 'cpu'\n",
    "DEVICE = torch.device('mps:0' if torch.backends.mps.is_available() else 'cpu')\n",
    "print('Using Device:', DEVICE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Step4] Create DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_img, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_img, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Step5] Set Network Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "cfg = {\n",
    "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, vgg_name):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = self._make_layers(cfg[vgg_name])\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(25088 * 1 * 1, 360),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(360, 100),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(100, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "    def _make_layers(self, cfg):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for x in cfg:\n",
    "            if x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
    "                           nn.BatchNorm2d(x),\n",
    "                           nn.ReLU(inplace=True)]\n",
    "                in_channels = x\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Step6] Create Model instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace=True)\n",
      "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace=True)\n",
      "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): ReLU(inplace=True)\n",
      "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (32): ReLU(inplace=True)\n",
      "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (36): ReLU(inplace=True)\n",
      "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (39): ReLU(inplace=True)\n",
      "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (42): ReLU(inplace=True)\n",
      "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=360, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=360, out_features=100, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=100, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = VGG('VGG16').to(DEVICE)\n",
    "print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Step7] Model compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Step8] Set train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    size = len(train_loader.dataset)\n",
    "\n",
    "    for batch, (X, y) in enumerate(train_loader):\n",
    "        X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "        pred = model(X)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f'loss: {loss:>7f} [{current:>5d}/{size:>5d}]')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Step9] Set test loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_loader, model, loss_fn):\n",
    "    model.eval()\n",
    "\n",
    "    size = len(test_loader.dataset)\n",
    "    num_batches = len(test_loader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in test_loader:\n",
    "            X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    \n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f'Test Error: \\n Accuracy: {(100 * correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Step10] Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.353894 [    0/50000]\n",
      "loss: 2.299620 [ 3200/50000]\n",
      "loss: 2.251302 [ 6400/50000]\n",
      "loss: 2.157037 [ 9600/50000]\n",
      "loss: 1.962983 [12800/50000]\n",
      "loss: 2.033034 [16000/50000]\n",
      "loss: 1.984756 [19200/50000]\n",
      "loss: 1.889907 [22400/50000]\n",
      "loss: 2.155015 [25600/50000]\n",
      "loss: 1.890409 [28800/50000]\n",
      "loss: 1.609838 [32000/50000]\n",
      "loss: 2.117489 [35200/50000]\n",
      "loss: 1.688444 [38400/50000]\n",
      "loss: 1.529558 [41600/50000]\n",
      "loss: 1.566147 [44800/50000]\n",
      "loss: 2.040133 [48000/50000]\n",
      "Test Error: \n",
      " Accuracy: 45.7%, Avg loss: 1.531206 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.970236 [    0/50000]\n",
      "loss: 1.724916 [ 3200/50000]\n",
      "loss: 1.671883 [ 6400/50000]\n",
      "loss: 1.508912 [ 9600/50000]\n",
      "loss: 1.738776 [12800/50000]\n",
      "loss: 1.502121 [16000/50000]\n",
      "loss: 1.553996 [19200/50000]\n",
      "loss: 1.604620 [22400/50000]\n",
      "loss: 1.828905 [25600/50000]\n",
      "loss: 1.680809 [28800/50000]\n",
      "loss: 1.480579 [32000/50000]\n",
      "loss: 1.717993 [35200/50000]\n",
      "loss: 1.555670 [38400/50000]\n",
      "loss: 1.279361 [41600/50000]\n",
      "loss: 1.547433 [44800/50000]\n",
      "loss: 1.490305 [48000/50000]\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 1.309808 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.520725 [    0/50000]\n",
      "loss: 1.381903 [ 3200/50000]\n",
      "loss: 1.271948 [ 6400/50000]\n",
      "loss: 1.401708 [ 9600/50000]\n",
      "loss: 1.488366 [12800/50000]\n",
      "loss: 1.530860 [16000/50000]\n",
      "loss: 1.870282 [19200/50000]\n",
      "loss: 1.738231 [22400/50000]\n",
      "loss: 1.406079 [25600/50000]\n",
      "loss: 1.093180 [28800/50000]\n",
      "loss: 1.376769 [32000/50000]\n",
      "loss: 1.121212 [35200/50000]\n",
      "loss: 1.288316 [38400/50000]\n",
      "loss: 1.216862 [41600/50000]\n",
      "loss: 1.364798 [44800/50000]\n",
      "loss: 1.647508 [48000/50000]\n",
      "Test Error: \n",
      " Accuracy: 55.7%, Avg loss: 1.230521 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.295861 [    0/50000]\n",
      "loss: 1.236915 [ 3200/50000]\n",
      "loss: 1.075611 [ 6400/50000]\n",
      "loss: 1.245281 [ 9600/50000]\n",
      "loss: 1.440298 [12800/50000]\n",
      "loss: 1.324826 [16000/50000]\n",
      "loss: 0.892267 [19200/50000]\n",
      "loss: 0.996596 [22400/50000]\n",
      "loss: 1.189970 [25600/50000]\n",
      "loss: 1.231601 [28800/50000]\n",
      "loss: 1.088069 [32000/50000]\n",
      "loss: 1.071529 [35200/50000]\n",
      "loss: 1.321585 [38400/50000]\n",
      "loss: 1.315752 [41600/50000]\n",
      "loss: 1.189183 [44800/50000]\n",
      "loss: 0.984488 [48000/50000]\n",
      "Test Error: \n",
      " Accuracy: 64.6%, Avg loss: 1.012238 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.036134 [    0/50000]\n",
      "loss: 1.271780 [ 3200/50000]\n",
      "loss: 1.051204 [ 6400/50000]\n",
      "loss: 1.305203 [ 9600/50000]\n",
      "loss: 0.910613 [12800/50000]\n",
      "loss: 1.084792 [16000/50000]\n",
      "loss: 1.473584 [19200/50000]\n",
      "loss: 0.682623 [22400/50000]\n",
      "loss: 1.113206 [25600/50000]\n",
      "loss: 0.857994 [28800/50000]\n",
      "loss: 1.037140 [32000/50000]\n",
      "loss: 1.104421 [35200/50000]\n",
      "loss: 1.164306 [38400/50000]\n",
      "loss: 1.189273 [41600/50000]\n",
      "loss: 0.871097 [44800/50000]\n",
      "loss: 0.958671 [48000/50000]\n",
      "Test Error: \n",
      " Accuracy: 68.5%, Avg loss: 0.891371 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.975004 [    0/50000]\n",
      "loss: 1.130918 [ 3200/50000]\n",
      "loss: 1.548941 [ 6400/50000]\n",
      "loss: 0.886689 [ 9600/50000]\n",
      "loss: 0.995147 [12800/50000]\n",
      "loss: 0.895095 [16000/50000]\n",
      "loss: 1.183009 [19200/50000]\n",
      "loss: 0.837271 [22400/50000]\n",
      "loss: 0.936325 [25600/50000]\n",
      "loss: 0.673611 [28800/50000]\n",
      "loss: 0.979491 [32000/50000]\n",
      "loss: 0.880907 [35200/50000]\n",
      "loss: 0.604494 [38400/50000]\n",
      "loss: 0.977740 [41600/50000]\n",
      "loss: 1.101597 [44800/50000]\n",
      "loss: 0.884151 [48000/50000]\n",
      "Test Error: \n",
      " Accuracy: 71.3%, Avg loss: 0.823306 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.003739 [    0/50000]\n",
      "loss: 1.086779 [ 3200/50000]\n",
      "loss: 1.189330 [ 6400/50000]\n",
      "loss: 0.759742 [ 9600/50000]\n",
      "loss: 0.939993 [12800/50000]\n",
      "loss: 0.895609 [16000/50000]\n",
      "loss: 0.944807 [19200/50000]\n",
      "loss: 0.834787 [22400/50000]\n",
      "loss: 0.968191 [25600/50000]\n",
      "loss: 0.711076 [28800/50000]\n",
      "loss: 0.815389 [32000/50000]\n",
      "loss: 0.955289 [35200/50000]\n",
      "loss: 0.659676 [38400/50000]\n",
      "loss: 0.967231 [41600/50000]\n",
      "loss: 0.727657 [44800/50000]\n",
      "loss: 0.972221 [48000/50000]\n",
      "Test Error: \n",
      " Accuracy: 71.3%, Avg loss: 0.804775 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.886591 [    0/50000]\n",
      "loss: 0.538677 [ 3200/50000]\n",
      "loss: 0.562074 [ 6400/50000]\n",
      "loss: 0.966337 [ 9600/50000]\n",
      "loss: 1.044207 [12800/50000]\n",
      "loss: 0.973160 [16000/50000]\n",
      "loss: 0.672071 [19200/50000]\n",
      "loss: 0.450063 [22400/50000]\n",
      "loss: 0.890153 [25600/50000]\n",
      "loss: 0.705478 [28800/50000]\n",
      "loss: 1.041809 [32000/50000]\n",
      "loss: 0.700165 [35200/50000]\n",
      "loss: 1.027937 [38400/50000]\n",
      "loss: 0.867272 [41600/50000]\n",
      "loss: 0.779083 [44800/50000]\n",
      "loss: 1.190265 [48000/50000]\n",
      "Test Error: \n",
      " Accuracy: 61.7%, Avg loss: 1.183880 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.703849 [    0/50000]\n",
      "loss: 0.578484 [ 3200/50000]\n",
      "loss: 0.896952 [ 6400/50000]\n",
      "loss: 0.630144 [ 9600/50000]\n",
      "loss: 0.535721 [12800/50000]\n",
      "loss: 0.480660 [16000/50000]\n",
      "loss: 0.680005 [19200/50000]\n",
      "loss: 0.729466 [22400/50000]\n",
      "loss: 0.883163 [25600/50000]\n",
      "loss: 0.558676 [28800/50000]\n",
      "loss: 0.599313 [32000/50000]\n",
      "loss: 0.793939 [35200/50000]\n",
      "loss: 0.550433 [38400/50000]\n",
      "loss: 0.623255 [41600/50000]\n",
      "loss: 0.797313 [44800/50000]\n",
      "loss: 0.595259 [48000/50000]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 0.666337 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.506524 [    0/50000]\n",
      "loss: 0.453328 [ 3200/50000]\n",
      "loss: 0.525792 [ 6400/50000]\n",
      "loss: 0.882826 [ 9600/50000]\n",
      "loss: 0.671233 [12800/50000]\n",
      "loss: 0.763535 [16000/50000]\n",
      "loss: 0.871566 [19200/50000]\n",
      "loss: 0.930107 [22400/50000]\n",
      "loss: 0.940962 [25600/50000]\n",
      "loss: 0.722888 [28800/50000]\n",
      "loss: 0.607994 [32000/50000]\n",
      "loss: 0.605871 [35200/50000]\n",
      "loss: 0.722438 [38400/50000]\n",
      "loss: 0.839414 [41600/50000]\n",
      "loss: 0.540742 [44800/50000]\n",
      "loss: 0.687834 [48000/50000]\n",
      "Test Error: \n",
      " Accuracy: 77.4%, Avg loss: 0.655852 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for i in range(EPOCH):\n",
    "    print(f'Epoch {i + 1}\\n-------------------------------')\n",
    "    train(train_loader, model, loss, optimizer)\n",
    "    test(test_loader, model, loss)\n",
    "print('Done!')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR Classifier(Pretrained VGGNet)\n",
    "\n",
    "- ImageNet 데이터로 학습한 VGGNet을 사용하여 주어진 데이터 셋에서 사용할 수 있도록 Fine tuning 해봅니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/woojin/miniforge3/envs/pytorch/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/woojin/miniforge3/envs/pytorch/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /Users/woojin/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "\n",
    "vgg16 = models.vgg16(pretrained=True)\n",
    "vgg16.to(DEVICE)\n",
    "print(vgg16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16.classifier[6].out_features = 10       # output 1000 -> 10\n",
    "\n",
    "for param in vgg16.features.parameters():\n",
    "    param.requires_grad = False             # gradient 계산 X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(vgg16.classifier.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 12.551889 [    0/50000]\n",
      "loss: 3.251927 [ 3200/50000]\n",
      "loss: 2.015601 [ 6400/50000]\n",
      "loss: 1.694982 [ 9600/50000]\n",
      "loss: 1.599399 [12800/50000]\n",
      "loss: 1.391162 [16000/50000]\n",
      "loss: 1.288280 [19200/50000]\n",
      "loss: 1.563966 [22400/50000]\n",
      "loss: 1.057321 [25600/50000]\n",
      "loss: 1.063684 [28800/50000]\n",
      "loss: 0.966865 [32000/50000]\n",
      "loss: 0.902289 [35200/50000]\n",
      "loss: 1.260174 [38400/50000]\n",
      "loss: 0.836121 [41600/50000]\n",
      "loss: 0.915865 [44800/50000]\n",
      "loss: 1.167854 [48000/50000]\n",
      "Test Error: \n",
      " Accuracy: 73.7%, Avg loss: 0.767432 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.862775 [    0/50000]\n",
      "loss: 0.809094 [ 3200/50000]\n",
      "loss: 0.946023 [ 6400/50000]\n",
      "loss: 0.912410 [ 9600/50000]\n",
      "loss: 0.963073 [12800/50000]\n",
      "loss: 0.619301 [16000/50000]\n",
      "loss: 0.768700 [19200/50000]\n",
      "loss: 0.891546 [22400/50000]\n",
      "loss: 0.648050 [25600/50000]\n",
      "loss: 1.146434 [28800/50000]\n",
      "loss: 0.665186 [32000/50000]\n",
      "loss: 0.562400 [35200/50000]\n",
      "loss: 0.843945 [38400/50000]\n",
      "loss: 1.079673 [41600/50000]\n",
      "loss: 0.888187 [44800/50000]\n",
      "loss: 0.812347 [48000/50000]\n",
      "Test Error: \n",
      " Accuracy: 77.8%, Avg loss: 0.643073 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.367058 [    0/50000]\n",
      "loss: 0.653353 [ 3200/50000]\n",
      "loss: 0.980735 [ 6400/50000]\n",
      "loss: 0.938255 [ 9600/50000]\n",
      "loss: 0.614310 [12800/50000]\n",
      "loss: 0.543033 [16000/50000]\n",
      "loss: 0.469733 [19200/50000]\n",
      "loss: 1.027917 [22400/50000]\n",
      "loss: 0.746783 [25600/50000]\n",
      "loss: 0.600267 [28800/50000]\n",
      "loss: 0.561824 [32000/50000]\n",
      "loss: 0.644689 [35200/50000]\n",
      "loss: 0.597315 [38400/50000]\n",
      "loss: 0.745601 [41600/50000]\n",
      "loss: 0.644098 [44800/50000]\n",
      "loss: 0.625817 [48000/50000]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.590331 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.518476 [    0/50000]\n",
      "loss: 0.378717 [ 3200/50000]\n",
      "loss: 0.802022 [ 6400/50000]\n",
      "loss: 0.619966 [ 9600/50000]\n",
      "loss: 0.529941 [12800/50000]\n",
      "loss: 0.762587 [16000/50000]\n",
      "loss: 0.704586 [19200/50000]\n",
      "loss: 0.967372 [22400/50000]\n",
      "loss: 0.577320 [25600/50000]\n",
      "loss: 0.443077 [28800/50000]\n",
      "loss: 0.751990 [32000/50000]\n",
      "loss: 0.668731 [35200/50000]\n",
      "loss: 0.651883 [38400/50000]\n",
      "loss: 0.644465 [41600/50000]\n",
      "loss: 0.793157 [44800/50000]\n",
      "loss: 0.807363 [48000/50000]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.557484 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.399704 [    0/50000]\n",
      "loss: 0.819490 [ 3200/50000]\n",
      "loss: 0.654437 [ 6400/50000]\n",
      "loss: 0.546814 [ 9600/50000]\n",
      "loss: 0.743176 [12800/50000]\n",
      "loss: 0.523762 [16000/50000]\n",
      "loss: 0.594274 [19200/50000]\n",
      "loss: 0.903840 [22400/50000]\n",
      "loss: 0.505423 [25600/50000]\n",
      "loss: 0.522826 [28800/50000]\n",
      "loss: 0.812536 [32000/50000]\n",
      "loss: 0.529534 [35200/50000]\n",
      "loss: 0.583041 [38400/50000]\n",
      "loss: 0.564870 [41600/50000]\n",
      "loss: 0.753209 [44800/50000]\n",
      "loss: 0.445503 [48000/50000]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.532553 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.406367 [    0/50000]\n",
      "loss: 0.557821 [ 3200/50000]\n",
      "loss: 0.497418 [ 6400/50000]\n",
      "loss: 0.625698 [ 9600/50000]\n",
      "loss: 0.577922 [12800/50000]\n",
      "loss: 0.483559 [16000/50000]\n",
      "loss: 0.627002 [19200/50000]\n",
      "loss: 0.257869 [22400/50000]\n",
      "loss: 0.896474 [25600/50000]\n",
      "loss: 0.699979 [28800/50000]\n",
      "loss: 0.570925 [32000/50000]\n",
      "loss: 0.505905 [35200/50000]\n",
      "loss: 0.592381 [38400/50000]\n",
      "loss: 0.693560 [41600/50000]\n",
      "loss: 0.708898 [44800/50000]\n",
      "loss: 0.411110 [48000/50000]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.518659 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.289619 [    0/50000]\n",
      "loss: 0.760793 [ 3200/50000]\n",
      "loss: 0.338680 [ 6400/50000]\n",
      "loss: 0.369775 [ 9600/50000]\n",
      "loss: 0.666455 [12800/50000]\n",
      "loss: 0.760341 [16000/50000]\n",
      "loss: 0.437817 [19200/50000]\n",
      "loss: 0.514092 [22400/50000]\n",
      "loss: 0.821135 [25600/50000]\n",
      "loss: 0.665979 [28800/50000]\n",
      "loss: 0.691077 [32000/50000]\n",
      "loss: 0.848893 [35200/50000]\n",
      "loss: 0.547819 [38400/50000]\n",
      "loss: 0.422730 [41600/50000]\n",
      "loss: 0.574299 [44800/50000]\n",
      "loss: 0.570477 [48000/50000]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.500911 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.619968 [    0/50000]\n",
      "loss: 0.546882 [ 3200/50000]\n",
      "loss: 0.711823 [ 6400/50000]\n",
      "loss: 0.291947 [ 9600/50000]\n",
      "loss: 0.469292 [12800/50000]\n",
      "loss: 0.798354 [16000/50000]\n",
      "loss: 0.572497 [19200/50000]\n",
      "loss: 0.489704 [22400/50000]\n",
      "loss: 0.579881 [25600/50000]\n",
      "loss: 0.536800 [28800/50000]\n",
      "loss: 0.582412 [32000/50000]\n",
      "loss: 0.274493 [35200/50000]\n",
      "loss: 0.452298 [38400/50000]\n",
      "loss: 0.656593 [41600/50000]\n",
      "loss: 0.471702 [44800/50000]\n",
      "loss: 0.284319 [48000/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.486435 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.306264 [    0/50000]\n",
      "loss: 0.517316 [ 3200/50000]\n",
      "loss: 0.147796 [ 6400/50000]\n",
      "loss: 0.782775 [ 9600/50000]\n",
      "loss: 0.597739 [12800/50000]\n",
      "loss: 0.455240 [16000/50000]\n",
      "loss: 0.294752 [19200/50000]\n",
      "loss: 0.535950 [22400/50000]\n",
      "loss: 0.431469 [25600/50000]\n",
      "loss: 0.599694 [28800/50000]\n",
      "loss: 0.588076 [32000/50000]\n",
      "loss: 0.435909 [35200/50000]\n",
      "loss: 0.571549 [38400/50000]\n",
      "loss: 0.388567 [41600/50000]\n",
      "loss: 0.798080 [44800/50000]\n",
      "loss: 0.759393 [48000/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.477310 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.868609 [    0/50000]\n",
      "loss: 0.343132 [ 3200/50000]\n",
      "loss: 0.443719 [ 6400/50000]\n",
      "loss: 0.553001 [ 9600/50000]\n",
      "loss: 0.551024 [12800/50000]\n",
      "loss: 0.738250 [16000/50000]\n",
      "loss: 0.445638 [19200/50000]\n",
      "loss: 0.353950 [22400/50000]\n",
      "loss: 0.495839 [25600/50000]\n",
      "loss: 0.410938 [28800/50000]\n",
      "loss: 0.348409 [32000/50000]\n",
      "loss: 0.443065 [35200/50000]\n",
      "loss: 0.653950 [38400/50000]\n",
      "loss: 0.495564 [41600/50000]\n",
      "loss: 0.593821 [44800/50000]\n",
      "loss: 0.460965 [48000/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.468224 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for i in range(EPOCH):\n",
    "    print(f'Epoch {i + 1}\\n-------------------------------')\n",
    "    train(train_loader, vgg16, loss, optimizer)\n",
    "    test(test_loader, vgg16, loss)\n",
    "print('Done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
