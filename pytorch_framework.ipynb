{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyOj4Hrd+1WeVigU34CI+l1D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahn283/finance/blob/main/pytorch_framework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <b>1. 파이토치(PyTorch) 개요</b>\n",
        "\n",
        "* PyTorch는 기계 학습 프레임워크(framework) 중 하나다.\n",
        "  * PyTorch의 텐서(tensor)는 NumPy 배열과 매우 유사하다.\n",
        "* PyTorch를 사용하면, GPU 연동을 통해 효율적으로 딥러닝 모델을 학습할 수 있다.\n",
        "* Google Colab을 이용하면, 손쉽게 PyTorch를 시작할 수 있다.\n",
        "* Google Colab에서는 <b>[런타임]</b> - <b>[런타임 유형 변경]</b>에서 <b>GPU를 선택</b>할 수 있다."
      ],
      "metadata": {
        "id": "YZNF7RXlxzI1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDiVpSrAxwaB"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <b>1) GPU 사용 여부 체크하기</b>\n",
        "\n",
        "* 텐서간의 연산을 수행할 때, 기본적으로 두 텐서가 같은 장치에 있어야 한다.\n",
        "* 따라서 가능하면, 연산을 수행하는 텐서들을 모두 GPU에 올린 뒤에 연산을 수행한다."
      ],
      "metadata": {
        "id": "plj1cLf17nio"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "    [1, 2],\n",
        "    [3, 4]\n",
        "]\n",
        "\n",
        "x = torch.tensor(data)\n",
        "print(x.is_cuda)"
      ],
      "metadata": {
        "id": "YGss_gEJ7sZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU 로 옮기기\n",
        "x = x.cuda()\n",
        "print(x.is_cuda)"
      ],
      "metadata": {
        "id": "qjU3ndcU7z2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CPU 로 옮기기\n",
        "x = x.cpu()\n",
        "print(x.is_cuda)"
      ],
      "metadata": {
        "id": "DUY5N0el75er"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* <b>서로 다른 장치(device)</b>에 있는 텐서끼리 연산을 수행하면 오류가 발생한다."
      ],
      "metadata": {
        "id": "dj2ba_fq9ivx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tensor on GPU\n",
        "a = torch.tensor([\n",
        "    [1, 1],\n",
        "    [2, 2]\n",
        "]).cuda()\n",
        "\n",
        "# tensor on CPU\n",
        "b = torch.tensor([\n",
        "    [5, 6],\n",
        "    [7, 8]\n",
        "])\n",
        "# print(torch.matmul(a, b))   # error\n",
        "print(torch.matmul(a.cpu(), b))"
      ],
      "metadata": {
        "id": "3htN1GuU9hd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <b>2. 텐서 소개 및 생성 방법</b>\n",
        "\n",
        "* PyTorch에서의 텐서(tensor)는 기능적으로 넘파이(NumPy)와 매우 유사하다.\n",
        "* 기본적으로 <b>다차원 배열</b>을 처리하기에 적합한 자료구조로 이해할 수 있다.\n",
        "* PyTorch의 텐서는 \"자동 미분\" 기능을 제공한다."
      ],
      "metadata": {
        "id": "pny6OVoF9_6G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <b>1) 텐서의 속성</b>\n",
        "\n",
        "* 텐서의 <b>기본 속성</b>으로는 다음과 같은 것들이 있다.\n",
        "  * 모양(shape)\n",
        "  * 자료형(data type)\n",
        "  * 저장된 장치"
      ],
      "metadata": {
        "id": "LTyH4fMW-Wh3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.rand(3, 4)\n",
        "\n",
        "print(tensor)\n",
        "print(f'shape: {tensor.shape}')\n",
        "print(f'Data type: {tensor.dtype}')\n",
        "print(f'Device: {tensor.device}')"
      ],
      "metadata": {
        "id": "5HCpE8DU9-Hk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <b>2) 텐서 초기화</b>\n",
        "\n",
        "* 리스트 데이터에서 직접 텐서를 초기화할 수 있다."
      ],
      "metadata": {
        "id": "qtyK5sEC-ZXD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "    [1, 2],\n",
        "    [3, 4]\n",
        "]\n",
        "x = torch.tensor(data)\n",
        "print(x)"
      ],
      "metadata": {
        "id": "MvpbpufS-SUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* NumPy 배열에서 텐서를 초기화할 수 있다."
      ],
      "metadata": {
        "id": "b0CM5XuK-g9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([5])\n",
        "b = torch.tensor([7])\n",
        "\n",
        "c = (a + b).numpy()\n",
        "print(c)\n",
        "print(type(c))\n",
        "\n",
        "result = c * 10\n",
        "tensor = torch.from_numpy(result)\n",
        "print(tensor)\n",
        "print(type(tensor))"
      ],
      "metadata": {
        "id": "jXuHVMBt94iN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <b>3) 다른 텐서로부터 텐서 초기화하기</b>\n",
        "\n",
        "* 다른 텐서의 정보를 토대로 텐서를 초기화할 수 있다.\n",
        "* <b>텐서의 속성</b>: 모양(shape), 자료형(data type)"
      ],
      "metadata": {
        "id": "NCD-0DrK-yaR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([\n",
        "    [5, 7],\n",
        "    [1, 2]\n",
        "])\n",
        "\n",
        "# x와 같은 모양과 자료형을 가지지만, 값이 1인 텐서 생성\n",
        "x_ones = torch.ones_like(x)\n",
        "print(x_ones)\n",
        "# x와 같은 모양을 가지되, 자료형은 float으로 덮어쓰고, 값은 랜덤으로 채우기\n",
        "x_rand = torch.rand_like(x, dtype=torch.float32)  # uniform distribution [0, 1)\n",
        "print(x_rand)"
      ],
      "metadata": {
        "id": "x-H6mKsM-vxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <b>3. 텐서의 형변환 및 차원 조작</b>\n",
        "\n",
        "* 텐서는 넘파이(NumPy) 배열처럼 조작할 수 있다."
      ],
      "metadata": {
        "id": "pppS_sStZ6vA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <b>1) 텐서의 특정 차원 접근하기</b>\n",
        "\n",
        "* 텐서의 원하는 차원에 접근할 수 있다."
      ],
      "metadata": {
        "id": "6CICHIdAaOIu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.tensor([\n",
        "    [1, 2, 3, 4],\n",
        "    [5, 6, 7, 8],\n",
        "    [9, 10, 11, 12]\n",
        "])\n",
        "\n",
        "print(tensor[0])  # first row\n",
        "print(tensor[:, 0])   # first column\n",
        "print(tensor[..., -1])  # last column"
      ],
      "metadata": {
        "id": "9g9oBlXlaQxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <b>2) 텐서 이어붙이기(Concatenate)</b>\n",
        "\n",
        "* 두 텐서를 이어 붙여 연결하여 새로운 텐서를 만들 수 있다."
      ],
      "metadata": {
        "id": "RF9mwzQHa_Si"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.tensor([\n",
        "    [1, 2, 3, 4],\n",
        "    [5, 6, 7, 8],\n",
        "    [9, 10, 11, 12]\n",
        "])\n",
        "\n",
        "# dim: 텐서를 이어 붙이기 위한 축\n",
        "# 0번 축(행)을 기준으로 이어 붙이기\n",
        "result = torch.cat([tensor, tensor, tensor], dim=0)\n",
        "print(result)\n",
        "\n",
        "# 1번 축(열)을 기준으로 이어 붙이기\n",
        "result = torch.cat([tensor, tensor, tensor], dim=1)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "hxm4XrwbbFGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <b>3) 텐서 형변환(Type Casting)</b>\n",
        "\n",
        "* 텐서의 자료형(정수, 실수 등)을 변환할 수 있다."
      ],
      "metadata": {
        "id": "bRTR-cTEcqYe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([2], dtype=torch.int)\n",
        "b = torch.tensor([5.0])\n",
        "\n",
        "print(a.type)\n",
        "print(b.type)\n",
        "\n",
        "# 텐서 a는 자동으로 float32형으로 형변환 처리\n",
        "print(a + b)\n",
        "# 텐서 b를 int32형으로 형변환하여 덧셈 수행\n",
        "print(a + b.type(torch.int32))"
      ],
      "metadata": {
        "id": "knQlu8awbp6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <b>4) 텐서의 모양 변경</b>\n",
        "\n",
        "* view()는 텐서의 모양을 변경할 때 사용한다.\n",
        "* 이때, 텐서(tensor)의 순서는 변경되지 않는다."
      ],
      "metadata": {
        "id": "e5W2aHsKdJ5x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# view()는 텐서의 모양을 변경할 때 사용한다.\n",
        "# 이 때, 텐서(tensor)의 순서는 변경되지 않는다.\n",
        "a = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8])\n",
        "b = a.view(4, 2)\n",
        "print(b)\n",
        "\n",
        "# a의 값을 변경하면 b도 변경\n",
        "a[0] = 7\n",
        "print(b)\n",
        "\n",
        "# a의 값을 복사(copy)한 뒤에 변경\n",
        "c = a.clone().view(4, 2)\n",
        "a[0] = 9\n",
        "print(c)"
      ],
      "metadata": {
        "id": "m8k91NuQdHpn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <b>5) 텐서의 차원 교환</b>\n",
        "\n",
        "* 하나의 텐서에서 특정한 차원끼리 순서를 교체할 수 있다."
      ],
      "metadata": {
        "id": "D5GMwtmJduAQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.rand((64, 32, 3))\n",
        "print(a.shape)\n",
        "\n",
        "b = a.permute(2, 1, 0)   # 차원 자체를 교환 (3번째 차원, 2번째 차원, 1번째 차원)\n",
        "# (2번째 축, 1번째 축, 0번째 축)의 형태가 되도록 한다.\n",
        "print(b.shape)"
      ],
      "metadata": {
        "id": "pzy62NKldq13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <b>4. 텐서의 연산과 함수</b>"
      ],
      "metadata": {
        "id": "akpIfLtQeIw5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <b>1) 텐서의 연산</b>\n",
        "\n",
        "* 텐서에 대하여 사칙연산 등 기본적인 연산을 수행할 수 있다."
      ],
      "metadata": {
        "id": "FSYgeiRpeL_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 같은 크기를 가진 두 개의 텐서에 대해서 사칙연산 가능\n",
        "# 기본적으로 요소별(element-wise) 연산\n",
        "a = torch.tensor([\n",
        "    [1, 2],\n",
        "    [3, 4]\n",
        "])\n",
        "b = torch.tensor([\n",
        "    [5, 6],\n",
        "    [7, 8]\n",
        "])\n",
        "print(a + b)\n",
        "print(a - b)\n",
        "print(a * b)\n",
        "print(a / b)"
      ],
      "metadata": {
        "id": "ekusdf1aeHZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 행렬 곱을 수행할 수 있다."
      ],
      "metadata": {
        "id": "cpNTWZvHesT8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([\n",
        "    [1, 2],\n",
        "    [3, 4]\n",
        "])\n",
        "b = torch.tensor([\n",
        "    [5, 6],\n",
        "    [7, 8]\n",
        "])\n",
        "\n",
        "# 행렬 곱(matrix multiplication) 수행\n",
        "print(a.matmul(b))\n",
        "print(torch.matmul(a, b))"
      ],
      "metadata": {
        "id": "ZZSz6gqDem8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <b>2) 텐서의 평균 함수</b>\n",
        "\n",
        "* 텐서의 평균(mean)을 계산할 수 있다."
      ],
      "metadata": {
        "id": "ig2yIxy0fBWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.Tensor([\n",
        "    [1, 2, 3, 4],\n",
        "    [5, 6, 7, 8]\n",
        "])\n",
        "\n",
        "print(a)\n",
        "print(a.mean())   # 전체 원소에 대한 평균\n",
        "print(a.mean(dim=0))  # 각 열에 대하여 평균 계산\n",
        "print(a.mean(dim=1))  # 각 행에 대하여 평균 계산"
      ],
      "metadata": {
        "id": "0T_BhYmmfARs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <b>4) 텐서의 최대 함수</b>\n",
        "\n",
        "* <b>max() 함수</b>는 원소의 최댓값을 반환한다.\n",
        "* <b>argmax() 함수</b>는 가장 큰 원소(최댓값)의 인덱스를 반환한다."
      ],
      "metadata": {
        "id": "pJn0zso4flyp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.Tensor([\n",
        "    [1, 2, 3, 4],\n",
        "    [5, 6, 7, 8]\n",
        "])\n",
        "\n",
        "print(a)\n",
        "print(a.max())  # 전체 원소에 대한 최대값\n",
        "print(a.max(dim=0)) # 각 열에 대하여 최대값 계산\n",
        "print(a.max(dim=1)) # 각 행에 대하여 최대값 계산"
      ],
      "metadata": {
        "id": "BozQP7tHfaIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.Tensor([\n",
        "    [1, 2, 3, 4],\n",
        "    [5, 6, 7, 8]\n",
        "])\n",
        "print(a)\n",
        "print(a.argmax()) # 전체 원소에 대한 최대값의 인덱스\n",
        "print(a.argmax(dim=0))  # 각 열에 대하여 최대값의 인덱스 계산\n",
        "print(a.argmax(dim=1))  # 각 행에 대하여 최대값의 인덱스 계산"
      ],
      "metadata": {
        "id": "LledhzjpgZtk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <b>5) 텐서의 차원 줄이기 혹은 늘리기</b>\n",
        "\n",
        "* <b>unsqueeze() 함수</b>는  크기가 1인 차원을 추가한다.\n",
        "  * 배치(batch) 차원을 추가하기 위한 목적으로 흔히 사용된다.\n",
        "* <b>squeeze() 함수</b>는 크기가 1인 차원을 제거한다."
      ],
      "metadata": {
        "id": "_GmRQxG5g81z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.Tensor([\n",
        "    [1, 2, 3, 4],\n",
        "    [5, 6, 7, 8]\n",
        "])\n",
        "print(a.shape)\n",
        "\n",
        "# 첫 번째 축에 차원 추가\n",
        "a = a.unsqueeze(0)\n",
        "print(a)\n",
        "\n",
        "# 네 번째 축에 차원 추가\n",
        "a = a.unsqueeze(3)\n",
        "print(a)\n",
        "print(a.shape)"
      ],
      "metadata": {
        "id": "i8Jdh5zPg6X5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 크기가 1인 차원 제거\n",
        "print(a.shape)\n",
        "a = a.squeeze()\n",
        "print(a)\n",
        "print(a.shape)"
      ],
      "metadata": {
        "id": "81zj-pcLfOHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <b>5. 자동 미분과 기울기(Gradient)</b>\n",
        "\n",
        "* PyTorch에서는 연산에 대하여 자동 미분을 수행할 수 있다."
      ],
      "metadata": {
        "id": "-AiAMSUpiZs0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# requires_grad를 설정할 때만 기울기 추적\n",
        "x = torch.tensor([3.0, 4.0], requires_grad=True)\n",
        "y = torch.tensor([1.0, 2.0], requires_grad=True)\n",
        "z = x + y \n",
        "\n",
        "print(z)  # [4.0, 6.0]\n",
        "print(z.grad_fn) # 더하기(add)\n",
        "\n",
        "out = z.mean()\n",
        "print(out)  # 5.0\n",
        "print(out.grad_fn)  # 평균(mean)\n",
        "\n",
        "out.backward()  # sclar에 대하여 가능\n",
        "print(x.grad)\n",
        "print(y.grad)\n",
        "print(z.grad)   # leat variable에 대해서만 gradient 추적이 가능하다. 따라서 None."
      ],
      "metadata": {
        "id": "vFzcMn7whnFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 일반적으로 모델을 학습할 때는 <b>기울기(gradient)를 추적</b>한다.\n",
        "* 하지만, 학습된 모델을 사용할 때는 파라미터를 업데이트하지 않으므로, 기울기를 추적하지 않는 것이 일반적이다."
      ],
      "metadata": {
        "id": "peB36qS6jqJS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp = torch.tensor([3.0, 4.0], requires_grad=True)\n",
        "print(temp.requires_grad)\n",
        "print((temp ** 2).requires_grad)\n",
        "\n",
        "# 기울기 추적을 하지 않기 때문에 계산 속도가 더 빠르다.\n",
        "with torch.no_grad():\n",
        "  temp = torch.tensor([3.0, 4.0], requires_grad=True)\n",
        "  print(temp.requires_grad)\n",
        "  print((temp ** 2).requires_grad)"
      ],
      "metadata": {
        "id": "Hdq9i_iwi3KW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}