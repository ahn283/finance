{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 알고리즘의 발전방향"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 통계추론에서 기계학습/딥러닝학습으로\n",
    "\n",
    "\"데이터 과학은 크게 2가지 관점으로 발전\"\n",
    "\n",
    "- 통계학 (inferential statistics)\n",
    "\n",
    "    - 데이터 과학의근간\n",
    "\n",
    "    - 통계학 기반의 다양한 기능들은 딥러닝, 패턴인식, 기계학습 등에서 사용중\n",
    "\n",
    "- 컴퓨터 공학 (computer science)\n",
    "    \n",
    "    - 부품 가격 절하와 성능 향상은 분석 성능에 영향\n",
    "\n",
    "    - 통계학에 컴퓨터 공학적인 접근을 받아들이게 하고, 통계와 기계학습 영역이 결합되어 시너지를 이루게 됨"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 통계학습(Statistical Learning) vs 기계학습(Machine Learning) : 알고리즘 생성 방식\n",
    "\n",
    "![](img/StatisticsMachineLearning.png)",
    "<img src='img/StatisticsMachineLearning.png'>\n",
    "\n",
    "\"데이터를 통해 문제 해결한다는 점은 일맥상통하나, 해결하는 목표/전략/방식에 대한 출발점이 다르며 점차 경계가 모호해지고 있음\"\n",
    "\n",
    "|| 통계학습(Statistical Learning) | 기계학습(Machine Learning) |\n",
    "|:---: |:---: |:---: | \n",
    "| 이론적 배경 | 통계학 | 컴퓨터과학 | \n",
    "| 발전 기반 | 통계학, 수치해석 등 | 패턴인식, 인공지능 등 | \n",
    "| 모형 구조 | 대부분 화이트박스 | 대부분 블랙박스 | \n",
    "| 관심 목적 | 설명력, 실패위험 줄이기 | 정확성, 성공확률 높이기 |\n",
    "| 주 사용 데이터 | 관측치 및 변수가 적은 경우 | 관측치 및 변수가 많은 경우 | \n",
    "| 상황/가정 반영 | 의존적 (독립성, 정규성, 등분산성 등) | 독립적 (대부분 무시) | \n",
    "| 학습 방법 | 데이터에 맞게 최적화 중점 | 반복학습으로 모델 구축 중점 | \n",
    "| 성능 평가 | 데이터의 해석과 가정 적합성 등 | 분할 데이터 반복 평가 | \n",
    "| 특징 | 가설(Hypothesis), 모집단(Population), 표분(Sample)에 기반하여 데이터를 기술(Descriptive)하거나 추론(Inference)하는데 이용 | 예측력(Prediction) 중심의 다양한 문제 해결을 위한 지도(Supervised), 비지도(Unsupervised), 강화학습(Reinforcement) 등의 방법론 구축에 이용 | \n",
    "| 문제 예시 | 대기오염과 호흡기 질환의 관계, 배너위치에 따른 컨텐츠 클릭 빈도 변화, 신규 장비의 불량률 감소 효과 분석, 임상을 통한 신약의 효능 분석 | 이미지 데이터의 객체 구분, 상황이나 사물인식 성능 향상, 음성인식을 통한 AI스피커 성능 향상, MRI데이터 사용 암 환자 조기 진단 |\n",
    "\n",
    "<img src='img/DL_AutoFE.PNG'>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정확성 vs 설명력\n",
    "\n",
    "#### 1) 기계학습 활용 데이터 분석의 현실\n",
    "\n",
    "<b>\"이상적으로 머신러닝 알고리즘에 데이터를 학습/적합/모델링 한다는 건...\"</b>\n",
    "\n",
    "(1) 사람/사물/시스템이 어떻게 동작하는지 이해의 과점\n",
    "\n",
    "(2) 사람/사물/시스템이 만들어내는 데이터를 체계적으로 요약하는 과정\n",
    "\n",
    "(3) 미래의 예측값과 실제값의 비교로 사람/사물/시스템을 일반화하는 과정\n",
    "\n",
    "(4) 일반화된 사람/사물/시스템으로 더욱 효과적이고 체계적인 의사결정 하는 방법\n",
    "\n",
    "<b>(현실적으로) 많은 시간과 비용이 투입되지만, 우리 사회를 이해((1),(2),(3)) <<< 빠른 의사결정(4)에 집중</b>\n",
    "\n",
    "- 사회를 이해하기 위한 사회학/교육학/철학/경제학 등의 학문은 ((1),(2),(3))에 집중\n",
    "\n",
    "- 경영과학/컴퓨터과학/산업공학 등의 학문은 기술적인 자동화나 인공지능을 반영하는 (4)에 집중\n",
    "\n",
    "- 학문적 출신에 따라 분석에 대한 관점 차이 또는 비즈니스 방향 차이가 존재할 수 있음\n",
    "\n",
    "<img src='img/Programming_Multidisciplinary.png'>\n",
    "\n",
    "#### 2) 정확성 vs 설명력은 모두 욕심낼 수 없는 반비례 관계\n",
    "\n",
    "- 대부분의 기계학습 및 딥러닝 모델은 이론적 기반이 없기 때문에 1회성 추정을 반복하는 알고리즘\n",
    "\n",
    "- 통계추론은 이론적 기반의 결과와 범위(신뢰구간)와 설명력을 제공하기에 반복추정이 필요없는 알고리즘\n",
    "\n",
    "<img src='img/Performance_Explanability.png'>\n",
    "\n",
    "#### 3) 반비례 관계 원인 : 회귀분석(통계학습) vs 딥러닝(기계학습)\n",
    "\n",
    "- 회귀분석(통계학습) : 함수의 선형성을 추정하는 정확성보다 설명력에 집중하는 알고리즘\n",
    "- 딥러닝(기계학습) : 함수의 비선형성을 추정하는 설명력보다 정확성에 집중하는 알고리즘\n",
    "\n",
    "| -                            | **회귀분석**                                            | **딥러닝**                                   |\n",
    "|----------------------------- |:----------------------------------- |:----------------------------------- |\n",
    "| **모델특징**                 | -                                                       | -                                                      |\n",
    "| 분석목적                     | 선형성파악(설명가능)                                    | 비선형성파악(설명불가)                                 |\n",
    "| 이론적(수학적) 근거          | 존재                                                    | 미존재                                                 |\n",
    "| **분석단계 특징(전처리)**    | -                                                       | -                                                      |\n",
    "| 데이터 로딩                  | <span style=\"color:blue\">Panel Data</span>              | <span style=\"color:red\">다양(운이좋으면 Panel)</span>  |\n",
    "| 데이터 빈칸 채우기/삭제      | <span style=\"color:red\">분석필요</span>                 | <span style=\"color:red\">분석필요</span>                |\n",
    "| 데이터 컬럼 추가/삭제        | <span style=\"color:red\">분석필요+민감</span>            | <span style=\"color:red\">분석필요+덜민감</span>         |\n",
    "| 데이터 분리                  | <span style=\"color:blue\">Train/Validate/Test</span>     | <span style=\"color:blue\">Train/Validate/Test</span>    |\n",
    "| 데이터 스케일링              | <span style=\"color:red\">분석필요/미필요</span>          | <span style=\"color:red\">분석필요</span>                |\n",
    "| **분석단계 특징(모델링)**    | -                                                       | -                                                      |\n",
    "| 입력 확인 및 변환            | <span style=\"color:blue\">Panel Data</span>              | <span style=\"color:red\">다양(정해지지 않음)</span>     |\n",
    "| 데이터 모델연결              | <span style=\"color:blue\">자동화</span>                  | <span style=\"color:red\">반자동화</span>                |\n",
    "| 비용함수(Cost)               | <span style=\"color:blue\">최소제곱에러(MSE)</span>       | <span style=\"color:red\">다양</span>                    |\n",
    "| 추정함수(Optimizer)          | <span style=\"color:blue\">고정(미분1회 대체가능)</span>  | <span style=\"color:red\">다양(미분지속)</span>          |\n",
    "| **분석단계 특징(검증)**      | -                                                       | -                                                      |\n",
    "| 정확성지표                   | <span style=\"color:red\">다양</span>                     | <span style=\"color:red\">다양</span>                    |\n",
    "| 잔차진단활용                 | <span style=\"color:red\">가능(분석필요)</span>           | <span style=\"color:blue\">불가</span>                   |\n",
    "| **분석단계 특징(결과해석)**  | -                                                       | -                                                      |\n",
    "| 관계성 시각화/영향력 해석    | <span style=\"color:red\">가능(분석필요)</span>           | <span style=\"color:blue\">불가</span>                   |   \n",
    "\n",
    "#### 4) 실무적으로 기계학습 알고리즘의 중요성\n",
    "\n",
    "\"자동화에 집중되어 딥러닝 알고리즘을 활용하면 적용 케이스가 적고 성능향상이 낮을 수 있으며, 문제해결에 집중하면 가장 많은 활용되는 모델링은 성능과 설명력을 어느정도 확보한 기계학습 알고리즘\"\n",
    "\n",
    "<img src='img/MachineLearning_Algorithms.png'>\n",
    "\n",
    "- 통계추론과 딥러닝 가운데쯤 위치한 기계학습 알고리즘을 이해하는 것이 중요\n",
    "\n",
    "<img src='img/Advanced_Algorithms.webp'>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 알고리즘 발전 이해를 위한 비용함수 구조\n",
    "\n",
    "#### 0) 지도학습 문제해결 비교 : 회귀분석 vs 분류분석\n",
    "\n",
    "- 데이터 분석 단계는 동일히지만 비용함수나 검증지표 등에서 차이\n",
    "\n",
    "| | **Regression** | **Classification** |\n",
    "|:-:|:-|:-|\n",
    "| **분석목적** | 수치 예측 | 라벨 예측 |\n",
    "| **분석단계** |  |  |\n",
    "| <span style=\"color:blue\">전처리</span> | 동일 | 동일 |\n",
    "| <span style=\"color:red\">Base 알고리즘</span> | Linear Regression | Logistic Regression |\n",
    "| <span style=\"color:blue\">특징</span> | 선형 | 선형 |\n",
    "| <span style=\"color:red\">비용함수</span> | $(Y - \\hat{Y})^2$ | $-\\hat{Y}log(Pr(\\hat{Y}))$ $-$ $(1-\\hat{Y})log(1-Pr(\\hat{Y}))$ |\n",
    "| <span style=\"color:red\">검증지표</span> | MSE<br>     MAE<br>     RMSE<br>     MAPE<br>     R^2<br>     F검정<br>     t검정<br>     Log-Likelihood<br>     AIC<br>     BIC | Log-Likelihood<br>     Confusion Matrix<br>     Accuracy<br>     Precision<br>     Recall<br>     F1-score<br>     Classification Report<br>     ROC<br>     AUC |\n",
    "| <span style=\"color:red\">잔차진단</span> | 정규분포<br>     자기상관<br>     등분산성 | - |\n",
    "| **Advanced 알고리즘** | - Linear regression<br>     - Polynomial regression<br>     - Stepwise regression<br>     - Ridge/Lasso/ElasticNet regression<br>     - Bayesian Linear regression<br>     - Quantile regression<br>     - Decision Tree regression<br>     - Random Forest regression<br>     - Support Vector regression | - Logistic Regression<br>     - Ordinal Regression<br>     - Cox Regression<br>     - Naïve Bayes<br>     - Stochastic Gradient Descent<br>     - K-Nearest Neighbours<br>     - Decision Tree<br>     - Random Forest<br>     - Support Vector Machine |\n",
    "\n",
    "#### 1) 수학적 이해 : 비용함수(cost function) = 편항(bias) + 분산(variance) + 에러(Error)\n",
    "\n",
    "<img src='img/Bias-Variance_Structure.PNG'>\n",
    "\n",
    "\n",
    "$F$ : 정답 알고리즘, $\\hat{F}$ : 예측을 위해 데이터를 학습한 알고리즘\n",
    "\n",
    "\\begin{align*}\n",
    "\\text{Real Y} && Y &= F(x) \\\\\n",
    "\\text{Estimated Y} && \\hat{Y} &= \\hat{F}(x) + \\epsilon, ~~~ \\epsilon \\sim N(0, \\sigma^2) \\\\\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "\\text{Cost Function} && MSE &= E\\Bigl[\\bigl(Y-\\hat{Y})^2 \\Bigr] \\\\\n",
    "&& &= E\\Bigl[\\bigl(F(x)-\\hat{F}(x)-\\epsilon\\bigr)^2 \\Bigr] \\\\\n",
    "&& &= E\\Bigl[\\bigl([F(x) - \\hat{F}(x)] - \\epsilon\\bigr)^2 \\Bigr] \\\\\n",
    "&& &= E\\Bigl[\\bigl(F(x) - \\hat{F}(x)\\bigr)^2 \\Bigr] - 2 \\bigl(F(x) - \\hat{F}(x)\\bigr) E(\\epsilon) + E(\\epsilon^2) \\\\\n",
    "&& &= E\\Bigl[\\bigl(F(x) - \\hat{F}(x)\\bigr)^2 \\Bigr] + \\sigma^2 \\\\\n",
    "&& &= E\\Bigl[\\bigl(F(x) - E\\bigl[\\hat{F}(x)\\bigr] + E\\bigl[\\hat{F}(x)\\bigr] - \\hat{F}(x)\\bigr)^2 \\Bigr] + \\sigma^2 \\\\\n",
    "&& &= E\\Bigl[\\bigl(F(x) - E\\bigl[\\hat{F}(x)\\bigr] \\bigr)^2 \\Bigr] + E\\Bigl[\\bigl(E\\bigl[\\hat{F}(x)\\bigr] - \\hat{F}(x)\\bigr] \\bigr)^2 \\Bigr] + \\sigma^2 \\\\\n",
    "&& &= E\\Bigl[\\bigl(F(x) - \\bar{F}(x) \\bigr)^2 \\Bigr] + E\\Bigl[\\bigl(\\bar{F}(x) - \\hat{F}(x)\\bigr] \\bigr)^2 \\Bigr] + \\sigma^2 \\\\\n",
    "&& &= \\text{Bias}^2 \\bigl( \\hat{F}(x) \\bigr) + \\text{Variance} \\bigl( \\hat{F}(x) \\bigr) + \\text{Irreducible Natural Error}\n",
    "\\end{align*}\n",
    "\n",
    "$\\Rightarrow$ 비용함수를 줄이려면 제거하기 어려운 에러를 뺀 편향과 분산을 줄이는 것이 최선\n",
    "\n",
    "\n",
    "#### 2) 비수학적 이해 : 직관적으로 편향 + 분산이 모두 작은 경우 알고리즘 성능 Best\n",
    "\n",
    "**편향(Bias)** : 여러 번 측정된 정확성의 중심 통계량 (점추정)\n",
    "\n",
    "- 여러번 모델링을 통해 데이터를 반복 학습 및 추정했을 때, 예측값이 실제값에서 얼마나 떨어져있는지 측정\n",
    "\n",
    "- 데이터 패턴을 잘 반영했는지 측정\n",
    "\n",
    "**분산(Variance)** : 여러 번 측정된 정확성의 변동 통계량 (구간추정)\n",
    "\n",
    "- 여러 번 모델링을 통해 데이터를 반족 학습 및 추정했을 때, 실제값과 상관없이 예측값들이 퍼져있는 정도\n",
    "\n",
    "- 실제값과 관계없이 예측값들의 퍼진 정도만 의미\n",
    "\n",
    "<img src='img/Bias_Variance1.jpeg'>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 비용함수에서 편향-분산 상충관계 \n",
    "\n",
    "#### 1) **과소적합(under-fitting) vs 과대적합(over-fitting)** : 알고리즘의 복잡도가 증가할수록 overfitting 가능성 증가\n",
    "\n",
    "- **과소적합(under-fitting)** : 알고리즘의 복잡도가 낮아 데이터의 일부 패턴만 학습\n",
    "\n",
    "- **과대적합(over-fitting)** : 알고리즘의 복잡도가 높아 데이터의 모든 패턴과 에러까지 학습\n",
    "\n",
    "<img src='img/Underfitting_Overfitting.png'>\n",
    "\n",
    "<img src='img/Underfitting_Overfitting.jpg'>\n",
    "\n",
    "\n",
    "  |  \t| **Underfitting** \t| **Overfitting** \t|\n",
    "  |:---:\t|:---:\t|:---:\t|\n",
    "  | **알고리즘 복잡도** \t| 낮음 \t| 높음 \t|\n",
    "  | **특징** \t| 데이터 <span   style=\"color:red\">패턴 일부</span>만 학습 \t| 데이터 <span   style=\"color:red\">패턴 및 잡음/에러</span>까지도 학습 \t|\n",
    "  | **예측 성능** \t| <span   style=\"color:red\">높은 Bias</span> + 낮은 Variance <br> <span   style=\"color:red\">높은 Bias</span> + 높은 Variance\t| 낮은 Bias + <span   style=\"color:red\">높은 Variance</span>  <br> 높은 Bias + <span   style=\"color:red\">높은 Variance</span> \t|\n",
    "  | **예측 경향**  | `Variance 낮을 수 있고` + `Bias 증가`\t| `Bias 낮을 수 있고` + `Variance 증가`\t|\n",
    "\n",
    "<img src='img/Bias_Variance2.jpeg'>\n",
    "\n",
    "(붉은색: Target, 파란색: Predicted)\n",
    "\n",
    "#### 2) 알고리즘 복잡도와 예측 성능\n",
    "\n",
    "|  \t| **(1,1)** \t| **(2,1)** \t| **(1,2)** \t| **(2,2)** \t|\n",
    "|:---:\t|:---:\t|:---:\t|:---:\t|:---:\t|\n",
    "| **학습정도** \t| 최적 \t| 과소 \t| 과대 \t| 과소 + 과대 \t|\n",
    "| **복잡도** \t| 데이터 대비 `적절` \t| 데이터 대비 `낮음` \t| 데이터 대비 `높음` \t| 일부 데이터 `낮음` + 나머지 데이터 `높음` \t|\n",
    "| **평균-분산 이슈 표현** \t| 없음 \t| High Bias \t| High Variance \t| High Bias + High Variance \t|\n",
    "\n",
    "- 최적 알고리즘 복잡도 : Bias와 Variance가 최소가 되는 복잡도 수준의 알고리즘 모델링 선택\n",
    "\n",
    "- 평균-분산 상충관계(Bias-variance trade-off) : 복잡도가 증가할 수록 Bias는 감소하나 variance가 증가하는 반비례 관계\n",
    "\n",
    "<img src='img/Bias-Variance-Tradeoff.png'>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터에서 편향-분산 상충관계\n",
    "\n",
    "\"비용함수 = 편향 + 분산을 줄이는 방향으로 알고리즘이 진화하고 성능이 향상되는 편(이론에서 확인예정) 이지만,\n",
    "알고리즘 성능은 데이터에 의존되어 있기 때문에 고성능 알고리즘이 무조건 나의 데이터에서 성능이 좋을거라 단정할 순 없고,\n",
    "나의 데이터에 여러 알고리즘을 적용하여 성능 분포나 변화를 확인하여,\n",
    "과소/과대적합 되지 않는 또는 편향과 분산이 모두 최소가 되는 최적 알고리즘을 선택하는 것이 최적 모델링 방향\"\n",
    "\n",
    "#### 1) Train 적절하게 학습 후 Test 예측성능 종류\n",
    "\n",
    "\"Train 데이터는 편향과 분산이 없게 모델링을 하더라도, Test는 Train과 차이가 있는 데이터이기 때문에 다양한 결과 가능\"\n",
    "\n",
    "- (1) Train(2,1) & Train(1,2) & Train(2,2) : 알고리즘이 Train에 과소/과대적합되어 추가적인 모델링 성능 향상부터 필요하며 당연히 Test 예측에 활용 불가\n",
    "\n",
    "<img src='img/Bias_Variance2.jpeg'>\n",
    "\n",
    "- (2) Train(1,1) : 알고리즘이 train에 최적/과대적합되어 Train 예측에는 활용 가능\n",
    "\n",
    "| **Test 예측 상황** | **결과 설명 및 의미** |\n",
    "|:---:|:---|\n",
    "| **(2,1)** | - 알고리즘이 Train학습 후 Test `예측성능은 부정확한 편`이며 측정마다 `일정하게 부정확`<br> - 알고리즘이 `Train`에 `최적적합`이지만 다른 데이터인 `Test`에는 `과소적합(더욱 복잡한 패턴 존재)`이라서 예측시 `High Bias` 발생 |\n",
    "| **(1,2)** | - 알고리즘이 Train학습 후 Test `예측성능은 정확한 편`인데 측정마다 `기복이 심함`<br> - 알고리즘이 `Train`에 `과대적합`이라 다른 데이터인 `Test` 예측시 `High Variance` 발생 |\n",
    "| **(2,2)** | - 알고리즘이 Train학습 후 Test `예측성능은 부정확한 편`이며 측정마다 달라져서 `더욱 부정확할 수 있게 기복이 심함`<br> - 알고리즘이 `Train`에 `과대적합`이라 다른 데이터인 `Test` 예측시 `High Variance` 발생 가능하며, 또한 상대적으로 `Test`에는 `과소적합(더욱 복잡한 패턴 존재)`이라서 예측시 `High Bias` 발생 |\n",
    "\n",
    "#### 2) 알고리즘 복잡도별 train/test 성능 : Bias & Variance 모두 감소시키는 건 어려움\n",
    "\n",
    "| **알고리즘(복잡도)** | **Train 학습 특징** | **Train 성능** | Test 성능 |\n",
    "|:---|:---|:---|:---|\n",
    "| **과소적합(낮음)** | 데이터 <span style=\"color:red\">일부 패턴만</span> 학습 | <span   style=\"color:red\">낮음: High Bias</span> + Low Variance | <span   style=\"color:red\">낮음: High Bias</span> + Low Variance |\n",
    "| **최적적합(적정)** | 데이터 <span style=\"color:red\">모든 패턴</span> 학습 | 적정: Low Bias + Low Variance | 적정: Log/<span style=\"color:red\">Middle Bias</span> + Low Variance |\n",
    "| **과대적합(높음)** | 데이터 <span style=\"color:red\">모든 패턴 및 잡음/에러까지</span> 학습 | 높음: Low Bias + Low Variance | <span   style=\"color:red\">낮음:</span> Low/<span   style=\"color:red\">Middle Bias + High Variance</span> |\n",
    "\n",
    "- **평균-분산 상충관계(Bias-Variance Trade-off)** : 복잡도가 증가할수록 bias 감소하나 variance가 증가하는 반비례 관계\n",
    "\n",
    "    - Train : 복잡도가 증가할수록 Bias 감소 + Variance 감소\n",
    "\n",
    "    - Test : 복잡도가 증가할수록 Bias 감소 + Varaince 증가\n",
    "\n",
    "    - Underfitting : train 패턴 적게 학습하여, 주로 bias 때문에 train/test 성능 낮음\n",
    "\n",
    "    - Overfitting : train 패턴 과하게 학습하여, 주로 variance 때문에 test 성능 낮음\n",
    "\n",
    "<img src='img/Bias_Variance4.png'  width=500>\n",
    "\n",
    "\"알고리즘이 복잡해지면 Bias와 Variance는 모두 감소하는 경항이지만, 어느 시점(Train 패턴과 다른 패턴이 Test에 나타나는 시점)부터는 Variance가 증가하여 Test의 비용함수/에러가 증가\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최적 데이터 분석 방향\n",
    "\n",
    "#### 0) Train/Test 성능 : `Train <<< Test`\n",
    "\n",
    "<img src='img/DataSplit_Concept1.png'>\n",
    "\n",
    "<img src='img/DataSplit_Concept1.png'>\n",
    "\n",
    "- 예시 : 비용함수(Cost Function) = 편향 (Bias) + 분산 (Variance) + 에러(Error)\n",
    "\n",
    "<img src='img/Bias_Variance_Example1.jpg'>\n",
    "<img src='img/Bias_Variance_Example2.jpg'>\n",
    "<img src='img/Bias_Variance_Example1.jpg'>\n",
    "\n",
    "#### 1) 최적 방향 : Bias & Variance 모두 감소시키는 건 어려움\n",
    "\n",
    "- (1) 성능 시각화를 통해 Train 데이터 패턴이 과하게 학습되어 다른 데이터나 환경의 적은 변동에도 Test 성능이 급하게/안정적으로 변하는지 측정 (Train <<< Test)\n",
    "\n",
    "- (2) Bias & Variance 모두 낮게 교차하는 알고리즘 복잡도가 적용된 모델링 결과 선택\n",
    "\n",
    "- (3) 추가적으로 Train/Test의 차이를 줄이는 것도 방법 $\\Rightarrow$ K-fold Cross Validation 배경\n",
    "\n",
    "- **K-fold**\n",
    "\n",
    "<img src='img/DataSplit_ver1.png'>\n",
    "\n",
    "- **Random-subsamples**\n",
    "\n",
    "<img src='img/DataSplit_ver2.png'>\n",
    "\n",
    "- **Leave-one-out**\n",
    "\n",
    "<img src='img/DataSplit_ver3.png'>\n",
    "\n",
    "- **Leave-$p$-out**\n",
    "\n",
    "<img src='img/DataSplit_ver4.png'>\n",
    "\n",
    "#### 2) 실제 데이터분석 접근 방법 : 편향과 분산 모두 최소화하기 위해 반복적으로 업데이트\n",
    "\n",
    "\"Train 데이터의 Bias가 적절(낮게)한지 확인 후, Test 데이터에 적용하여 Variance가 적절(낮게)하도록 반복적 업데이트\"\n",
    "\n",
    "- Train의 Bias가 높다면,  알고리즘 복잡하게 또는 빅데이터(Row & Column) 또는 최적화를 통해 해결\n",
    "\n",
    "- Test의 Variance가 높다면, 알고리즘 덜 복잡하게 또는 빅데이터(Row) & 스몰데이터(Column) 또는 최적화를 통해 해결\n",
    "\n",
    "<img src='img/Bias_Variance_Reduce.png'>\n",
    "\n",
    "- 딥러닝(인공지능 알고리즘): 딥러닝은 엄청나게 복잡한 모델이며 Bias-variance Trade-off를 피할 수 없음\n",
    "\n",
    "- 스몰데이터의 딥러닝은 과대적합되어 High Variance가 우려되기에, 딥러닝으로 성능을 내기 위해선 빅데이터가 반드시 필요!\n",
    "\n",
    "- 빅데이터를 통해 Train과 Test의 패턴 차이 감소되어 Bias & Variance를 모두 감소시키기 유리\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
