{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 비지도학습(Unsupervised) 알고리즘: 군집분석"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Advanced_Algorithms_Unsupervised](./img/Advanced_Algorithms_Unsupervised.png)\n",
    "\n",
    "#### 0) 실제 데이터분석 접근 방법: 편향과 분산 모두 최소화하기 위해 반복적으로 업데이트\n",
    "\n",
    "<img src='./img/Bias_Variance4.png' width=400>\n",
    "\n",
    "**\"Train 데이터의 Bias가 적절(낮게)한지 확인 후, Test 데이터에 적용하여 Variance가 적절(낮게)하도록 반복적 업데이트\"**\n",
    "\n",
    "- Train의 Bias가 높다면,  빅데이터(Row & Column) 또는 알고리즘 복잡하게 또는 최적화를 통해 해결\n",
    "\n",
    "- Test의 Variance가 높다면, 빅데이터(Row) & 스몰데이터(Column) 또는 알고리즘 덜 복잡하게 또는 최적화를 통해 해결\n",
    "\n",
    "<img src='./img/Bias_Variance_Reduce.png' width=500>\n",
    "\n",
    "- 딥러닝(인공지능 알고리즘): 딥러닝은 엄청나게 복잡한 모델이며 Bias-variance Trade-off를 피할 수 없음\n",
    "\n",
    "- 스몰데이터의 딥러닝은 과대적합되어 High Variance가 우려되기에, 딥러닝으로 성능을 내기 위해선 빅데이터가 반드시 필요!\n",
    "\n",
    "- 빅데이터를 통해 Train과 Test의 패턴 차이 감소되어 Bias & Variance를 모두 감소시키기 유리\n",
    "\n",
    "| Clustering Algorithms | Association Rule Learning Algorithms | Dimensionality Reduction Algorithms | Ensemble Algorithms | Deep Learning Algorithms |\n",
    "|------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| <img src='./img/Clustering-Algorithms.png' width='150'> | <img src='./img/Assoication-Rule-Learning-Algorithms.png' width='150'> | <img src='./img/Dimensional-Reduction-Algorithms.png' width='150'> | <img src='./img/Ensemble-Algorithms.png' width='150'> | <img src='./img/Deep-Learning-Algorithms.png' width='150'> |\n",
    "| k-Means | Apriori algorithm | Principal Component Analysis (PCA) | Boosting | Deep Boltzmann Machine (DBM) |\n",
    "| k-Medians | Eclat algorithm | Principal Component Regression (PCR) | Bootstrapped Aggregation (Bagging) | Deep Belief Networks (DBN) |\n",
    "| Expectation Maximisation (EM) | - | Partial Least Squares Regression (PLSR) | AdaBoost | Convolutional Neural Network (CNN) |\n",
    "| Hierarchical Clustering | - | Sammon Mapping | Stacked Generalization (blending) | Stacked Auto-Encoders |\n",
    "| - | - | Multidimensional Scaling (MDS) | Gradient Boosting Machines (GBM) | - |\n",
    "| - | - | Projection Pursuit | Gradient Boosted Regression Trees (GBRT) | - |\n",
    "| - | - | Linear Discriminant Analysis (LDA) | Random Forest | - |\n",
    "| - | - | Mixture Discriminant Analysis (MDA) | - | - |\n",
    "| - | - | Quadratic Discriminant Analysis (QDA) | - | - |\n",
    "| - | - | Flexible Discriminant Analysis (FDA) | - | - |\n",
    "\n",
    "**\"비지도학습(Unsupervised Learning)은 정답 레이블이 없기 때문에, 주로 데이터를 새롭게 표현하여 원래 데이터보다 쉽게 해석하거나 특성들을 추가적으로 파악하는데 주로 사용\"**\n",
    "\n",
    "- 집분석: 비지도학습 알고리즘 중 군집화를 위해 사용되는 가장 기본(Baseline) 알고리즘\n",
    "\n",
    "    **(비수학적) \"일상 속 문제들은 어떤 유형들이 있는지 파악하는 문제\"**\n",
    "\n",
    "    - 고객들의 정보를 통해 성인인지 미성년자인지 정답을 찾는 문제가 분류문제\n",
    "\n",
    "    - 고객들의 정보를 통해 어떤 쇼핑 취향들이 있는지 성인 또는 미성년자 레이블을 할당하며 추론하는 문제가 군집문제\n",
    "\n",
    "        - 데이터가 2차원일 경우 시각화를 통해 눈으로도 패턴, 군집, 관계를 어림짐작 가능\n",
    "\n",
    "        - 데이터가 3차원 이상일 경우 시각화로 패턴, 군집, 관계 파악 어려움\n",
    "\n",
    "    **(수학적) \"특정 출력(종속변수)/입력(독립변수)의 구분이나 관계 추론도 없고 학습을 위한 목표값도 없이, 주어진 데이터를 유사한 그룹으로 군집화(Clustering) 하는 알고리즘\"**\n",
    "\n",
    "    - **분류문제**: 데이터 변수(Feature, Variable)들을 사용하여 특정 분류값을 예측\n",
    "\n",
    "    - **군집문제**: 데이터 변수(Feature, Variable)들을 사용하여 여러개의 레이블을 할당하면서 특정 군집값(Cluster)을 예측\n",
    "\n",
    "- **Target Algorithm**\n",
    "\n",
    "    **(1) Partitional Clustering vs Hierarchical Clustering**\n",
    "\n",
    "    - **Partitional**: 전체 데이터를 Hard Clustering 기준으로 한번에 군집형성하는 방식\n",
    "\n",
    "    - **Hierarchical**: 각각의 데이터에서 유사성 척도(Similarity Measure)에 의해 가까운 데이터들을 Tree 형태의 계층적 군집으로 차근차근 묶어나가는 방식이며 Tree에서 어느 수준을 기준으로 하느냐에 따라 군집이 달라짐\n",
    "\n",
    "    <img src='./img/Partitional_Hierarchical.png' width=500>\n",
    "\n",
    "    **(2) Hierarchical Clustering**\n",
    "\n",
    "    - **Agglomerative(Bottom-up)**: 개별 데이터에서 유사한 데이터끼리 묶어가는 방식\n",
    "\n",
    "    - **Divisive(Top-down)**: 모든 데이터를 하나의 군집이라 가정 후 세부 군집으로 분리하는 방식\n",
    "\n",
    "    <img src='./img/AggloDivHierarClustering.png' width=500>\n",
    "\n",
    "\n",
    "| **군집특성 분류** \t| **접근방법** \t| **측정기준** \t| **알고리즘** \t|\n",
    "|:---:\t|:---:\t|:---:\t|:---:\t|\n",
    "| **Hard Clustering** \t| **Partitional Clustering** \t| **Distance-based** \t| `K-Means` \t|\n",
    "|  \t|  \t|  \t| `K-Median` \t|\n",
    "|  \t|  \t|  \t| `K-Mode` \t|\n",
    "|  \t|  \t|  \t| `K-Medoid` \t|\n",
    "|  \t|  \t|  \t| Fuzzy Clustering \t|\n",
    "|  \t|  \t|  \t| PAM(Partitioning Around Medoids) \t|\n",
    "|  \t|  \t|  \t| CLARA(Clustering LARge Applications) \t|\n",
    "|  \t|  \t|  \t| CLARANS(Clustering Large Applications based on RANdomized Search) \t|\n",
    "| **Soft Clustering** \t| **`Hierarchical Clustering`** \t| **Agglomerative<br>     (Bottom-up)** \t| Single Linkage(Graph-based) \t|\n",
    "|  \t|  \t|  \t| Complete Linkage(Graph-based) \t|\n",
    "|  \t|  \t|  \t| Average Linkage(Graph-based) \t|\n",
    "|  \t|  \t|  \t| Centroid Linkage(Distance-based) \t|\n",
    "|  \t|  \t|  \t| Ward Linkage(Distance-based) \t|\n",
    "|  \t|  \t|  \t| AGNES(AGglomerative NESting) \t|\n",
    "|  \t|  \t| **Divisive<br>     (Top-down)** \t| DIANA(DIvisive ANAlysis) \t|\n",
    "|  \t|  \t|  \t| BIRCH(Balanced Iterative Reducint and Clustering Using Hierarchies) \t|\n",
    "|  \t|  \t|  \t| CURE(Clustering Using Representatives) \t|\n",
    "|  \t|  \t|  \t| Chameleon \t|\n",
    "|  \t| **`Density-based Clustering`** \t|  \t| DBSCAN(Density Based   Spatial Clustering of Applications with Noise) \t|\n",
    "|  \t|  \t|  \t| OPTICS(Ordering Points To   Identify the Clustering Structure) \t|\n",
    "|  \t|  \t|  \t| DENCLUE(DENsity-based   CLUstEring) \t|\n",
    "|  \t|  \t|  \t| Density-peaks \t|\n",
    "|  \t|  \t|  \t| Robust-DB(Density Based) \t|\n",
    "|  \t| **Grid-based Clustering** \t|  \t| STING(Statistical   Information Grid) \t|\n",
    "|  \t|  \t|  \t| WaveCluster \t|\n",
    "|  \t|  \t|  \t| CLIQUE(CLustering In QUEst) \t|\n",
    "|  \t| **Model-based Clustering** \t| **Distribution-based** \t| Gaussian Mixture Algorithm \t|\n",
    "|  \t|  \t|  \t| Expectation Maximization   Algorithm \t|\n",
    "|  \t|  \t|  \t| AutoClass(Mixture of Naïve   Bayes) \t|\n",
    "|  \t|  \t|  \t| Cobweb \t|\n",
    "|  \t|  \t| **Network-based** \t| Kohonen Clustering \t|\n",
    "|  \t|  \t|  \t| SOM(Self-Organizing Map) \t|"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 계층적 군집화(Hierarchical Clustering, HC)\n",
    "\n",
    "#### 1) **방향** : 유사도가 높은 또는 거리가 가까운 데이터 그룹을 계층적으로 묶으면서 군집 갯수 줄이는 방법\n",
    "\n",
    "- **(1) 소형견 vs 소 vs 중형견** : (푸들, 요크셔테리어), (물소, 젖소, 황소), (셰퍼드, 골든리트리버)\n",
    "\n",
    "- **(2) 개 vs 소** : (푸들, 요크셔테리어, 셰퍼드, 골든리트리버), (물소, 젖소, 황소)\n",
    "\n",
    "- **(3) 동물** : (푸들, 요크셔테리어, 셰퍼드, 골든리트리버, 물소, 젖소, 황소)\n",
    "\n",
    "<img src='./img/Hierarchical_ExamplePlot.png' width=600>\n",
    "\n",
    "- **결과 표현 방식** : Nested Clusters vs Dendrogram\n",
    "\n",
    "    - 데이터가 2차원인 경우 Nested Clusters를, 일반적으로는 Dendrogram 사용\n",
    "\n",
    "<img src='./img/Hierarchical_ResultExample.png' width=500>\n",
    "\n",
    "- **추정 과정**\n",
    "\n",
    "    - 데이터들의 유사성(Distance, Dissimilarity)을 추정 후 결합과정(Agglomeration)을 거쳐 Dendrogram 출력\n",
    "\n",
    "    - 처음에 모든 군집은 하나의 데이터를 가지기에 데이터 갯수만큼 군집 존재\n",
    "\n",
    "    - 최종적으론 군집이 합처져 군집화되면서 하나의 군집만 존재\n",
    "\n",
    "    <img src='./img/Hierarchical_Process.png' width=500>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) 알고리즘 함수세팅: 유사성 추정 방식과 결합 과정에 따라 여러가지 방식 존재\n",
    "\n",
    "**(1) 유사성 추정 방식(Distance Matrix)**: 두 데이터 간의 차이를 어떻게 표현할 것인가 \n",
    "\n",
    "- 데이터 특성에 따라\n",
    "\n",
    "| **대분류** \t| **소분류** \t| **의미/예시** \t|\n",
    "|:---:\t|:---:\t|:---:\t|\n",
    "| **질적변수(Qualitative Variable)** \t| **-** \t| 내부 값이 특정 범주(Category)로 분류된 변수(색상,성별,종교) \t|\n",
    "|  \t| **명목형 변수(Nominal Variable)** \t| 값이 순위가 존재하지 않는 경우(혈액형) \t|\n",
    "|  \t| **순위형 변수(Ordinal Variable)** \t| 값이 순위가 존재하는 경우(성적) \t|\n",
    "| **양적변수(Quantitative Variable)** \t| **-** \t| 내부 값이 다양한 숫자 분포로 구성된 변수(키,몸무게,소득) \t|\n",
    "|  \t| **이산형 변수(Discrete Variable)** \t| 값이 셀수 있는 경우(정수) \t|\n",
    "|  \t| **연속형 변수(Continuous Variable)** \t| 값이 셀수 없는 경우(실수) \t|\n",
    "\n",
    "- 변수 종류에 따른 측정 방식\n",
    "\n",
    "| **변수 종류** \t| **측정** \t| **설명** \t|\n",
    "|:---:\t|:---:\t|:---\t|\n",
    "| **Continuous Variable** \t| **Manhattan Distance(Minkowski at Rank=1)** \t| 최단 루트 측정(변수들의 단위가 다르거나 상관성이 있으면 크게 변함) \t|\n",
    "|  \t| **Euclidean Distance(Minkowski at Rank=2)** \t| 최단 거리 측정(변수들의 단위가 다르거나 상관성이 있으면 크게 변함) \t|\n",
    "|  \t| **Standardized Distance** \t| 변수의 분산을 고려하여 표준화 측정 \t|\n",
    "|  \t| **Mahalanobis Distance** \t| 변수의 표준화 및 변수들의 상관관계 측정 \t|\n",
    "|  \t| **Weighted Euclidean Distance** \t| Euclidean & Standardized의 일반화 측정 \t|\n",
    "| **Continuous/Discrete Variable** \t| **Pearson's Correlation Coefficient** \t| 상관관계 측정 \t|\n",
    "| **Discrete(Binary)/Nominal Variable** \t| **Simple Matching Coefficient** \t| 수식 참고 \t|\n",
    "|  \t| **Jaccard's Coefficient** \t| 수식 참고 \t|\n",
    "|  \t| **Russell and Rao Coefficient** \t| 수식 참고 \t|\n",
    "| **Nominal Variable** \t| **Cosine Distance** \t| 문자 벡터들의 각도 측정 \t|\n",
    "|  \t| **Levenshtein Metric** \t| 문자 벡터들에서 다른 단어로 변경시 필요한 편집수 측정 \t|\n",
    "|  \t| **Tanimoto Coefficient(Expanded Jaccard's Coefficient)** \t| 문자 벡터 적용 Jaccard's Coefficient \t|\n",
    "| **Ordinal Variable** \t| **Rank Correlation Coefficient** \t| 순위기반 상관관계 측정 \t|\n",
    "| **Continuous/Discrete/Nominal/Ordinal** \t| **Hamming Distance** \t| 같은 길이의 데이터에 같은 위치에 있는 값들의 비교 측정 \t|\n",
    "\n",
    "- 실제 데이터 값들마다 유사성을 추정하여 행렬(Matrix)로 표현\n",
    "\n",
    "- 특정 값의 쌍에서 추정된 유사성 거리는 행렬에서 2군데에 대칭적으로 표현\n",
    "\n",
    "- 값 자체의 유사성은 계산하지 않고 0으로 표현\n",
    "\n",
    "<img src='./img/Hierarchical_DistanceMatrix.png'>\n",
    "\n",
    "**(2) 결합 방식(Agglomeration)**: 두 데이터 간의 차이를 어떻게 표현할 것인가\n",
    "\n",
    "- Agglomerative는 각 데이터로부터 군집을 만들며 키워가는 방식\n",
    "\n",
    "- Divisive는 반대로 군집을 점차 나누면서 세부 군집으로 줄여가는 방식\n",
    "\n",
    "<img src='./img/AggloDivHierarClustering.png' width=500>\n",
    "<br/>\n",
    "\n",
    "| **군집특성 분류** \t| **접근방법** \t| **측정기준** \t| **알고리즘** \t|\n",
    "|:---:\t|:---:\t|:---:\t|:---:\t|\n",
    "| **Soft Clustering** \t| **`Hierarchical Clustering`** \t| **Agglomerative<br>     (Bottom-up)** \t| Single Linkage(Graph-based) \t|\n",
    "|  \t|  \t|  \t| Complete Linkage(Graph-based) \t|\n",
    "|  \t|  \t|  \t| Average Linkage(Graph-based) \t|\n",
    "|  \t|  \t|  \t| Centroid Linkage(Distance-based) \t|\n",
    "|  \t|  \t|  \t| Ward Linkage(Distance-based) \t|\n",
    "|  \t|  \t|  \t| AGNES(AGglomerative NESting) \t|\n",
    "|  \t|  \t| **Divisive<br>     (Top-down)** \t| DIANA(DIvisive ANAlysis) \t|\n",
    "|  \t|  \t|  \t| BIRCH(Balanced Iterative Reducint and Clustering Using Hierarchies) \t|\n",
    "|  \t|  \t|  \t| CURE(Clustering Using Representatives) \t|\n",
    "|  \t|  \t|  \t| Chameleon \t|\n",
    "\n",
    "<img src='./img/Hierarchical_DirectionType.png' width=500>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) 비용함수: 군집과 군집간의 거리를 계산하며 Linkage라고 함\n",
    "\n",
    "| **Linkage 방향** \t| **Linkage 종류** \t| **설명** \t| **특징** \t|\n",
    "|:---:\t|:---:\t|:---\t|:---\t|\n",
    "| **비계층적 방법** \t| - \t| 모든 군집화 알고리즘에 사용가능 <br>계산량 많은   단점 \t|  \t|\n",
    "|  \t| `Centroid` \t| 서로 다른 군집의 `모든 데이터의 평균 간 거리` \t| 일부 Noise / Outlier에 덜 민감하나 <br>다소 성능이 떨어짐 \t|\n",
    "|  \t| `Single` \t| 서로 다른 군집의 `모든 데이터 간 거리 중 최소값` \t| 일부 Noise / Outlier에 민감하게 반응 \t|\n",
    "|  \t| `Complete` \t| 서로 다른 군집의 `모든 데이터 간 거리 중 최대값` \t| 일부 Noise / Outlier에 민감하게 반응하며 <br>큰 클러스터 생성에 약함  \t|\n",
    "|  \t| `Average` \t| 서로 다른 군집의 `모든 데이터 간 거리의 평균` \t| 일부 Noise / Outlier에 덜 민감하나 <br>편향성 존재 \t|\n",
    "| **계층적 방법** \t| - \t| 계층적 군집화 알고리즘에만 사용가능 <br>계산량 적어 효율적 \t|  \t|\n",
    "|  \t| `Median` \t| Centroid의 변형으로 모든 데이터 아닌 <br>`기존 군집 중심점 평균` 사용 \t|  \t|\n",
    "|  \t| `Weighted` \t| Centroid의 변형으로 모든 군집들 내부와 <br>`외부 데이터와의 거리 평균` 사용 \t|  \t|\n",
    "|  \t| `Ward` \t| Weighted의 변형으로 군집화 증가시 <br>`내부 분산을 가장 작게 증가시키는 군집` \t| 일반적으로 많이 사용하나 <br>편향성 존재 \t|\n",
    "\n",
    "<br/>\n",
    "\n",
    "<img src='./img/Hierarchical_Linkage.jpg' width=600>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) 추정과정 예시: Agglomerative Hierarchical Clustering\n",
    "\n",
    "**(0) 데이터 기반 Distance Matrix**\n",
    "\n",
    "- 5개의 변수와 각 데이터간 거리는 왼쪽과 같음\n",
    "\n",
    "<img src='./img/Hierarchical_Estimation1.png' width=600>\n",
    "\n",
    "**(1) 군집화**\n",
    "\n",
    "- Single Linkage기준 A & B, D & E 거리가 가장 짧으니 군집화\n",
    "\n",
    "- Dendrogram의 높이는 군집간 거리\n",
    "\n",
    "<img src='./img/Hierarchical_Estimation2.png' width=600>\n",
    "\n",
    "**(2) Distance Matrix 업데이트**\n",
    "\n",
    "- 군집화 된 변수와 그렇지 않은 변수들과의 거리 기반 Distance Matrix 업데이트\n",
    "\n",
    "<img src='./img/Hierarchical_Estimation3.png' width=600>\n",
    "\n",
    "**(3) 군집화**\n",
    "\n",
    "- Single Linkage기준 AB & C 거리가 가장 짧으니 군집화\n",
    "\n",
    "<img src='./img/Hierarchical_Estimation4.png' width=600>\n",
    "\n",
    "**(4) Distance Matrix 업데이트 및 반복**\n",
    "\n",
    "<img src='./img/Hierarchical_Estimation5.png' width=600>\n",
    "\n",
    "**(5) 최종 군집 완성**\n",
    "\n",
    "- 모든 데이터가 하나의 군집으로 합쳐짐\n",
    "\n",
    "<img src='./img/Hierarchical_Estimation6.png' width=400>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5) 이슈 및 방향: 비용함수에 따라 군집화 결과 다름\n",
    "\n",
    "<img src='./img/Hierarchical_Issue1.png' width=500>\n",
    "<br/>\n",
    "<img src='./img/Hierarchical_Issue2.png' width=500>\n",
    "\n",
    "- Hierarchical Clustering에서는 K-means와 달리 군집의 갯수를 사전에 설정하지 않음\n",
    "\n",
    "- 최종 Dendrogram에 가상의 선을 그어 군집의 갯수 결정\n",
    "\n",
    "<img src='./img/Hierarchical_ClusterNumber.png' width=400>\n",
    "\n",
    "- 각 군집의 갯수에 따른 Metric을 통해 최종 갯수 결정\n",
    "\n",
    "    - Dunn Index\n",
    "    \n",
    "    - Silhouette Index\n",
    "    \n",
    "    - ARI(Adjusted Rand Index)\n",
    "    \n",
    "    - NMI(Normalized Mutual Information)\n",
    "    \n",
    "    - AMI(Adjusted Mutual Information)\n",
    "\n",
    "**(1) Dunn 지표(Dunn Index)**: 군집 내 데이터 간 거리 최대값 대비 군집간 거리 최소값의 비율\n",
    "$$\n",
    "DI(C)=\\cfrac { \\min _{ i\\neq j }{ \\{ { d }_{ c }({ C }_{ i },{ C }_{ j })\\}  }  }{ \\max _{ 1\\le l\\le k }{ \\{ \\triangle { C }_{ l }\\}  }  }\n",
    "$$\n",
    "\n",
    "<img src='./img/Clustering_DunnIndex.png' width=600>\n",
    "\n",
    "**(2) 실루엣 지표(Silhouette Index):** 군집 내 데이터 간 거리 평균과 가장 가까운 군집 내 데이터 간 거리 평균의 차이\n",
    "\n",
    "$$\n",
    "S(i)=\\frac { b(i)-a(i) }{ \\max { \\{ a(i),b(i)\\}  }  }\n",
    "$$\n",
    "\n",
    "**군집 내 응집도(Cohesion)**\n",
    "\n",
    "- $a(i)$ : $i$번째 군집 내 속한 데이터들과의 거리 평균\n",
    "\n",
    "**군집 간 분리도(Separation)**\n",
    "\n",
    "- $b(i)$ : $i$번째 군집과 가장 가까운 군집에 속한 데이터들과의 거리 평균\n",
    "\n",
    "<img src='./img/Clustering_Silhouette.png' width=600>\n",
    "\n",
    "- 보통 실루엣 지표가 0.5보다 크면 군집 결과가 타당한 것으로 평가\n",
    "\n",
    "<img src='./img/Clustering_Silhouette_BestWorst.png' width=600>\n",
    "\n",
    "- 오히려 평가보다 군집 갯수를 결정하는데 많이 사용\n",
    "\n",
    "- 밀집된 클러스터에선 성능이 좋으나 모양이 복잡할 때는 평가 성능 좋지 않음\n",
    "\n",
    "**(3) Others**: 클러스터 레이블 정답을 아는 경우 군집성능 평가\n",
    "\n",
    "- **ARI(Adjusted Rand Index)**: 얼마나 많은 클러스터들이 정답과 유사한지 측정\n",
    "\n",
    "    ```python\n",
    "    from sklearn.metric import adjusted_rand_score\n",
    "    ```\n",
    "\n",
    "- **NMI(Normalized Mutual Information)**: 상관관계 한계를 대체하기 위해 실제와 예측 클러스터 생성을 위한 정보량 분포의 유사성/의존도 측정\n",
    "\n",
    "    ```python\n",
    "    from sklearn.metrics import normalized_mutual_info_score\n",
    "    ```\n",
    "\n",
    "- **AMI(Adjusted Mutual Information)**: 정보량과 상관없이 클러스터 수가 많을 때 NMI가 높아지는 한계를 보완\n",
    "\n",
    "    ```python\n",
    "    from sklearn.metrics import adjusted_mutual_info_score\n",
    "    ```\n",
    "\n",
    "**(4) 현실 지표**\n",
    "\n",
    "- 데이터에 잡음/변화를 주었을 때의 결과 변동성 고려\n",
    "\n",
    "- 알고리즘 매개변수에 변화를 주었을 때의 결과 변동성 고려\n",
    "\n",
    "- 여러가지 변화에도 결과가 일정하면(Robust) 신뢰할만한 모델링"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) 사용방법\n",
    "\n",
    "```python\n",
    "from matplotlib import pyplot as plt \n",
    "from scipy.cluster.hierarchy \n",
    "import dendrogram, linkage from sklearn.cluster \n",
    "import AgglomerativeClustering\n",
    "```\n",
    "\n",
    "<br/>\n",
    "\n",
    "```python\n",
    "# Linkage 계산 및 Dendrogram 시각화\n",
    "X_tr_link = linkage(X_train, method='ward') \n",
    "dendrogram(X_tr_link, orientation='top', distance_sort='ascending', show_leaf_counts=True) \n",
    "plt.show()\n",
    "```\n",
    "\n",
    "**Cluster 추정**\n",
    "\n",
    "```python\n",
    "model_aggclust = AgglomerativeClustering(n_clusters=5, affinity='euclidean', linkage='ward') \n",
    "Y_trpred = model_aggclust.fit_predict(X_train) \n",
    "Y_tepred = model_aggclust.fit_predict(X_test)\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 밀도기반 군집화(Density-Based Clustering, DBC)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) 방향"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
