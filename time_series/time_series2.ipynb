{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터분석 단계(Data Analysis Cycle)\n",
    "\n",
    "<img src='./img/DataAnalysis_Cycle0.png' width='800'>\n",
    "\n",
    "<img src='./img/DataAnalysis_Cycle1.png' width='800'>\n",
    "\n",
    "<img src='./img/DataAnalysis_Cycle2.png' width='800'>\n",
    "\n",
    "<img src='./img/DataAnalysis_Cycle3.png' width='800'>\n",
    "\n",
    "<img src='./img/DataAnalysis_Cycle4.png' width='800'>\n",
    "\n",
    "<img src='./img/DataAnalysis_Cycle5.png' width='800'>\n",
    "\n",
    "<img src='./img/DataAnalysis_Cycle6.png' width='800'>\n",
    "\n",
    "<img src='./img/DataAnalysis_Cycle7.png' width='800'>\n",
    "\n",
    "<img src='./img/DataAnalysis_Cycle8.png' width='800'>\n",
    "\n",
    "<img src='./img/DataAnalysis_Cycle9.png' width='800'>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 시계열분석과 기계학습의 차이(Comparison)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 확률적 프로세스 및 시계열 데이터\n",
    "\n",
    "<img src='./img/TS_MS_Comparison.png'>\n",
    "\n",
    "- **확률적 프로세스(Stochastic Process)** : `시간`에 따라 `확률적 수치의 변화`를 가지는 `변수`\n",
    "\n",
    "    - **변수** : $X={X_1, X_2, \\cdots, X_n}$\n",
    "\n",
    "    - **확률적 프로세스** : 각 변수 내 확률적 수치의 변화\n",
    "\n",
    "    $$Y={\\dots, Y_{-2}, Y_{-1}, Y_0. Y_1. Y_2. \\dots}$$\n",
    "\n",
    "    $$X_1={\\dots. X_{1, -2}. X_{1, -1}, X_{1, 0}, X_{1, 1}, X_{1, 2}, \\dots}$$\n",
    "\n",
    "    $$X_2={\\dots. X_{2, -2}. X_{2, -1}, X_{2, 0}, X_{2, 1}, X_{2, 2}, \\dots}$$\n",
    "\n",
    "    $$\\dots$$\n",
    "\n",
    "    - 종속변수($Y_t$) 또는 독립변수($X_{1,t}$)가 시간단위 ($t$)를 포함\n",
    "\n",
    "    - 모델링의 출력(output)은 변수 $Y$의 특정 시간 $t$에서의 예측값 ($\\hat{Y_t}$)\n",
    "\n",
    "- **시계열 데이터(Time Series Data):** `일정한 시간 간격`에 따라 `순차적(Sequentially)으로 기록`된 `확률적 프로세스` 또는 `시간변화 데이터`\n",
    "\n",
    "    - 시간의 흐름에 따라 `불규칙적 변동`을 분석하기 위해 `필수적 데이터`\n",
    "\n",
    "    - `과거`가 `미래`에 어떤 영향을 주는지 `분석을 통해 예측` 가능\n",
    "\n",
    "    - 최근 `기계학습과 딥러닝`을 사용하여 `복잡한 데이터 예측`\n",
    "\n",
    "    - 시계열예측과 기계학습/딥러닝 간 `전처리와 알고리즘 방식 차이` 때문에, 별도로 `(1) 시계열 데이터분석 단계 이해, (2) 시계열 데이터의 전처리, (3) 시계열 알고리즘 이해` 필수!\n",
    "\n",
    "<img src='./img/TS_Example1.png'>\n",
    "\n",
    "<img src='./img/TS_Example2.png'>(https://www.ecb.europa.eu/pub/financial-stability/fsr/html/ecb.fsr202205~f207f46ea0.en.html#toc6)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시계열 데이터의 활용\n",
    "\n",
    "- 관측된 `시계열 데이터를 분석하여 미래를 예측`하는 문제가 바로 시계열 예측 문제\n",
    "\n",
    "- 흔하게 접하는 문제로 주로 `경제 지표를 예측`하거나 시간에 따른 `정당지지율을 예측`하거나, `어떤 상품의 수요를 예측`하는 문제에 이르기까지 다양하게 활용되고 있으며 `현실에 가까울수록 항상 고려해야 하는 문제`\n",
    "\n",
    "<img src='./img/TS_Applications.png'>\n",
    "\n",
    "- 예측된 결과를 바탕으로 `여러 정책이나 비즈니스 전략을 결정하는 과정에 활용`되기에, `실제 비즈니스 영역에서는 시계열 예측 문제가 매우 중요`\n",
    "\n",
    "<img src='./img/DataUseCase.png'>\n",
    "\n",
    "- `McKinsey Global Institute`에 따르면, 시계열 데이터가 텍스트나 이미지 데이터 보다 `더 큰 잠재적 가치`를 가지고 있다고 보고있음\n",
    "\n",
    "<img src='./img/DataPotential.png'>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터분석 단계의 변화\n",
    "\n",
    "> **\"시계열예측과 기계학습/딥러닝 간 `전처리와 알고리즘 방식 차이` 때문에, 별도로 `(1) 시계열 데이터분석 단계 이해, (2) 시계열 데이터의 전처리, (3) 시계열 알고리즘 이해` 필수!\"**\n",
    "\n",
    "<img src='./img/DataAnalysis_CycleTS0.png' width='900'>\n",
    "\n",
    "<img src='./img/DataAnalysis_Cycle1.png' width='900'>\n",
    "\n",
    "<img src='./img/DataAnalysis_CycleTS1.png' width='900'>\n",
    "\n",
    "<img src='./img/DataAnalysis_CycleTS2.png' width='900'>\n",
    "\n",
    "<img src='./img/DataAnalysis_CycleTS5.png' width='900'>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [시계열 알고리즘 종류](https://paperswithcode.com/area/time-series)\n",
    "\n",
    "**\"통계추론, 기계학습 및 딥러닝의 흐름에 `시간패턴`을 반영하려 진화\"**\n",
    "\n",
    "**\"`지도학습(예측 분류), 비지도학습` 문제에 모두 활용되는 필수 알고리즘\"** \n",
    "\n",
    "**\"`미래 예측을 포함한 추천 서비스와 같은 비즈니스`에 활용중\"** \n",
    "\n",
    "<img src='./img/TS_Evolution.png' width='900'>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) 통계추론(Statistical Inference) 알고리즘 : `통계분포`에 기반한 `설명력 중시 알고리즘`\n",
    "\n",
    "<img src='./img/TS_Algorithm_Concept.png'>\n",
    "\n",
    "**(1) 단변량 선형기반:** `Y가 1개` & `Y와 X의 관계를 선형 가정`\n",
    "\n",
    "- Linear Regression\n",
    "\n",
    "- `ARIMA(AutoRegressive Integrated Moving Average)`\n",
    "\n",
    "- `ARIMAX`\n",
    "\n",
    "- `SARIMAX`\n",
    "\n",
    "**(2) 다변량 선형기반:** `Y가 2개 이상` & `Y와 X의 관계를 선형 가정`\n",
    "\n",
    "- Bayesian-based Models\n",
    "\n",
    "- [`Vector Autoregression(VAR)`](https://en.wikipedia.org/wiki/Vector_autoregression)\n",
    "\n",
    "- `Vector Error Correction Model(VECM)`\n",
    "\n",
    "**(3) 비선형기반:** `Y와 X의 관계를 비선형 가정`\n",
    "\n",
    "- `Exponential Smoothing`\n",
    "\n",
    "- `ETS(Error/Trend/Seasonal)`\n",
    "\n",
    "- `Kalman Filter`\n",
    "\n",
    "- State Space Model\n",
    "\n",
    "- Change Point Detection(CPD)\n",
    "\n",
    "- `Autoregressive conditional heteroskedasticity(ARCH)`\n",
    "\n",
    "- [`Generalized Autoregressive Conditional Heteroskedasticity(GARCH)`](https://en.wikipedia.org/wiki/Autoregressive_conditional_heteroskedasticity)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) 기계학습/딥러닝 알고리즘:** `컴퓨팅` 기반 `인공지능 알고리즘`으로 `정확성 높은 비선형 관계` 추론\n",
    "\n",
    "- `Prophet`\n",
    "\n",
    "- `Neural Prophet`\n",
    "\n",
    "- `RNN(Recurrent Neural Network)`\n",
    "\n",
    "- `LSTM(Long Short-Term Memory)`\n",
    "\n",
    "- `GRU(Gated Recurrent Unit)`\n",
    "\n",
    "- Neural Networks Autoregression(NNAR)\n",
    "\n",
    "- Attention\n",
    "\n",
    "- Self-attention\n",
    "\n",
    "- Transformer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Platforms:** 글로벌 기업들이 독자적으로 개발한 `시계열 분석 플랫폼` 확대중\n",
    "\n",
    "- [Amazon Forecast](https://aws.amazon.com/ko/forecast/)\n",
    "\n",
    "- [Automated ML Time-series Forecasting at Microsoft Azure](https://azure.microsoft.com/en-us/blog/build-more-accurate-forecasts-with-new-capabilities-in-automated-machine-learning/)\n",
    "\n",
    "- [Time Series Forecasting with Google Cloud AI Platform](https://codelabs.developers.google.com/codelabs/time-series-forecasting-with-cloud-ai-platform#0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전처리 방향(Preprocessing)\n",
    "\n",
    "**\"시계열예측과 기계학습/딥러닝 간 `전처리와 알고리즘 방식 차이` 때문에, 별도로 `(1) 시계열 데이터분석 단계 이해, (2) 시계열 데이터의 전처리, (3) 시계열 알고리즘 이해` 필수!\"**\n",
    "\n",
    "- **목표** \n",
    "\n",
    "    - 대량으로 수집된 데이터는 `그대로 활용 어려움`\n",
    "\n",
    "    - `잘못 수집/처리 된 데이터`는 엉뚱한 결과를 발생\n",
    "\n",
    "    - 알고리즘이 `학습이 가능한 형태`로 데이터를 정리\n",
    "\n",
    "    <img src='./img/DataAnalysis_Time.jpg' width=500>\n",
    "\n",
    "- **일반적인 전처리 필요항목**\n",
    "\n",
    "    - 데이터 결합\n",
    "\n",
    "    - 결측값 처리\n",
    "\n",
    "    - 이상치 처리\n",
    "\n",
    "    - 자료형 변환\n",
    "\n",
    "    - `데이터 분리`\n",
    "\n",
    "    - `데이터 변환`\n",
    "\n",
    "    - 스케일 조정\n",
    "\n",
    "$\\Rightarrow$ **\"알고리즘의 범위와 종류가 다양하여, `각 알고리즘의 입력에 맞게 변환`하는 것이 최선\"**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시계열 변수추출(Feature Engineering)\n",
    "\n",
    "- **데이터 과학자들은 보통 `수동/자동 변수 처리 및 변환(Feature Engineering)`에 익숙하지만, `새로운 변수를 생성하는 것`은 분석에서 가장 중요하고 시간이 많이 걸리는 작업 중 하나이며, `머신러닝과 딥러닝의 발전`으로 점차 자동화 중**\n",
    "\n",
    "<img src='./img/DL_AutoFE.png' width=700>\n",
    "\n",
    "**\"변수 생성시 주의할 점!\"** \n",
    "\n",
    "(1) 미래의 실제 `종속변수 예측값`이 `어떤 독립/종속변수의 Feature Engineering`에 의해 효과가 있을지 `단정할 수 없음`  \n",
    "\n",
    "(2) 독립변수의 예측값을 `Feature Engineering`를 통해 생성될 수 있지만 이는 종속변수의 `예측에 오류증가를 야기할 수` 있음 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 구성요소 및 시간빈도\n",
    "\n",
    "#### 1) 시계열 데이터는 `여러 구성 성분`\n",
    "\n",
    "- **시계열 = `체계적 성분` + 불규칙 성분**\n",
    "\n",
    "<img src='./img/TimeSeries_Decomposition.png' width=600>\n",
    "\n",
    "| **시계열 방향** \t| **시계열 구성요소** \t| **의미** \t|\n",
    "|-----|-----|-----|\n",
    "| **장기적 움직임** \t| **추세(Trend)** \t| 장기적으로 시간흐름에 따른 데이터의 상승/하강 경향 \t|\n",
    "| **단기적 움직임** \t| **계절성(Seasonality)** \t| 특정기간 간격으로 반복적으로 나타나는 패턴 \t|\n",
    "|  \t| **주기(Cycle)** \t| 계절변동으로 설명되지 않는 패턴(기후변화, 정책변화, 사회관습 등) \t|\n",
    "| **불규칙 움직임** \t| **에러(Error)** \t| 사전(Prior)적으로 예측할 수 없는 특수 패턴(지진, 전쟁, 파업 등) \t|"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) 여러 구성성분들이 `단기적 및 장기적`으로 복합적으로 융합되어 작동**\n",
    "\n",
    "<img src='./img/TS_Example3.png' width=600>(http://www.sbr.ai/news/articleView.html?idxno=1608)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) 빈도(Frequency)\n",
    "\n",
    "- 사람이 인지하는 데이터의 빈도를 `컴퓨터는 명확히 인지하지 못하기 때문에 별도 설정`필요\n",
    "\n",
    "- **`계절성 패턴(Seasonality)`이 나타나기 전까지의 `데이터 갯수`로 분석가가 반영**\n",
    "\n",
    "- **예시1**\n",
    "\n",
    "| **Data** | Seasonality | Frequency |\n",
    "|-----|-----|-----|\n",
    "| **Annual** | **Annual** | 1 |\n",
    "| **Quarterly** | **Annual** | 4 |\n",
    "| **Monthly** | **Annual** | 12 |\n",
    "| **Weekly** | **Annual** | 52 |\n",
    "\n",
    "- **예시2**\n",
    "\n",
    "| **Data** | Seasonality | Frequency |\n",
    "|-----|-----|-----|\n",
    "| **Daily(데이터가 Day 단위로 수집)** | **Weekly** | 7 |\n",
    "|  | **Annual** | 365 |\n",
    "\n",
    "- **예시3**\n",
    "\n",
    "| **Data** | Seasonality | Frequency |\n",
    "|-----|-----|-----|\n",
    "| **Minutely(데이터가 Minute 단위로 수집)** | **Hourly** | 60 |\n",
    "|  | **Daily** | 24 x 60 |\n",
    "|  | **Weekly** | 24 x 60 x 7 |\n",
    "|  | **Annual** | 24 x 60 x 365 |\n",
    "\n",
    "- **`빈도 설정`을 위한 `Python 함수 옵션`**\n",
    "\n",
    "| Alias | Description |\n",
    "|-----|-----|\n",
    "| **B** | Business day |\n",
    "| **D** | Calendar day |\n",
    "| **W** | Weekly |\n",
    "| **M** | Month end |\n",
    "| **Q** | Quarter end |\n",
    "| **A** | Year end |\n",
    "| **BA** | Business year end |\n",
    "| **AS** | Year start |\n",
    "| **H** | Hourly frequency |\n",
    "| **T, min** | Minutely frequency |\n",
    "| **S** | Secondly frequency |\n",
    "| **L, ms** | Millisecond frequency |\n",
    "| **U, us** | Microsecond frequency |\n",
    "| **N, ns** | Nanosecond frequency |\n",
    "\n",
    "**빈도 설정 후 `비어있는 시간 결측치가 발견되거나 빈도 변경으로 발생하는 결측치`를채우기 위한 `Python 함수 옵션`**\n",
    "\n",
    "- 시계열에는 `노이즈 데이터 또는 관찰되지 못한 기간`이 종종 존재\n",
    "\n",
    "- 측정하고 데이터를 기록하는 과정에서의 `오류나 예측치 못한 상황으로 인해 발생`\n",
    "\n",
    "- 예를들어 `상품의 품절`로 인하여 장기간 `판매량이 없는 경우` 데이터는 없을 수 있고 이를 `적절하게 전처리 하는 것`이 실제 문제해결 성능에 매우 중요\n",
    "\n",
    "| Method | Description |\n",
    "|-----|-----|\n",
    "| **bfill** | Backward fill |\n",
    "| **count** | Count of values |\n",
    "| **ffill** | Forward fill |\n",
    "| **first** | First valid data value |\n",
    "| **last** | Last valid data value |\n",
    "| **max** | Maximum data value |\n",
    "| **mean** | Mean of values in time range |\n",
    "| **median** | Median of values in time range |\n",
    "| **min** | Minimum data value |\n",
    "| **nunique** | Number of unique values |\n",
    "| **ohlc** | Opening value, highest value, lowest value, closing value |\n",
    "| **pad** | Same as forward fill |\n",
    "| **std** | Standard deviation of values |\n",
    "| **sum** | Sum of values |\n",
    "| **var** | Variance of values |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 추세/계절성/주기/지연값 등\n",
    "\n",
    "#### 1) 추세(Trend, $T_t$)\n",
    "\n",
    "- 시계열이 `시간에 따라 증가, 감소 또는 일정 수준을 유지`하는 경우\n",
    "\n",
    "**(시각적 이해)**\n",
    "\n",
    "<img src='./img/Trend_Increasing.png' width='400'>\n",
    "\n",
    "<img src='./img/Trend_Decreasing.png' width='400'>\n",
    "\n",
    "<img src='./img/Trend_None.png' width='400'>\n",
    "\n",
    "\n",
    "**(수학적 이해)** \n",
    "\n",
    "- 확률과정의 `기댓값 함수`를 알아내는 것\n",
    "\n",
    "- 확률과정($Y_t$)이 추정이 가능한 `추세함수`($f(t)$)와 `정상확률과정`($Y^s_t$)의 합\n",
    "\n",
    "$$Y_t=f(t) +Y_t^s$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) 계절성(Seasonality, $S_t$)\n",
    "\n",
    "`일정한 빈도`로 `주기적으로 반복`되는 패턴($m$), 특정한 시간값(달/요일)에 따라 `기대값이 달라지는 것`\n",
    "\n",
    "- **예시:** 주기적 패턴이 12개월마다 반복($m$ = 12) \n",
    "\n",
    "<img src='./img/Seasonal.png' width='400'>\n",
    "\n",
    "- **대표적 계절성 변수 생성 2가지:** \n",
    "\n",
    "    - 수치값 그대로 반영 $\\rightarrow$ `LabelEncoding`\n",
    "\n",
    "    <img src='./img/Label_Encoding.png' width='250'>\n",
    "\n",
    "    - 계절성 주기 내 시점마다 별도 변수 생성 $\\rightarrow$ `OneHotEncoding`\n",
    "\n",
    "    <img src='./img/Dummy_Engineering.png' width='500'>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) 주기(Cycle, $C_t$)\n",
    "\n",
    "- `일정하지 않은 빈도`로 발생하는 패턴(계절성과 다름) \n",
    "\n",
    "- **예시:** 빈도가 1인 경우에도 발생 가능($m$ = 1)\n",
    "\n",
    "<img src='./img/Cycle.png' width='400'>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) 시계열 분해(추세/계절성/잔차(Residual, $e_t$))\n",
    "\n",
    "<img src='./img/Decomposed-into-its-trend-seasonal-and-irregular.png.jpeg' width='600'>\n",
    "\n",
    "**(1) 가법모형(Additive Model):** `추세 + 계절성 + 주기 + 오차`\n",
    "\n",
    "- 구성요소간 `독립성`을 가정하고 시계열이 `구성요소의 합` 가정\n",
    "\n",
    "- 주로 계절성분의 진폭/분산이 시간이 흘러도 `일정한 경우` 사용\n",
    "\n",
    "**(2) 승법모형(Multiplicative Model):** `추세 * 계절성 * 주기 * 오차`\n",
    "\n",
    "- 구성요소간 `비독립성`을 가정하고 시계열이 `구성요소의 곱` 가정\n",
    "\n",
    "- 주로 계절성분의 진폭/분산이 시간에 따라 `일정하지 않은 경우` 사용"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5) 지연값(Lagged values, $Lag_t(X_1)$)\n",
    "\n",
    "- 변수의 `지연된 값들`로 별도 독립변수를 생성하는 것으로, `ARIMA/VAR/NNAR(Neural Network Autoregression) 등`의 알고리즘도 내부적으로 활용 \n",
    "\n",
    "<img src='./img/Lag-explanation.PNG' width='400'>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6) 시간변수\n",
    "\n",
    "- `시간정보`가 담고 있는 년/월/일/요일 등 자체를 `별도 독립적인 변수로 생성`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7) 요약\n",
    "\n",
    "- 시계열 구성요소는 각 변수의 `시간패턴을 파악`하는데 중요\n",
    "\n",
    "- FE를 통해 생성된 `변수의 입력(Input) 형태나 빈도`로 `알고리즘 선택`시 고려해야\n",
    "\n",
    "- 생성된 변수의 패턴이 기존 모델에서 반영하지 않던 패턴이라면 `예측 성능을 높임`\n",
    "\n",
    "- 예측성능 향상 뿐 아니라 `결과를 해석`하고 해당 속성을 분석하며 가능한 `원인 식별에 도움`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 분리(Data Split)\n",
    "\n",
    "**배경**\n",
    "\n",
    "(1) 독립변수와 종속변수 구분\n",
    "\n",
    "| **대분류** \t| **의미/예시** \t|\n",
    "|-----|-----|\n",
    "| **독립변수(Independent Variable)** \t| 다른 변수에 영향을 미치는 변수 (X) \t|\n",
    "| **종속변수(Dependent Variable)** \t| 다른 변수에 의해 영향을 받는 변수 (Y) \t|\n",
    "\n",
    "(2) 과거/현재와 미래 기간 구분\n",
    "\n",
    "- **Training Period:** 과거/현재의 상황을 분석\n",
    "\n",
    "<img src='./img/DataSplit_Concept1.png' width='700'>\n",
    "\n",
    "- **Testing Period:** 미래를 예측 할 수 있는 환경\n",
    "\n",
    "<img src='./img/DataSplit_Concept2.png' width='700'>\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) 간단한 방법(Holdout Validation)\n",
    "\n",
    "- **훈련셋(Training set):** 일반적으로 `전체 데이터의 70%` 사용 \n",
    "- **테스트셋(Testing set):** 일반적으로 `전체 데이터의 30%` 사용"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) 일반적 방법(Simple Validation)\n",
    "\n",
    "- **훈련셋(Training set):** 일반적으로 `전체 데이터의 60%`를 사용\n",
    "\n",
    "- **검증셋(Validation set):** \n",
    "    \n",
    "    - 개발셋이라고도 하며, 일반적으로 `전체 데이터의 20%`를 사용함\n",
    "    \n",
    "    - `훈련된 여러가지 모델들의 성능을 테스트` 하는데 사용되며 모델 선택의 기준이 됨\n",
    "\n",
    "- **테스트셋(Testing set):** 일반적으로 `전체 데이터의 20%`를 사용하며 최종 모델의 정확성을 확인하는 목적에 사용됨\n",
    "\n",
    "<img src='./img/DataSplit_Simple.png' width='500'>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) $K$교차검사($K$-fold Cross Validation)\n",
    "\n",
    "(1) 훈련셋을 복원없이 `K`개로 분리한 후, `K-1`는 하위훈련셋으로 나머지 `1개`는 검증셋으로 사용함  \n",
    "\n",
    "(2) 검증셋과 하위훈련셋을 `번갈아가면서` `K번 반복`하여 각 모델별로 `K`개의 `성능 추정치`를 계산  \n",
    "\n",
    "(3) `K개의 성능 추정치 평균`을 최종 모델 성능 기준으로 사용 \n",
    "\n",
    "<img src='./img/DataSplit_Kfold.png' width='500'>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) $K$-fold vs. Random-subsamples vs. Leave-one-out vs. Leave-$p$-out\n",
    "\n",
    "- **$K$-fold**\n",
    "\n",
    "<img src='./img/DataSplit_ver1.png' width='500'>\n",
    "\n",
    "- **Random-subsamples**\n",
    "\n",
    "<img src='./img/DataSplit_ver2.png' width='500'>\n",
    "\n",
    "- **Leave-one-out**\n",
    "\n",
    "<img src='./img/DataSplit_ver3.png' width='500'>\n",
    "\n",
    "- **Leave-$p$-out**\n",
    "\n",
    "<img src='./img/DataSplit_ver4.png' width='500'>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 시계열 데이터 분리\n",
    "\n",
    "#### 1) 시계열 데이터인 경우 `랜덤성(set.seed) 없이 시간축 유지가 핵심!`\n",
    "\n",
    "- **훈련셋 < 검증셋 < 테스트셋**\n",
    "\n",
    "    - **훈련셋(Training set):** `가장 오래된` 데이터\n",
    "\n",
    "    - **검증셋(Validation set):** `그 다음 최근` 데이터\n",
    "\n",
    "    - **테스트셋(Testing set):** `가장 최신`의 데이터\n",
    "\n",
    "<img src='./img/DataSplit_TimeSeries.png' width='500'>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) 최선의 성능을 가지는 `Robust 모델링`을 위해 `시계열 교차검증` 필수!\n",
    "\n",
    "**(1) 모든 미래 시점을 한번에 예측하면 `정확성 낮아짐`:** 미래 시점마다 Train/Test `재분류 필요`**\n",
    "\n",
    "- **Sliding Window:** `고정된 사이즈의 Train & Test Window`를 움직이며 데이터를 재분리\n",
    "\n",
    "- **Expanding Window:** `가변 사이즈 Train Window & 고정된 사이즈 Test Window`를 움직이며 데이터를 재분리\n",
    "\n",
    "<img src='./img/DataSplit_TSWindow.png' width='800'>(https://eng.uber.com/forecasting-introduction/)\n",
    "\n",
    "**(2) 단기/중기/장기 모든 미래시점에 동일 성능을 가지는 `Robust 알고리즘`은 없기 때문에 시점마다 `별도 모델링 필요`**\n",
    "\n",
    "- **1스텝 교차검사(One-step Ahead Cross-validation):**\n",
    "\n",
    "<img src='./img/DataSplit_TimeSeries_ver1.png' width='500'>\n",
    "\n",
    "- **2스텝 교차검사(Two-step Ahead Cross-validation):**\n",
    "\n",
    "<img src='./img/DataSplit_TimeSeries_ver2.png' width='500'>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 변환(Reality & Feature Selection)\n",
    "\n",
    "### 시간현실 반영(Reality)\n",
    "\n",
    "**\"미래의 시간패턴을 `미리 반영하는건 비현실적`, 이는 `과적합(Overfitting)` 유발\"**\n",
    "\n",
    "- 데이터 전처리시, `데이터 분리 후 패턴을 추출`하여 해결\n",
    "\n",
    "<img src='./img/DataAnalysis_CycleTS0.png' width='800'>\n",
    "\n",
    "<img src='./img/DataAnalysis_Cycle1.png' width='800'>\n",
    "\n",
    "<img src='./img/DataAnalysis_CycleTS1.png' width='800'>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 변수들의 독립성 향상(Condition Number)\n",
    "\n",
    "#### 1) 배경: `예측 성능을 향상`시키려면 `독립변수들의 독립성이 높아야` 함 \n",
    "\n",
    "- **이상적:** Train 예측성능 $\\uparrow$ + Test 예측성능 $\\uparrow$  \n",
    "\n",
    "- **현실적:** Train 예측성능 <<< Test 예측성능 $\\Longleftrightarrow$ `낮은 조건수(Condition Number)`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) 낮은 조건수란?\n",
    "\n",
    "**(비수학적 이해)** \n",
    "\n",
    "- 독립변수들($X$)의 `상호의존도(관련성)`가 분석결과($Y$)에 주는 `영향을 줄이고`, 독립변수 각각의 `순수한 영향`만을 반영\n",
    "\n",
    "**(수학적 이해)**\n",
    "\n",
    "- 독립변수($X$)가 움직일 수 있는 변동성(공분산)을 줄여 `분석결과(Y)의 변동을 줄여 신뢰성 향상`\n",
    "\n",
    "- **변동성(공분산)?:** 알고리즘이 예측 영향력(계수/가중치)추정 과정에서 발생하는 `역행렬의 변화에 오차가 미치는 영향`\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{Condition Number(조건수)} &= \\dfrac{\\lambda_{max}}{\\lambda_{min}} \\\\ \n",
    "\\lambda_{max} &= \\max[\\text{eigenvalue}\\{Cov(X^T X)\\}], \\\\\n",
    "\\lambda_{min} &= \\min[\\text{eigenvalue}\\{Cov(X^T X)\\}]\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 조건수가 작을 때\n",
    "# X 데이터\n",
    "import numpy as np\n",
    "A = np.eye(4)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Y 데이터\n",
    "Y = np.ones(4)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 계수 추정\n",
    "np.linalg.solve(A, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0001, 0.    , 0.    , 0.    ],\n",
       "       [0.    , 1.0001, 0.    , 0.    ],\n",
       "       [0.    , 0.    , 1.0001, 0.    ],\n",
       "       [0.    , 0.    , 0.    , 1.0001]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X 데이터 오차반영\n",
    "A_new = A + 0.0001 * np.eye(4)\n",
    "A_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99990001, 0.99990001, 0.99990001, 0.99990001])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 계수 추정\n",
    "np.linalg.solve(A_new, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 조건수 확인\n",
    "np.linalg.cond(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.5       , 0.33333333, 0.25      ],\n",
       "       [0.5       , 0.33333333, 0.25      , 0.2       ],\n",
       "       [0.33333333, 0.25      , 0.2       , 0.16666667],\n",
       "       [0.25      , 0.2       , 0.16666667, 0.14285714]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 조건수가 클 때\n",
    "# X 데이터\n",
    "from scipy.linalg import hilbert\n",
    "A = hilbert(4)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Y 데이터\n",
    "Y = np.ones(4)\n",
    "Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  -4.,   60., -180.,  140.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 계수 추정\n",
    "np.linalg.solve(A, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0001    , 0.5       , 0.33333333, 0.25      ],\n",
       "       [0.5       , 0.33343333, 0.25      , 0.2       ],\n",
       "       [0.33333333, 0.25      , 0.2001    , 0.16666667],\n",
       "       [0.25      , 0.2       , 0.16666667, 0.14295714]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X 데이터 오차반영\n",
    "A_new = A + 0.0001 * np.eye(4)\n",
    "A_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -0.58897672,  21.1225671 , -85.75912499,  78.45650825])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 계수 추정\n",
    "np.linalg.solve(A_new, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15513.738738929662"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 조건수 확인\n",
    "np.linalg.cond(A)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) 조건수를 낮추는 방법:** `예측 안정성(Robust/Goodfit)`을 높이는 방법\n",
    "\n",
    "(1) `변수들의 단위차이`로 숫자의 스케일들이 크게 다른 경우, `스케일링(Scaling)`으로 해결 가능\n",
    "\n",
    "(2) 독립변수들 간에 `상관관계(상호의존성)`가 높은 `다중공선성` 존재할 경우, `Variance Inflation Factor(VIF)`나 `Principal Component Analysis(PCA)`를 통한 `변수선별`로 해결 가능\n",
    "\n",
    "(3) 독립변수들 간 `상호의존성이 높은 변수들에 패널티`를 부여하는 `정규화(Resularization)`로 해결 가능 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다중공선성(Multicollinearity)\n",
    "\n",
    "#### 1) 다중공선성(Multicollinearity)이 `발생`하는 경우\n",
    "\n",
    "- 특정 독립변수가 `다른 독립변수의 조합으로 표현`될 수 있는 경우 \n",
    "\n",
    "- 독립변수들이 `서로 독립이 아니라 상호상관관계가 강한` 경우 \n",
    "\n",
    "- 독립변수의 공분산 행렬(Covariance Matrix) 벡터공간(Vector Space)의 `차원과 독립변수의 수가 달라` 변수들이 `모두 독립이 아닌 경우`(Full Rank가 아니다)\n",
    "\n",
    "$\\Rightarrow$ `다중공선성`이 있으면 독립변수 공분산 행렬의 `조건수(Condition Number) 증가`\n",
    "\n",
    "$\\Rightarrow$ 조건수(Condition Number)가 증가하면 `과적합(Overfitting) 발생가능성 증가`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) 다중공선성을 줄이는 방법\n",
    "\n",
    "**(1) Variance Inflation Factor(VIF) 변수선택**\n",
    "\n",
    "**\"VIF는 `독립변수를 다른 독립변수들로 선형회귀한 성능들을 비교`하여 상호 `의존성이 높은 변수를 제거`하거나 `의존성이 낮은 변수를 선택`\"**\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "VIF_i &= Var(\\hat{\\beta}_i) = \\dfrac{\\sigma^2_{\\epsilon}}{(n-1)Var(X_i)} \\cdot \\dfrac{1}{1-R_i^2} \\\\\n",
    "& (R_i^2:\\text{ 독립변수 } X_i를 \\text{ 다른 독립변수들로 선형회귀한 성능})\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "**Variance Inflation Factor : Multicollinearity**\n",
    "\n",
    "$$y_i=\\alpha+\\beta_1 x_{1,i}+\\beta_2 x_{2i}+\\cdots+\\beta_{\\rho}x_{\\rho i}+\\varepsilon_i$$\n",
    "\n",
    "- Correlation matrix\n",
    "\n",
    "- Scatterplot\n",
    "\n",
    "- Variace Inflation Factor\n",
    "\n",
    "$$R^2 \\Leftarrow X_{1i} = \\delta_0+\\delta_1x{2i}+\\delta_2x_{3i}+\\cdots+\\delta_{\\rho-1}x_{\\rho i}+ v_i \\\\\n",
    "\\Leftarrow X_{2i}=\\delta_0+\\delta_1x_{ij}+\\delta_2 x_{3i}+\\cdots$$\n",
    "\n",
    "<img src='./img/VIF_Explanation.jpg' width='800'>(https://www.youtube.com/watch?v=0SBIXgPVex8)\n",
    "\n",
    "**(2) Principal Component Analysis(PCA) 변수선택**\n",
    "\n",
    "\"PCA는 `다차원에서 상호 관련성이 높은 독립변수들을 관련성이 없는 서로 독립인 소차원으로 변경`하는 알고리즘으로, 이를 통해 상호 의존성을 제거\"\n",
    "\n",
    "<img src='./img/PCA_2D_Ex.png' width='900'>(https://www.mdpi.com/2076-3417/11/9/3780)\n",
    "\n",
    "<img src='./img/PCA_Visualization.png' width='900'>\n",
    "\n",
    "<img src='./img/PCA_MultiEx.png' width='900'>\n",
    "\n",
    "<img src='./img/PCA_MultiExPC1PC2.png' width='600'>(https://www.mdpi.com/2076-3417/11/9/3780)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [스케일 조정(Scaling)](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html#sphx-glr-download-auto-examples-preprocessing-plot-all-scaling-py)\n",
    "\n",
    "- **목적:** 변수들의 `크기를 일정하게 맞추어` `크기` 때문에 `영향`이 높은 현상을 회피\n",
    "\n",
    "    - **수학적:** 독립 변수의 공분산 `행렬 조건수(Condition Number)를 감소`시켜 최적화 안정성 및 수렴 속도 향상 \n",
    "\n",
    "    - **컴퓨터적:** PC 메모리를 고려하여 `오버플로우(Overflow)나 언더플로우(Underflow)를 줄여줌` "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Standard Scaler: $\\dfrac{X_{it} - E(X_i)}{SD(X_i)}$\n",
    "\n",
    "- 기본 스케일로 평균을 제외하고 표준편차를 나누어 변환  \n",
    "\n",
    "- 각 변수(Feature)가 `정규분포를 따른다는 가정`이기에 정규분포가 아닐 시 최선이 아닐 수 있음\n",
    "\n",
    "```python\n",
    "sklearn.preprocessing.StandardScaler().fit()\n",
    "sklearn.preprocessing.StandardScaler().transform()\n",
    "sklearn.preprocessing.StandardScaler().fit_transform()\n",
    "```\n",
    "\n",
    "<img src='./img/Scaling_StandardScaler.png' width='500'>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Min-Max Scaler : $\\dfrac{X_{it} - min(X_i)}{max(X_i) - min(X_i)}$\n",
    "\n",
    "- 가장 많이 활용되는 방식으로 최소\\~최대 값이 `0~1` 또는 `-1~1` 사이의 값으로 변환  \n",
    "\n",
    "- 각 변수(Feature)가 `정규분포가 아니거나 표준편차가 매우 작을 때` 효과적 \n",
    "\n",
    "```python\n",
    "sklearn.preprocessing.MinMaxScaler().fit()\n",
    "sklearn.preprocessing.MinMaxScaler().transform()\n",
    "sklearn.preprocessing.MinMaxScaler().fit_transform()\n",
    "```\n",
    "\n",
    "<img src='./img/Scaling_MinMaxScaler.png' width='500'>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Robust Scaler:$\\dfrac{X_{it} - Q_1(X_i)}{Q_3(X_i) - Q_1(X_i)}$\n",
    "\n",
    "- 최소-최대 스케일러와 유사하지만 `최소/최대 대신`에 IQR(Interquartile Range) 중 `25%값/75%값`을 사용하여 변환  \n",
    "\n",
    "- 이상치(Outlier)에 영향을 최소화하였기에 `이상치가 있는 데이터에 효과적`이고 `적은 데이터에도 효과적`인 편  \n",
    "\n",
    "```python\n",
    "sklearn.preprocessing.RobustScaler().fit()\n",
    "sklearn.preprocessing.RobustScaler().transform()\n",
    "sklearn.preprocessing.RobustScaler().fit_transform()\n",
    "```\n",
    "\n",
    "<img src='./img/Scaling_RobustScaler.png' width='500'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
