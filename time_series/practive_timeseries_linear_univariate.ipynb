{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library : 분석에 사용할 모듈 설치\n",
    "\n",
    "\"통계추론, 기계학습 및 딥러닝의 흐름에 시간패턴을 반영하려 진화\"\n",
    "\n",
    "\"지도학습(예측 분류), 비지도학습 문제에 모두 활용되는 필수 알고리즘\"\n",
    "\n",
    "\"미래 예측을 포함한 추천 서비스와 같은 비즈니스에 활용중\"\n",
    "\n",
    "<img src='./img/TS_Evolution.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade pip\n",
    "# !python -m pip install --user --upgrade pip\n",
    "# !pip install pandas-datareader\n",
    "# !pip install tqdm\n",
    "# !pip install xgboost\n",
    "# !pip install lightgbm\n",
    "# !pip install --user pmdarima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto reload and user defined functions\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from module_regression import *\n",
    "from module_classification import *\n",
    "from module_timeseries import *\n",
    "\n",
    "# Data manipulation and useful functions\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import random\n",
    "from itertools import product\n",
    "import scipy as sp\n",
    "\n",
    "# Time series algorithms\n",
    "from statsmodels.tsa.arima_process import arma_generate_sample\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from pmdarima import AutoARIMA\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf, plot_predict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Base Algorithm:** Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_size: (13128, 29) Test_size: (4416, 29)\n",
      "X_train: (13128, 24) Y_train: (13128, 1)\n",
      "X_test: (4416, 24) Y_test: (4416, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Must have equal len keys and value when setting with an iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39m# 데이터 전처리(현실성)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m### Reality ###\u001b[39;00m\n\u001b[1;32m     16\u001b[0m target \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mcount_trend\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcount_seasonal\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcount_Day\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcount_Week\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcount_diff\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m---> 17\u001b[0m X_train_R \u001b[39m=\u001b[39m feature_engineering_year_duplicated(X_train, target)\n\u001b[1;32m     18\u001b[0m X_test_R \u001b[39m=\u001b[39m feature_engineering_year_duplicated(X_test, target)\n\u001b[1;32m     19\u001b[0m target \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mcount_lag1\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcount_lag2\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/Github/finance/finance/time_series/module_timeseries.py:189\u001b[0m, in \u001b[0;36mfeature_engineering_year_duplicated\u001b[0;34m(raw, target)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m target:\n\u001b[1;32m    188\u001b[0m     raw_fe\u001b[39m.\u001b[39mloc[\u001b[39m'\u001b[39m\u001b[39m2012-01-01\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39m2012-02-28\u001b[39m\u001b[39m'\u001b[39m, col] \u001b[39m=\u001b[39m raw\u001b[39m.\u001b[39mloc[\u001b[39m'\u001b[39m\u001b[39m2011-01-01\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39m2011-02-28\u001b[39m\u001b[39m'\u001b[39m, col]\u001b[39m.\u001b[39mvalues\n\u001b[0;32m--> 189\u001b[0m     raw_fe\u001b[39m.\u001b[39;49mloc[\u001b[39m'\u001b[39;49m\u001b[39m2012-03-01\u001b[39;49m\u001b[39m'\u001b[39;49m:\u001b[39m'\u001b[39;49m\u001b[39m2012-12-31\u001b[39;49m\u001b[39m'\u001b[39;49m, col] \u001b[39m=\u001b[39m raw\u001b[39m.\u001b[39mloc[\u001b[39m'\u001b[39m\u001b[39m2011-03-01\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39m2011-12-31\u001b[39m\u001b[39m'\u001b[39m, col]\u001b[39m.\u001b[39mvalues\n\u001b[1;32m    190\u001b[0m     step \u001b[39m=\u001b[39m (raw\u001b[39m.\u001b[39mloc[\u001b[39m'\u001b[39m\u001b[39m2011-03-01 00:00:00\u001b[39m\u001b[39m'\u001b[39m, col] \u001b[39m-\u001b[39m raw\u001b[39m.\u001b[39mloc[\u001b[39m'\u001b[39m\u001b[39m2011-02-28 23:00:00\u001b[39m\u001b[39m'\u001b[39m, col])\u001b[39m/\u001b[39m\u001b[39m25\u001b[39m\n\u001b[1;32m    191\u001b[0m     step_value \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(raw\u001b[39m.\u001b[39mloc[\u001b[39m'\u001b[39m\u001b[39m2011-02-28 23:00:00\u001b[39m\u001b[39m'\u001b[39m, col]\u001b[39m+\u001b[39mstep, raw\u001b[39m.\u001b[39mloc[\u001b[39m'\u001b[39m\u001b[39m2011-03-01 00:00:00\u001b[39m\u001b[39m'\u001b[39m, col], step)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexing.py:818\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[1;32m    817\u001b[0m iloc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39miloc\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39miloc\n\u001b[0;32m--> 818\u001b[0m iloc\u001b[39m.\u001b[39;49m_setitem_with_indexer(indexer, value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexing.py:1795\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1792\u001b[0m \u001b[39m# align and set the values\u001b[39;00m\n\u001b[1;32m   1793\u001b[0m \u001b[39mif\u001b[39;00m take_split_path:\n\u001b[1;32m   1794\u001b[0m     \u001b[39m# We have to operate column-wise\u001b[39;00m\n\u001b[0;32m-> 1795\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setitem_with_indexer_split_path(indexer, value, name)\n\u001b[1;32m   1796\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1797\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_single_block(indexer, value, name)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexing.py:1850\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_split_path\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1845\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(value) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_integer(info_axis):\n\u001b[1;32m   1846\u001b[0m         \u001b[39m# This is a case like df.iloc[:3, [1]] = [0]\u001b[39;00m\n\u001b[1;32m   1847\u001b[0m         \u001b[39m#  where we treat as df.iloc[:3, 1] = 0\u001b[39;00m\n\u001b[1;32m   1848\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_with_indexer((pi, info_axis[\u001b[39m0\u001b[39m]), value[\u001b[39m0\u001b[39m])\n\u001b[0;32m-> 1850\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1851\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMust have equal len keys and value \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1852\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mwhen setting with an iterable\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1853\u001b[0m     )\n\u001b[1;32m   1855\u001b[0m \u001b[39melif\u001b[39;00m lplane_indexer \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(value) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39mindex):\n\u001b[1;32m   1856\u001b[0m     \u001b[39m# We get here in one case via .loc with a all-False mask\u001b[39;00m\n\u001b[1;32m   1857\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Must have equal len keys and value when setting with an iterable"
     ]
    }
   ],
   "source": [
    "# 데이터 로딩\n",
    "location = os.path.join('.', 'data', 'Bike_Sharing_Demand_Full.csv')\n",
    "df_all = pd.read_csv(location)\n",
    "\n",
    "# 데이터 전처리\n",
    "df_fe = feature_engineering(df_all)\n",
    "\n",
    "# 데이터 분리\n",
    "Y_colname = ['count']\n",
    "X_remove = ['datetime', 'DateTime', 'temp_group', 'casual', 'registered']\n",
    "X_colname = [x for x in df_fe.columns if x not in Y_colname+X_remove]\n",
    "X_train, X_test, Y_train, Y_test = datasplit_ts(df_fe, Y_colname, X_colname, '2012-07-01')\n",
    "\n",
    "# 데이터 전처리(현실성)\n",
    "### Reality ###\n",
    "target = ['count_trend', 'count_seasonal', 'count_Day', 'count_Week', 'count_diff']\n",
    "X_train_R = feature_engineering_year_duplicated(X_train, target)\n",
    "X_test_R = feature_engineering_year_duplicated(X_test, target)\n",
    "target = ['count_lag1', 'count_lag2']\n",
    "X_test_R = feature_engineering_lag_modified(Y_test, X_test_R, target)\n",
    "###############\n",
    "### Scaling ###\n",
    "X_train_RS, X_test_RS = feature_engineering_scaling(preprocessing.Normalizer(), \n",
    "                                                    X_train_R, X_test_R)\n",
    "###############\n",
    "### Multicollinearity ###\n",
    "print('Number_of_Total_X: ', len(X_train_RS.columns))\n",
    "X_colname_vif = feature_engineering_XbyVIF(X_train_RS, 12)\n",
    "print('Number_of_Selected_X: ', len(X_colname_vif))\n",
    "X_train_RSM, X_test_RSM = X_train_RS[X_colname_vif].copy(), X_test_RS[X_colname_vif].copy()\n",
    "#########################\n",
    "\n",
    "# Linear Regression\n",
    "model_lr = sm.OLS(Y_train, X_train_RSM).fit()\n",
    "display(model_lr.summary())\n",
    "\n",
    "Y_trpred = pd.DataFrame(model_lr.predict(X_train_RSM), columns=['Pred'])\n",
    "Y_tepred = pd.DataFrame(model_lr.predict(X_test_RSM), columns=['Pred'])\n",
    "plot_prediction(pd.concat([Y_train, Y_trpred], axis=1).reset_index().iloc[:,1:])\n",
    "plot_prediction(pd.concat([Y_test, Y_tepred], axis=1).reset_index().iloc[:,1:])\n",
    "\n",
    "# 분석 검증\n",
    "Score = evaluation_reg_trte(Y_train, Y_trpred, Y_test, Y_tepred)\n",
    "display(Score)\n",
    "\n",
    "# 에러 분석\n",
    "Resid_te = Y_test - Y_tepred.values\n",
    "Resid_te.columns = ['Error']\n",
    "Error_te = error_analysis(X_test, Y_tepred, Resid_te, graph_on=True)\n",
    "display(Error_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
