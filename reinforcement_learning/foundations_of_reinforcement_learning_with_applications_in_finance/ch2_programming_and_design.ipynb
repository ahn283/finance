{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment setup\n",
    "\n",
    "- [The book github](https://github.com/TikhonJelvis/RL-book)\n",
    "\n",
    "- First, move to the directory with the codebase:\n",
    "\n",
    "   ```cd rl-book```\n",
    "\n",
    "- Then, create and activate a Python vitrual environment\n",
    "\n",
    "   ```python3 -m venv .venv```\n",
    "\n",
    "   ```source .venv/bin/activate```\n",
    "   \n",
    "   ```conda create -n {env_name}```\n",
    "\n",
    "   ```conda activate {env_name}```\n",
    "\n",
    "- Once the environment is activated, you can install the right versions of each Python dependency.\n",
    "\n",
    "   ```pip install -r requirements.txt```\n",
    "\n",
    "- Once the environment is set up, you can confirm that it works by running the frameworks automated tests.\n",
    "\n",
    "   ```python -m unittest discover```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes and interfaces\n",
    "\n",
    "- There are always two parts to answering this questions:\n",
    "\n",
    "    - Understanding the domain concept that you are modeling.\n",
    "\n",
    "    - Figuring out how to express that concept with features and patterns provided by your programming language.\n",
    "\n",
    "- One approach would be to keep Probability implicit. Whenever we have a random variable, we could call a function and get a random result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "def six_sided():\n",
    "    return randint(1, 6)\n",
    "\n",
    "def roll_dice():\n",
    "    return six_sided() + six_sided()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This works, but it's pretty limited. We can't do anything except get one outcome at a time. This only captures a slice of how we think about Probability: there's randomness but we never even mentioned probability distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A distribution interface\n",
    "\n",
    "- Let's define an abstaction for probability distributions. It depends on what kind of distribution we're working with. \n",
    "\n",
    "    - If we know something about the structure of a distribution - perhaps it's a Poisson distribution where $\\lambda=5$, perhaps it's an empirical distribution with set probabilities for each outcome - we could do produce an exact Probability Distribution Function (PDF) or Cumumlative Distribution Function (CDF), calcaulate expectations and do various operations efficiently.\n",
    "\n",
    "    - What if the distribution comes from a complicated simulation? At the extreme, we might not be able to do anything except draw samples from the distribution.\n",
    "\n",
    "- Sampling is the least common denominator. Any abstraction we start with for a probability distribution needs to cover sampling, and any abstraction that requires and any abstraction that requires more than just sampling will not let us handle all the distributions we care about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class Distribution(ABC):\n",
    "    @abstractmethod\n",
    "    def sample(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This class defines an interface : a definition of what we require for something to qualify as a distribution. Any kind of distribution we implement in the future will be able to generate samples; when we write functions that sample distributions, they cam require their inputs to inherit from `Distribtution`.\n",
    "\n",
    "- We've made `Distribuition` an abstract base class (ABC), with `sample` as an abstact method. Abstract classes and abstract methods are features that Python provides to help us define interfaces for abstractions. We can define the `Distribiution` class to structure the rest of our probability distribution code before we define any specific distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A concrete distribution\n",
    "\n",
    "- An interface can be approached from two sides:\n",
    "\n",
    "    - Something that requires the interface. This will be code that uses operations specified in the interface and work with any value that satisfies those requirements.\n",
    "\n",
    "    - Something that provides the interface. This will be some value that supports the operations specified in the interface.\n",
    "\n",
    "- To use our `Distribution` class, we can start by providing a concrete class that implements the interface. Let's model dice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Die(Distribution):\n",
    "    def __init__(self, sides):\n",
    "        self.sides = sides\n",
    "    def sample(self):\n",
    "        return random.randint(1, self.sides)\n",
    "    \n",
    "six_sided = Die(6)\n",
    "def roll_dice():\n",
    "    return six_sided.sample() + six_sided.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Die object at 0x106897c90>\n"
     ]
    }
   ],
   "source": [
    "print(six_sided)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With a class we can fix this. To change the class is printed, we can override `__repr__`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Die(Distribution):\n",
    "    def __init__(self, sides):\n",
    "        self.sides = sides\n",
    "    def sample(self):\n",
    "        return random.randint(1, self.sides)\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"Die(sides={self.sides})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die(sides=6)\n"
     ]
    }
   ],
   "source": [
    "print(Die(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataclasses\n",
    "\n",
    "- Two `Die` object with the same number of sides have the same behavior and represent the same probablility distribution, but with the default version of `__eq__`, two `Die` objects declared separately will never be equal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "six_sided = Die(6)\n",
    "six_sided == six_sided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "six_sided == Die(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Die(6) == Die(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Die(Distribution):\n",
    "    def __init__(self, sides):\n",
    "        self.sides = sides\n",
    "    def sample(self):\n",
    "        return random.randint(1, self.sides)\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"Die(sides={self.sides})\"\n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, Die):\n",
    "            return self.sides == other.sides\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Die(6) == Die(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Die(6) == None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Python 3.7 introduces a feature that fixes all of these problems: `dataclases`. The `dataclasses` module provides a decorator that lets up write a class that behaves like `Die` without needing to manually implement `__init__`, `__repr__`, or `__eq__`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Die(Distribution):\n",
    "    sides: int\n",
    "    def sample(self):\n",
    "        return random.randint(1, self.sides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Die(6) == Die(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Immutability\n",
    "\n",
    "- Changing state can create invisible conncections between seemingly separate parts of the codebase, which becomes hard to mentally track. \n",
    "\n",
    "- It is better to have the language prevent us from doing the wrong thing than relying on pure convention. Normal Python classes don't have a convenient  way to stop attributes from changing, but luckily dataclasses do:\n",
    "\n",
    "    - With `frozen=True`, attempting to change sides will raise an exception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Die(Distribution):\n",
    "    \n",
    "    sides: int\n",
    "    def sample(self):\n",
    "        return random.randint(1, self.sides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Die(6)\n",
    "# an exception is raised\n",
    "# d.sides = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- An object that we cannot change is called immutable. Instead of changing the object inplace, we can return a fresh copy with the attribute changed; `dataclassses` provides a `replace` function that makes this easy: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Die(sides=20)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dataclasses\n",
    "\n",
    "d6 = Die(6)\n",
    "d20 = dataclasses.replace(d6, sides=20)\n",
    "d20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`frozen=True` has an important bonus: we can use immutable objects as dictionary keys and set elements. Without `frozen=True`, we would get a `TypeError` because non-frozen dataclases do not implement `__hash__`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Die(Distribution):\n",
    "    \n",
    "    sides: int\n",
    "    def sample(self):\n",
    "        return random.randint(1, self.sides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Die(6)\n",
    "# an excepion occurs\n",
    "# {d: 'abc'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Die(Distribution):\n",
    "    \n",
    "    sides: int\n",
    "    def sample(self):\n",
    "        return random.randint(1, self.sides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Die(sides=6): 'abc'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = Die(6)\n",
    "{d: 'abc'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type variables\n",
    "\n",
    "- The `distribution` class defines an interface for any distribution.\n",
    "\n",
    "- To deal with different types from `sample`, we need type variables. Type variables are also known as 'generics' because they let us write classes that generically work for any type.\n",
    "\n",
    "- To add annotations to the abstract `Distribution` class, we will need to define a type variable for the outcoimes for the distribution, then tell Python that `Distribution` is \"generic\" in that type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Generic, TypeVar\n",
    "\n",
    "# A type variable named \"A\"\n",
    "A = TypeVar(\"A\")\n",
    "\n",
    "# Distribution is \"generic in A\"\n",
    "class Distribution(ABC, Generic[A]):\n",
    "    # sampling must produce a value of type A\n",
    "    def sample(self) -> A:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this code, we defined a type variable A and specified that `Distribution` uses A by inheriting from `Generic[A]`. We can not write type annotations for distributions with specific types of outcomes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Die(Distribution[int]):\n",
    "    \n",
    "    sides: int\n",
    "    def sample(self):\n",
    "        return random.randint(1, self.sides)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This lets us write specialized functions that only work with certain kinds of distributions. Let's say we wanted to write a function that approximated the expected value fo a distribution by sampling repeatedly and calculating the mean. This function works for distributions that have numeric outcomes - `float` or `int`- but not other kinds of distributions. We can annotate this explicitly by using `Distribution[float]:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "\n",
    "def expected_value(d: Distribution[float], n: int=100) -> float:\n",
    "    return statistics.mean(d.sample() for _ in range(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functionality\n",
    "\n",
    "- One of the practical advantages of defining general-purpose abstration in our code is that it gives us a place to add functionality that will work for any instance of the abstraction. \n",
    "\n",
    "- One of the most common operations for a probability distribution that we can sample i drawing $n$ samples.\n",
    "\n",
    "- We could just write a loop every time we needed to do this.\n",
    "\n",
    "```python\n",
    "samples = []\n",
    "for _ in range(100):\n",
    "    samples += [Distribution.sample()]\n",
    "\n",
    "samples\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can add a method for it instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Generic, TypeVar\n",
    "from collections.abc import Sequence\n",
    "\n",
    "# A type variable named \"A\"\n",
    "A = TypeVar(\"A\")\n",
    "\n",
    "# Distribution is \"generic in A\"\n",
    "class Distribution(ABC, Generic[A]):\n",
    "    \n",
    "    def sample_n(self, n:int) -> Sequence[A]:\n",
    "        return [self.sample() for _ in range(n)]\n",
    "    \n",
    "    # sampling must produce a value of type A\n",
    "    def sample(self) -> A:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The impression here is different - it's using a list comprehension rather than a normal `for` loop. The more important distinction happens when we use the method; instead of needing a `for` loop or list comprehension each time, we can jusy write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution = Distribution()\n",
    "\n",
    "samples = distribution.sample_n(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This pattern of implmenting general-purpose functions on our abstractions becomes a lot more useful as the functions themselves become more complicated.\n",
    "\n",
    "- There is another advantage to defining methods like `sample_n`: some kinds of distributions might have more efficient or more accurate ways to implement the same logic. If that's the case, we would override `sample_n` to use the better implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "@dataclass\n",
    "class Gaussian(Distribution[float]):\n",
    "    mu: float\n",
    "    sigma: float\n",
    "    \n",
    "    def sample(self) -> float:\n",
    "        return np.random.normal(loc=self.mu, scale=self.sigma)\n",
    "    \n",
    "    def sample_n(self, n: int) -> Sequence[float]:\n",
    "        return np.random.normal(loc=self.mu, scale=self.sigma, size=n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `numpy` is optimized for array operations, which means that there is an up-front cost to calling `numpy.random.normal` the first time, but it can quickly generate additional samples after that. The performance impact is significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43.988386292010546"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "d = Gaussian(mu=0, sigma=1)\n",
    "timeit.timeit(lambda: [d.sample() for _ in range(100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1296967500820756"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeit.timeit(lambda: d.sample_n(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstraction over computation\n",
    "\n",
    "- Classes do give us one way to model behavior: methods. A common analogy is that objects act as \"nouns\" and methods act as \"verbs\".\n",
    "\n",
    "    - 1. If we implement a new type of distribution with a custom sample method, we get `sample_n` for free for that distribution.\n",
    "\n",
    "    - 2. If we implement a new type of distribution that has a way to get $n$ samples fasater than calling sample $n$ times, we can override the method to use the faster algorithm.\n",
    "\n",
    "    - If we made `sample_n` function we could get 1, but not 2. If we left `sample_n` as an abstract method, we'd get 2, but not 1. Having a non-abstract method on the abstract class gives us the best of both worlds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First-class functions\n",
    "\n",
    "- One way we could work around this would be to represent functions as objects with a single method. We'd be able to pass them around just like normal values and, when we needed to actually perform the action or computation.\n",
    "\n",
    "- First class functions give us a new way to abstract over computation. Methods let us talk about the same kind of behavior for differnt objects. \n",
    "\n",
    "- A simple example might be repeating the same action $n$ times. Without an abstraction, we might do this with a `for` loop:\n",
    "\n",
    "```python\n",
    "for _ in range(10):\n",
    "    do_something()\n",
    "```\n",
    "\n",
    "- We could factor this logic into a function that look `n` and `do_something` as arguments:\n",
    "\n",
    "```python\n",
    "def repeat(action: Callable, n: int):\n",
    "    for _ in range(n):\n",
    "        actoin()\n",
    "\n",
    "repeat(do_something, 10)\n",
    "```\n",
    "\n",
    "- If we wanted the type of a function that took an `int` and a `str` as input and returned a bool, we would write `Callable[[int, str], bool]`.\n",
    "\n",
    "- Let's look at the expeted_value function we defined earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the expeted_value function we defined earlier.\n",
    "def expected_value(d: Distribution[float], n: int) -> float:\n",
    "    return statistics.mean(d.sample() for _ in range(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- An alternative would be to provide the mapping as an argument to the `expected_value` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "def expected_value(\n",
    "    d: Distribution[A],\n",
    "    f: Callable[[A], float],\n",
    "    n: int\n",
    ") -> float:\n",
    "    return statistics.mean(f(d.sample()) for _ in range(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It's the same `mean` calculation as previously, except we apply `f` to each outcome. This small changes has made the function far more flexible: we can now call `expected_value` on any sort of `Distribution`m bit just `Distribution[float]`.\n",
    "\n",
    "```python\n",
    "def payoff(coin: Coin) -> float:\n",
    "    return 1.0 if coin == 'heads' else 0.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The idea key to renember is that functions are values that we can pass around or store just like any other object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lambdas\n",
    "\n",
    "- Lambdas are function literals. We can write a `lambda` expression to get a function without giving it a name.\n",
    "\n",
    "```python\n",
    "expected_values(coin_flip, lambda coin: 1.0 if coin == \"heads\" else 0.0)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterative algorithms\n",
    "\n",
    "- For example, we can approximate the square root of $a$ by starting with some initial guess $x_0$ and repeatedly calculating $x_{n+1}$:\n",
    "\n",
    "$$x_{n+1}=\\frac{x_n+\\frac{a}{x_n}}{2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sqrt(a: float) -> float:\n",
    "    x = a / 2 # initial guess\n",
    "    x_n = 0\n",
    "    while abs(x_n - x) > 0.01:\n",
    "        x_n = (x + (a / x)) / 2\n",
    "    return x_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The first improvement we can make is to turn the `0.01` into an extra parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sqrt(a: float, threshold: float) -> float:\n",
    "    x = a / 2   # initial guess\n",
    "    x_n = 0\n",
    "    while abs(x_n - x) > threshold:\n",
    "        x_n = (x + (a / x)) / 2\n",
    "    return x_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterators and generators\n",
    "\n",
    "- We need some way to abstract over iteration in some way that lets us separate producing values iteratively from cosumuing them.\n",
    "\n",
    "- Luckily, Python provides powerful facitities for doing exactly this: iterators and generators. Iterators give us a way of consuming values and generators give us a way of producing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "3\n",
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for x in [3, 2, 1]: print(x)\n",
    "for x in {3, 2, 1}: print(x)\n",
    "for x in range(3): print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note how the iterator for the set({3, 2, 1}) prints 1 2 3 rather 3 2 1 - sets do not preserve the order in which elements are added.\n",
    "\n",
    "- When we iterate over a dictionary, we will print the keys rather than the values because that is the default iterator. To get values or key-value pairs we'd need to use the `values` and `items` methods respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "b\n",
      "c\n",
      "1\n",
      "2\n",
      "3\n",
      "a 1\n",
      "b 2\n",
      "c 3\n"
     ]
    }
   ],
   "source": [
    "d = {'a': 1, 'b': 2, 'c': 3}\n",
    "for k in d: print(k)\n",
    "for v in d.values(): print(v)\n",
    "for k, v in d.items(): print(k, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Python's `list` function can convert any iterator into a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 5)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The Python standard library has a set of operations like this in the `itertools` modules. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 2]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# itertools.takewhile lets us stop iterating as soon as some condition stops holding\n",
    "import itertools\n",
    "\n",
    "elements = [1, 3, 2, 5, 3]\n",
    "list(itertools.takewhile(lambda x: x < 5, elements))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How do we define our own iterators? In the most general sense, a Python Iterator is any object that implements a `__next__()` method.\n",
    "\n",
    "- However, Python has a more convenient way to create an iterator by creating a generator using `yield` keyworld. `yield` acts similar to return from a function, except instead of stopping the function altogether, it outputs yielded value to an iterator and pauses the function until the yielded element is consumed by the caller.\n",
    "\n",
    "\n",
    "- Instead of looping and stopping based on some condition, we'll write a version of `sqrt` that returns an iterator with each iteration of the algorithm as a value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Iterator\n",
    "\n",
    "def sqrt(a: float) -> Iterator[float]:\n",
    "    x = a /2    # initial guess\n",
    "    while True:\n",
    "        x = (x + (a / x)) / 2\n",
    "        yield x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With this version, we update $x$ at each iteration and then `yield` the updated value. The caller of the cunction gets an iterator that contains an infinete number of iterations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We probably want the threshold-based convergence logic. Since we now have a first-class abstraction for iteration, we can write a general-purpose converge function that takes an iterator and returns a version of that same iterator that stops as soon as two values are sufficiently close."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Iterator\n",
    "\n",
    "def converge(values: Iterator[float], threshold: float) -> Iterator[float]:\n",
    "    for a, b in itertools.pairwise(values):\n",
    "        yield a \n",
    "        if abs(a - b) < threshold:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Each function takes an iterator as an input and returns an iterator as an output. We get a major advantage when it is iterator $\\rightarrow$ iterator operations compose.\n",
    "\n",
    "- We don't need to write a new version of `sqrt` or even `converge` to do this; instead, we can use converge with `itertools.islice`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10000000\n",
    "results = converge(sqrt(n), 0.001)\n",
    "capped_results = itertools.islice(results, 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This is a powerful programming style because we can write and test each opration - `sqrt`, `converge`, `islice` - in isolation and get complex behavior by combining them in the right way. If we were writing the same logic without iterators, we would need a single loop that calculated each step of `sqrt`, checked for convergence and kept a counter to stop after 10,000 steps."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
