{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\woojin\\anaconda3\\envs\\reinforce\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import ptan\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMMA = 0.99\n",
    "LEARNING_RATE = 0.01\n",
    "# specifying how many complete episodes we will use for training\n",
    "EPISODE_TO_TRAIN = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PGN(nn.Module):\n",
    "    def __init__(self, input_size, n_actions):\n",
    "        super(PGN, self).__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, n_actions)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_qvals(rewards):\n",
    "    res = []\n",
    "    sum_r = 0.0\n",
    "    for r in reversed(rewards):\n",
    "        sum_r *= GAMMA\n",
    "        sum_r += r \n",
    "        res.append(sum_r)\n",
    "    return list(reversed(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PGN(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v0\")\n",
    "writer = SummaryWriter(comment=\"-cartpole-reinforce\")\n",
    "\n",
    "net = PGN(env.observation_space.shape[0], env.action_space.n)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ptan.agent.PolicyAgent(net, preprocessor=ptan.agent.float32_preprocessor,\n",
    "                               apply_softmax=True)\n",
    "exp_source = ptan.experience.ExperienceSourceFirstLast(env, agent, gamma=GAMMA)\n",
    "optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rewards = []\n",
    "step_idx = 0\n",
    "done_episodes = 0\n",
    "\n",
    "batch_episodes = 0\n",
    "batch_states, batch_actions, batch_qvals = [], [], []\n",
    "cur_rewards = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15: reward:  15.00, mean_100:  15.00, episodes: 1\n",
      "62: reward:  47.00, mean_100:  31.00, episodes: 2\n",
      "88: reward:  26.00, mean_100:  29.33, episodes: 3\n",
      "103: reward:  15.00, mean_100:  25.75, episodes: 4\n",
      "131: reward:  28.00, mean_100:  26.20, episodes: 5\n",
      "176: reward:  45.00, mean_100:  29.33, episodes: 6\n",
      "197: reward:  21.00, mean_100:  28.14, episodes: 7\n",
      "211: reward:  14.00, mean_100:  26.38, episodes: 8\n",
      "226: reward:  15.00, mean_100:  25.11, episodes: 9\n",
      "259: reward:  33.00, mean_100:  25.90, episodes: 10\n",
      "296: reward:  37.00, mean_100:  26.91, episodes: 11\n",
      "312: reward:  16.00, mean_100:  26.00, episodes: 12\n",
      "345: reward:  33.00, mean_100:  26.54, episodes: 13\n",
      "385: reward:  40.00, mean_100:  27.50, episodes: 14\n",
      "409: reward:  24.00, mean_100:  27.27, episodes: 15\n",
      "449: reward:  40.00, mean_100:  28.06, episodes: 16\n",
      "491: reward:  42.00, mean_100:  28.88, episodes: 17\n",
      "522: reward:  31.00, mean_100:  29.00, episodes: 18\n",
      "534: reward:  12.00, mean_100:  28.11, episodes: 19\n",
      "571: reward:  37.00, mean_100:  28.55, episodes: 20\n",
      "624: reward:  53.00, mean_100:  29.71, episodes: 21\n",
      "647: reward:  23.00, mean_100:  29.41, episodes: 22\n",
      "690: reward:  43.00, mean_100:  30.00, episodes: 23\n",
      "720: reward:  30.00, mean_100:  30.00, episodes: 24\n",
      "755: reward:  35.00, mean_100:  30.20, episodes: 25\n",
      "798: reward:  43.00, mean_100:  30.69, episodes: 26\n",
      "870: reward:  72.00, mean_100:  32.22, episodes: 27\n",
      "955: reward:  85.00, mean_100:  34.11, episodes: 28\n",
      "1027: reward:  72.00, mean_100:  35.41, episodes: 29\n",
      "1050: reward:  23.00, mean_100:  35.00, episodes: 30\n",
      "1099: reward:  49.00, mean_100:  35.45, episodes: 31\n",
      "1143: reward:  44.00, mean_100:  35.72, episodes: 32\n",
      "1178: reward:  35.00, mean_100:  35.70, episodes: 33\n",
      "1214: reward:  36.00, mean_100:  35.71, episodes: 34\n",
      "1261: reward:  47.00, mean_100:  36.03, episodes: 35\n",
      "1301: reward:  40.00, mean_100:  36.14, episodes: 36\n",
      "1340: reward:  39.00, mean_100:  36.22, episodes: 37\n",
      "1378: reward:  38.00, mean_100:  36.26, episodes: 38\n",
      "1422: reward:  44.00, mean_100:  36.46, episodes: 39\n",
      "1440: reward:  18.00, mean_100:  36.00, episodes: 40\n",
      "1455: reward:  15.00, mean_100:  35.49, episodes: 41\n",
      "1507: reward:  52.00, mean_100:  35.88, episodes: 42\n",
      "1553: reward:  46.00, mean_100:  36.12, episodes: 43\n",
      "1580: reward:  27.00, mean_100:  35.91, episodes: 44\n",
      "1621: reward:  41.00, mean_100:  36.02, episodes: 45\n",
      "1656: reward:  35.00, mean_100:  36.00, episodes: 46\n",
      "1676: reward:  20.00, mean_100:  35.66, episodes: 47\n",
      "1726: reward:  50.00, mean_100:  35.96, episodes: 48\n",
      "1763: reward:  37.00, mean_100:  35.98, episodes: 49\n",
      "1793: reward:  30.00, mean_100:  35.86, episodes: 50\n",
      "1861: reward:  68.00, mean_100:  36.49, episodes: 51\n",
      "1886: reward:  25.00, mean_100:  36.27, episodes: 52\n",
      "1941: reward:  55.00, mean_100:  36.62, episodes: 53\n",
      "1975: reward:  34.00, mean_100:  36.57, episodes: 54\n",
      "2011: reward:  36.00, mean_100:  36.56, episodes: 55\n",
      "2041: reward:  30.00, mean_100:  36.45, episodes: 56\n",
      "2067: reward:  26.00, mean_100:  36.26, episodes: 57\n",
      "2128: reward:  61.00, mean_100:  36.69, episodes: 58\n",
      "2170: reward:  42.00, mean_100:  36.78, episodes: 59\n",
      "2212: reward:  42.00, mean_100:  36.87, episodes: 60\n",
      "2279: reward:  67.00, mean_100:  37.36, episodes: 61\n",
      "2311: reward:  32.00, mean_100:  37.27, episodes: 62\n",
      "2478: reward: 167.00, mean_100:  39.33, episodes: 63\n",
      "2581: reward: 103.00, mean_100:  40.33, episodes: 64\n",
      "2611: reward:  30.00, mean_100:  40.17, episodes: 65\n",
      "2689: reward:  78.00, mean_100:  40.74, episodes: 66\n",
      "2733: reward:  44.00, mean_100:  40.79, episodes: 67\n",
      "2784: reward:  51.00, mean_100:  40.94, episodes: 68\n",
      "2837: reward:  53.00, mean_100:  41.12, episodes: 69\n",
      "2892: reward:  55.00, mean_100:  41.31, episodes: 70\n",
      "2949: reward:  57.00, mean_100:  41.54, episodes: 71\n",
      "2992: reward:  43.00, mean_100:  41.56, episodes: 72\n",
      "3048: reward:  56.00, mean_100:  41.75, episodes: 73\n",
      "3087: reward:  39.00, mean_100:  41.72, episodes: 74\n",
      "3173: reward:  86.00, mean_100:  42.31, episodes: 75\n",
      "3226: reward:  53.00, mean_100:  42.45, episodes: 76\n",
      "3394: reward: 168.00, mean_100:  44.08, episodes: 77\n",
      "3456: reward:  62.00, mean_100:  44.31, episodes: 78\n",
      "3485: reward:  29.00, mean_100:  44.11, episodes: 79\n",
      "3529: reward:  44.00, mean_100:  44.11, episodes: 80\n",
      "3635: reward: 106.00, mean_100:  44.88, episodes: 81\n",
      "3772: reward: 137.00, mean_100:  46.00, episodes: 82\n",
      "3818: reward:  46.00, mean_100:  46.00, episodes: 83\n",
      "3917: reward:  99.00, mean_100:  46.63, episodes: 84\n",
      "3985: reward:  68.00, mean_100:  46.88, episodes: 85\n",
      "4038: reward:  53.00, mean_100:  46.95, episodes: 86\n",
      "4082: reward:  44.00, mean_100:  46.92, episodes: 87\n",
      "4158: reward:  76.00, mean_100:  47.25, episodes: 88\n",
      "4195: reward:  37.00, mean_100:  47.13, episodes: 89\n",
      "4247: reward:  52.00, mean_100:  47.19, episodes: 90\n",
      "4284: reward:  37.00, mean_100:  47.08, episodes: 91\n",
      "4343: reward:  59.00, mean_100:  47.21, episodes: 92\n",
      "4392: reward:  49.00, mean_100:  47.23, episodes: 93\n",
      "4441: reward:  49.00, mean_100:  47.24, episodes: 94\n",
      "4512: reward:  71.00, mean_100:  47.49, episodes: 95\n",
      "4606: reward:  94.00, mean_100:  47.98, episodes: 96\n",
      "4681: reward:  75.00, mean_100:  48.26, episodes: 97\n",
      "4734: reward:  53.00, mean_100:  48.31, episodes: 98\n",
      "4826: reward:  92.00, mean_100:  48.75, episodes: 99\n",
      "4872: reward:  46.00, mean_100:  48.72, episodes: 100\n",
      "4915: reward:  43.00, mean_100:  49.00, episodes: 101\n",
      "4955: reward:  40.00, mean_100:  48.93, episodes: 102\n",
      "4999: reward:  44.00, mean_100:  49.11, episodes: 103\n",
      "5033: reward:  34.00, mean_100:  49.30, episodes: 104\n",
      "5112: reward:  79.00, mean_100:  49.81, episodes: 105\n",
      "5185: reward:  73.00, mean_100:  50.09, episodes: 106\n",
      "5238: reward:  53.00, mean_100:  50.41, episodes: 107\n",
      "5274: reward:  36.00, mean_100:  50.63, episodes: 108\n",
      "5314: reward:  40.00, mean_100:  50.88, episodes: 109\n",
      "5377: reward:  63.00, mean_100:  51.18, episodes: 110\n",
      "5418: reward:  41.00, mean_100:  51.22, episodes: 111\n",
      "5450: reward:  32.00, mean_100:  51.38, episodes: 112\n",
      "5486: reward:  36.00, mean_100:  51.41, episodes: 113\n",
      "5543: reward:  57.00, mean_100:  51.58, episodes: 114\n",
      "5575: reward:  32.00, mean_100:  51.66, episodes: 115\n",
      "5609: reward:  34.00, mean_100:  51.60, episodes: 116\n",
      "5649: reward:  40.00, mean_100:  51.58, episodes: 117\n",
      "5685: reward:  36.00, mean_100:  51.63, episodes: 118\n",
      "5729: reward:  44.00, mean_100:  51.95, episodes: 119\n",
      "5823: reward:  94.00, mean_100:  52.52, episodes: 120\n",
      "5893: reward:  70.00, mean_100:  52.69, episodes: 121\n",
      "5936: reward:  43.00, mean_100:  52.89, episodes: 122\n",
      "5964: reward:  28.00, mean_100:  52.74, episodes: 123\n",
      "6024: reward:  60.00, mean_100:  53.04, episodes: 124\n",
      "6049: reward:  25.00, mean_100:  52.94, episodes: 125\n",
      "6161: reward: 112.00, mean_100:  53.63, episodes: 126\n",
      "6196: reward:  35.00, mean_100:  53.26, episodes: 127\n",
      "6232: reward:  36.00, mean_100:  52.77, episodes: 128\n",
      "6277: reward:  45.00, mean_100:  52.50, episodes: 129\n",
      "6340: reward:  63.00, mean_100:  52.90, episodes: 130\n",
      "6382: reward:  42.00, mean_100:  52.83, episodes: 131\n",
      "6461: reward:  79.00, mean_100:  53.18, episodes: 132\n",
      "6615: reward: 154.00, mean_100:  54.37, episodes: 133\n",
      "6718: reward: 103.00, mean_100:  55.04, episodes: 134\n",
      "6772: reward:  54.00, mean_100:  55.11, episodes: 135\n",
      "6817: reward:  45.00, mean_100:  55.16, episodes: 136\n",
      "6861: reward:  44.00, mean_100:  55.21, episodes: 137\n",
      "6998: reward: 137.00, mean_100:  56.20, episodes: 138\n",
      "7063: reward:  65.00, mean_100:  56.41, episodes: 139\n",
      "7131: reward:  68.00, mean_100:  56.91, episodes: 140\n",
      "7211: reward:  80.00, mean_100:  57.56, episodes: 141\n",
      "7406: reward: 195.00, mean_100:  58.99, episodes: 142\n",
      "7502: reward:  96.00, mean_100:  59.49, episodes: 143\n",
      "7544: reward:  42.00, mean_100:  59.64, episodes: 144\n",
      "7631: reward:  87.00, mean_100:  60.10, episodes: 145\n",
      "7691: reward:  60.00, mean_100:  60.35, episodes: 146\n",
      "7755: reward:  64.00, mean_100:  60.79, episodes: 147\n",
      "7803: reward:  48.00, mean_100:  60.77, episodes: 148\n",
      "7909: reward: 106.00, mean_100:  61.46, episodes: 149\n",
      "7955: reward:  46.00, mean_100:  61.62, episodes: 150\n",
      "8016: reward:  61.00, mean_100:  61.55, episodes: 151\n",
      "8099: reward:  83.00, mean_100:  62.13, episodes: 152\n",
      "8161: reward:  62.00, mean_100:  62.20, episodes: 153\n",
      "8213: reward:  52.00, mean_100:  62.38, episodes: 154\n",
      "8271: reward:  58.00, mean_100:  62.60, episodes: 155\n",
      "8341: reward:  70.00, mean_100:  63.00, episodes: 156\n",
      "8489: reward: 148.00, mean_100:  64.22, episodes: 157\n",
      "8579: reward:  90.00, mean_100:  64.51, episodes: 158\n",
      "8653: reward:  74.00, mean_100:  64.83, episodes: 159\n",
      "8787: reward: 134.00, mean_100:  65.75, episodes: 160\n",
      "8844: reward:  57.00, mean_100:  65.65, episodes: 161\n",
      "8988: reward: 144.00, mean_100:  66.77, episodes: 162\n",
      "9099: reward: 111.00, mean_100:  66.21, episodes: 163\n",
      "9185: reward:  86.00, mean_100:  66.04, episodes: 164\n",
      "9251: reward:  66.00, mean_100:  66.40, episodes: 165\n",
      "9331: reward:  80.00, mean_100:  66.42, episodes: 166\n",
      "9395: reward:  64.00, mean_100:  66.62, episodes: 167\n",
      "9489: reward:  94.00, mean_100:  67.05, episodes: 168\n",
      "9585: reward:  96.00, mean_100:  67.48, episodes: 169\n",
      "9703: reward: 118.00, mean_100:  68.11, episodes: 170\n",
      "9782: reward:  79.00, mean_100:  68.33, episodes: 171\n",
      "9950: reward: 168.00, mean_100:  69.58, episodes: 172\n",
      "10045: reward:  95.00, mean_100:  69.97, episodes: 173\n",
      "10127: reward:  82.00, mean_100:  70.40, episodes: 174\n",
      "10186: reward:  59.00, mean_100:  70.13, episodes: 175\n",
      "10308: reward: 122.00, mean_100:  70.82, episodes: 176\n",
      "10389: reward:  81.00, mean_100:  69.95, episodes: 177\n",
      "10472: reward:  83.00, mean_100:  70.16, episodes: 178\n",
      "10612: reward: 140.00, mean_100:  71.27, episodes: 179\n",
      "10780: reward: 168.00, mean_100:  72.51, episodes: 180\n",
      "10894: reward: 114.00, mean_100:  72.59, episodes: 181\n",
      "10983: reward:  89.00, mean_100:  72.11, episodes: 182\n",
      "11105: reward: 122.00, mean_100:  72.87, episodes: 183\n",
      "11145: reward:  40.00, mean_100:  72.28, episodes: 184\n",
      "11203: reward:  58.00, mean_100:  72.18, episodes: 185\n",
      "11372: reward: 169.00, mean_100:  73.34, episodes: 186\n",
      "11468: reward:  96.00, mean_100:  73.86, episodes: 187\n",
      "11648: reward: 180.00, mean_100:  74.90, episodes: 188\n",
      "11733: reward:  85.00, mean_100:  75.38, episodes: 189\n",
      "11778: reward:  45.00, mean_100:  75.31, episodes: 190\n",
      "11876: reward:  98.00, mean_100:  75.92, episodes: 191\n",
      "12065: reward: 189.00, mean_100:  77.22, episodes: 192\n",
      "12265: reward: 200.00, mean_100:  78.73, episodes: 193\n",
      "12338: reward:  73.00, mean_100:  78.97, episodes: 194\n",
      "12439: reward: 101.00, mean_100:  79.27, episodes: 195\n",
      "12503: reward:  64.00, mean_100:  78.97, episodes: 196\n",
      "12556: reward:  53.00, mean_100:  78.75, episodes: 197\n",
      "12679: reward: 123.00, mean_100:  79.45, episodes: 198\n",
      "12729: reward:  50.00, mean_100:  79.03, episodes: 199\n",
      "12848: reward: 119.00, mean_100:  79.76, episodes: 200\n",
      "12954: reward: 106.00, mean_100:  80.39, episodes: 201\n",
      "13026: reward:  72.00, mean_100:  80.71, episodes: 202\n",
      "13084: reward:  58.00, mean_100:  80.85, episodes: 203\n",
      "13241: reward: 157.00, mean_100:  82.08, episodes: 204\n",
      "13327: reward:  86.00, mean_100:  82.15, episodes: 205\n",
      "13385: reward:  58.00, mean_100:  82.00, episodes: 206\n",
      "13495: reward: 110.00, mean_100:  82.57, episodes: 207\n",
      "13610: reward: 115.00, mean_100:  83.36, episodes: 208\n",
      "13669: reward:  59.00, mean_100:  83.55, episodes: 209\n",
      "13791: reward: 122.00, mean_100:  84.14, episodes: 210\n",
      "13909: reward: 118.00, mean_100:  84.91, episodes: 211\n",
      "13984: reward:  75.00, mean_100:  85.34, episodes: 212\n",
      "14058: reward:  74.00, mean_100:  85.72, episodes: 213\n",
      "14199: reward: 141.00, mean_100:  86.56, episodes: 214\n",
      "14291: reward:  92.00, mean_100:  87.16, episodes: 215\n",
      "14379: reward:  88.00, mean_100:  87.70, episodes: 216\n",
      "14434: reward:  55.00, mean_100:  87.85, episodes: 217\n",
      "14507: reward:  73.00, mean_100:  88.22, episodes: 218\n",
      "14642: reward: 135.00, mean_100:  89.13, episodes: 219\n",
      "14740: reward:  98.00, mean_100:  89.17, episodes: 220\n",
      "14827: reward:  87.00, mean_100:  89.34, episodes: 221\n",
      "14904: reward:  77.00, mean_100:  89.68, episodes: 222\n",
      "14966: reward:  62.00, mean_100:  90.02, episodes: 223\n",
      "15097: reward: 131.00, mean_100:  90.73, episodes: 224\n",
      "15226: reward: 129.00, mean_100:  91.77, episodes: 225\n",
      "15318: reward:  92.00, mean_100:  91.57, episodes: 226\n",
      "15406: reward:  88.00, mean_100:  92.10, episodes: 227\n",
      "15490: reward:  84.00, mean_100:  92.58, episodes: 228\n",
      "15542: reward:  52.00, mean_100:  92.65, episodes: 229\n",
      "15644: reward: 102.00, mean_100:  93.04, episodes: 230\n",
      "15787: reward: 143.00, mean_100:  94.05, episodes: 231\n",
      "15987: reward: 200.00, mean_100:  95.26, episodes: 232\n",
      "16187: reward: 200.00, mean_100:  95.72, episodes: 233\n",
      "16387: reward: 200.00, mean_100:  96.69, episodes: 234\n",
      "16587: reward: 200.00, mean_100:  98.15, episodes: 235\n",
      "16740: reward: 153.00, mean_100:  99.23, episodes: 236\n",
      "16940: reward: 200.00, mean_100: 100.79, episodes: 237\n",
      "17140: reward: 200.00, mean_100: 101.42, episodes: 238\n",
      "17340: reward: 200.00, mean_100: 102.77, episodes: 239\n",
      "17489: reward: 149.00, mean_100: 103.58, episodes: 240\n",
      "17689: reward: 200.00, mean_100: 104.78, episodes: 241\n",
      "17889: reward: 200.00, mean_100: 104.83, episodes: 242\n",
      "18089: reward: 200.00, mean_100: 105.87, episodes: 243\n",
      "18289: reward: 200.00, mean_100: 107.45, episodes: 244\n",
      "18489: reward: 200.00, mean_100: 108.58, episodes: 245\n",
      "18689: reward: 200.00, mean_100: 109.98, episodes: 246\n",
      "18835: reward: 146.00, mean_100: 110.80, episodes: 247\n",
      "19035: reward: 200.00, mean_100: 112.32, episodes: 248\n",
      "19235: reward: 200.00, mean_100: 113.26, episodes: 249\n",
      "19372: reward: 137.00, mean_100: 114.17, episodes: 250\n",
      "19572: reward: 200.00, mean_100: 115.56, episodes: 251\n",
      "19741: reward: 169.00, mean_100: 116.42, episodes: 252\n",
      "19941: reward: 200.00, mean_100: 117.80, episodes: 253\n",
      "20141: reward: 200.00, mean_100: 119.28, episodes: 254\n",
      "20256: reward: 115.00, mean_100: 119.85, episodes: 255\n",
      "20456: reward: 200.00, mean_100: 121.15, episodes: 256\n",
      "20606: reward: 150.00, mean_100: 121.17, episodes: 257\n",
      "20781: reward: 175.00, mean_100: 122.02, episodes: 258\n",
      "20981: reward: 200.00, mean_100: 123.28, episodes: 259\n",
      "21181: reward: 200.00, mean_100: 123.94, episodes: 260\n",
      "21334: reward: 153.00, mean_100: 124.90, episodes: 261\n",
      "21455: reward: 121.00, mean_100: 124.67, episodes: 262\n",
      "21595: reward: 140.00, mean_100: 124.96, episodes: 263\n",
      "21735: reward: 140.00, mean_100: 125.50, episodes: 264\n",
      "21880: reward: 145.00, mean_100: 126.29, episodes: 265\n",
      "21957: reward:  77.00, mean_100: 126.26, episodes: 266\n",
      "22081: reward: 124.00, mean_100: 126.86, episodes: 267\n",
      "22219: reward: 138.00, mean_100: 127.30, episodes: 268\n",
      "22276: reward:  57.00, mean_100: 126.91, episodes: 269\n",
      "22374: reward:  98.00, mean_100: 126.71, episodes: 270\n",
      "22457: reward:  83.00, mean_100: 126.75, episodes: 271\n",
      "22569: reward: 112.00, mean_100: 126.19, episodes: 272\n",
      "22639: reward:  70.00, mean_100: 125.94, episodes: 273\n",
      "22717: reward:  78.00, mean_100: 125.90, episodes: 274\n",
      "22784: reward:  67.00, mean_100: 125.98, episodes: 275\n",
      "22856: reward:  72.00, mean_100: 125.48, episodes: 276\n",
      "22922: reward:  66.00, mean_100: 125.33, episodes: 277\n",
      "23018: reward:  96.00, mean_100: 125.46, episodes: 278\n",
      "23091: reward:  73.00, mean_100: 124.79, episodes: 279\n",
      "23162: reward:  71.00, mean_100: 123.82, episodes: 280\n",
      "23262: reward: 100.00, mean_100: 123.68, episodes: 281\n",
      "23322: reward:  60.00, mean_100: 123.39, episodes: 282\n",
      "23395: reward:  73.00, mean_100: 122.90, episodes: 283\n",
      "23483: reward:  88.00, mean_100: 123.38, episodes: 284\n",
      "23567: reward:  84.00, mean_100: 123.64, episodes: 285\n",
      "23664: reward:  97.00, mean_100: 122.92, episodes: 286\n",
      "23751: reward:  87.00, mean_100: 122.83, episodes: 287\n",
      "23809: reward:  58.00, mean_100: 121.61, episodes: 288\n",
      "23918: reward: 109.00, mean_100: 121.85, episodes: 289\n",
      "23996: reward:  78.00, mean_100: 122.18, episodes: 290\n",
      "24073: reward:  77.00, mean_100: 121.97, episodes: 291\n",
      "24141: reward:  68.00, mean_100: 120.76, episodes: 292\n",
      "24244: reward: 103.00, mean_100: 119.79, episodes: 293\n",
      "24392: reward: 148.00, mean_100: 120.54, episodes: 294\n",
      "24452: reward:  60.00, mean_100: 120.13, episodes: 295\n",
      "24546: reward:  94.00, mean_100: 120.43, episodes: 296\n",
      "24661: reward: 115.00, mean_100: 121.05, episodes: 297\n",
      "24783: reward: 122.00, mean_100: 121.04, episodes: 298\n",
      "24898: reward: 115.00, mean_100: 121.69, episodes: 299\n",
      "25036: reward: 138.00, mean_100: 121.88, episodes: 300\n",
      "25139: reward: 103.00, mean_100: 121.85, episodes: 301\n",
      "25261: reward: 122.00, mean_100: 122.35, episodes: 302\n",
      "25402: reward: 141.00, mean_100: 123.18, episodes: 303\n",
      "25527: reward: 125.00, mean_100: 122.86, episodes: 304\n",
      "25639: reward: 112.00, mean_100: 123.12, episodes: 305\n",
      "25765: reward: 126.00, mean_100: 123.80, episodes: 306\n",
      "25912: reward: 147.00, mean_100: 124.17, episodes: 307\n",
      "26012: reward: 100.00, mean_100: 124.02, episodes: 308\n",
      "26141: reward: 129.00, mean_100: 124.72, episodes: 309\n",
      "26288: reward: 147.00, mean_100: 124.97, episodes: 310\n",
      "26405: reward: 117.00, mean_100: 124.96, episodes: 311\n",
      "26535: reward: 130.00, mean_100: 125.51, episodes: 312\n",
      "26648: reward: 113.00, mean_100: 125.90, episodes: 313\n",
      "26762: reward: 114.00, mean_100: 125.63, episodes: 314\n",
      "26903: reward: 141.00, mean_100: 126.12, episodes: 315\n",
      "27024: reward: 121.00, mean_100: 126.45, episodes: 316\n",
      "27147: reward: 123.00, mean_100: 127.13, episodes: 317\n",
      "27284: reward: 137.00, mean_100: 127.77, episodes: 318\n",
      "27398: reward: 114.00, mean_100: 127.56, episodes: 319\n",
      "27563: reward: 165.00, mean_100: 128.23, episodes: 320\n",
      "27677: reward: 114.00, mean_100: 128.50, episodes: 321\n",
      "27819: reward: 142.00, mean_100: 129.15, episodes: 322\n",
      "27966: reward: 147.00, mean_100: 130.00, episodes: 323\n",
      "28097: reward: 131.00, mean_100: 130.00, episodes: 324\n",
      "28212: reward: 115.00, mean_100: 129.86, episodes: 325\n",
      "28320: reward: 108.00, mean_100: 130.02, episodes: 326\n",
      "28460: reward: 140.00, mean_100: 130.54, episodes: 327\n",
      "28583: reward: 123.00, mean_100: 130.93, episodes: 328\n",
      "28718: reward: 135.00, mean_100: 131.76, episodes: 329\n",
      "28826: reward: 108.00, mean_100: 131.82, episodes: 330\n",
      "28961: reward: 135.00, mean_100: 131.74, episodes: 331\n",
      "29078: reward: 117.00, mean_100: 130.91, episodes: 332\n",
      "29203: reward: 125.00, mean_100: 130.16, episodes: 333\n",
      "29340: reward: 137.00, mean_100: 129.53, episodes: 334\n",
      "29491: reward: 151.00, mean_100: 129.04, episodes: 335\n",
      "29614: reward: 123.00, mean_100: 128.74, episodes: 336\n",
      "29747: reward: 133.00, mean_100: 128.07, episodes: 337\n",
      "29865: reward: 118.00, mean_100: 127.25, episodes: 338\n",
      "29982: reward: 117.00, mean_100: 126.42, episodes: 339\n",
      "30090: reward: 108.00, mean_100: 126.01, episodes: 340\n",
      "30191: reward: 101.00, mean_100: 125.02, episodes: 341\n",
      "30312: reward: 121.00, mean_100: 124.23, episodes: 342\n",
      "30436: reward: 124.00, mean_100: 123.47, episodes: 343\n",
      "30542: reward: 106.00, mean_100: 122.53, episodes: 344\n",
      "30626: reward:  84.00, mean_100: 121.37, episodes: 345\n",
      "30744: reward: 118.00, mean_100: 120.55, episodes: 346\n",
      "30811: reward:  67.00, mean_100: 119.76, episodes: 347\n",
      "30921: reward: 110.00, mean_100: 118.86, episodes: 348\n",
      "31052: reward: 131.00, mean_100: 118.17, episodes: 349\n",
      "31176: reward: 124.00, mean_100: 118.04, episodes: 350\n",
      "31293: reward: 117.00, mean_100: 117.21, episodes: 351\n",
      "31407: reward: 114.00, mean_100: 116.66, episodes: 352\n",
      "31546: reward: 139.00, mean_100: 116.05, episodes: 353\n",
      "31649: reward: 103.00, mean_100: 115.08, episodes: 354\n",
      "31765: reward: 116.00, mean_100: 115.09, episodes: 355\n",
      "31873: reward: 108.00, mean_100: 114.17, episodes: 356\n",
      "31989: reward: 116.00, mean_100: 113.83, episodes: 357\n",
      "32119: reward: 130.00, mean_100: 113.38, episodes: 358\n",
      "32242: reward: 123.00, mean_100: 112.61, episodes: 359\n",
      "32372: reward: 130.00, mean_100: 111.91, episodes: 360\n",
      "32483: reward: 111.00, mean_100: 111.49, episodes: 361\n",
      "32625: reward: 142.00, mean_100: 111.70, episodes: 362\n",
      "32733: reward: 108.00, mean_100: 111.38, episodes: 363\n",
      "32853: reward: 120.00, mean_100: 111.18, episodes: 364\n",
      "32981: reward: 128.00, mean_100: 111.01, episodes: 365\n",
      "33096: reward: 115.00, mean_100: 111.39, episodes: 366\n",
      "33236: reward: 140.00, mean_100: 111.55, episodes: 367\n",
      "33365: reward: 129.00, mean_100: 111.46, episodes: 368\n",
      "33490: reward: 125.00, mean_100: 112.14, episodes: 369\n",
      "33616: reward: 126.00, mean_100: 112.42, episodes: 370\n",
      "33753: reward: 137.00, mean_100: 112.96, episodes: 371\n",
      "33900: reward: 147.00, mean_100: 113.31, episodes: 372\n",
      "34037: reward: 137.00, mean_100: 113.98, episodes: 373\n",
      "34178: reward: 141.00, mean_100: 114.61, episodes: 374\n",
      "34318: reward: 140.00, mean_100: 115.34, episodes: 375\n",
      "34462: reward: 144.00, mean_100: 116.06, episodes: 376\n",
      "34612: reward: 150.00, mean_100: 116.90, episodes: 377\n",
      "34768: reward: 156.00, mean_100: 117.50, episodes: 378\n",
      "34905: reward: 137.00, mean_100: 118.14, episodes: 379\n",
      "35051: reward: 146.00, mean_100: 118.89, episodes: 380\n",
      "35219: reward: 168.00, mean_100: 119.57, episodes: 381\n",
      "35405: reward: 186.00, mean_100: 120.83, episodes: 382\n",
      "35568: reward: 163.00, mean_100: 121.73, episodes: 383\n",
      "35711: reward: 143.00, mean_100: 122.28, episodes: 384\n",
      "35854: reward: 143.00, mean_100: 122.87, episodes: 385\n",
      "36009: reward: 155.00, mean_100: 123.45, episodes: 386\n",
      "36140: reward: 131.00, mean_100: 123.89, episodes: 387\n",
      "36295: reward: 155.00, mean_100: 124.86, episodes: 388\n",
      "36483: reward: 188.00, mean_100: 125.65, episodes: 389\n",
      "36630: reward: 147.00, mean_100: 126.34, episodes: 390\n",
      "36809: reward: 179.00, mean_100: 127.36, episodes: 391\n",
      "36956: reward: 147.00, mean_100: 128.15, episodes: 392\n",
      "37113: reward: 157.00, mean_100: 128.69, episodes: 393\n",
      "37277: reward: 164.00, mean_100: 128.85, episodes: 394\n",
      "37466: reward: 189.00, mean_100: 130.14, episodes: 395\n",
      "37639: reward: 173.00, mean_100: 130.93, episodes: 396\n",
      "37821: reward: 182.00, mean_100: 131.60, episodes: 397\n",
      "38007: reward: 186.00, mean_100: 132.24, episodes: 398\n",
      "38207: reward: 200.00, mean_100: 133.09, episodes: 399\n",
      "38384: reward: 177.00, mean_100: 133.48, episodes: 400\n",
      "38564: reward: 180.00, mean_100: 134.25, episodes: 401\n",
      "38764: reward: 200.00, mean_100: 135.03, episodes: 402\n",
      "38950: reward: 186.00, mean_100: 135.48, episodes: 403\n",
      "39150: reward: 200.00, mean_100: 136.23, episodes: 404\n",
      "39340: reward: 190.00, mean_100: 137.01, episodes: 405\n",
      "39540: reward: 200.00, mean_100: 137.75, episodes: 406\n",
      "39722: reward: 182.00, mean_100: 138.10, episodes: 407\n",
      "39905: reward: 183.00, mean_100: 138.93, episodes: 408\n",
      "40105: reward: 200.00, mean_100: 139.64, episodes: 409\n",
      "40297: reward: 192.00, mean_100: 140.09, episodes: 410\n",
      "40497: reward: 200.00, mean_100: 140.92, episodes: 411\n",
      "40697: reward: 200.00, mean_100: 141.62, episodes: 412\n",
      "40897: reward: 200.00, mean_100: 142.49, episodes: 413\n",
      "41097: reward: 200.00, mean_100: 143.35, episodes: 414\n",
      "41297: reward: 200.00, mean_100: 143.94, episodes: 415\n",
      "41497: reward: 200.00, mean_100: 144.73, episodes: 416\n",
      "41697: reward: 200.00, mean_100: 145.50, episodes: 417\n",
      "41897: reward: 200.00, mean_100: 146.13, episodes: 418\n",
      "42097: reward: 200.00, mean_100: 146.99, episodes: 419\n",
      "42297: reward: 200.00, mean_100: 147.34, episodes: 420\n",
      "42497: reward: 200.00, mean_100: 148.20, episodes: 421\n",
      "42697: reward: 200.00, mean_100: 148.78, episodes: 422\n",
      "42897: reward: 200.00, mean_100: 149.31, episodes: 423\n",
      "43097: reward: 200.00, mean_100: 150.00, episodes: 424\n",
      "43297: reward: 200.00, mean_100: 150.85, episodes: 425\n",
      "43497: reward: 200.00, mean_100: 151.77, episodes: 426\n",
      "43691: reward: 194.00, mean_100: 152.31, episodes: 427\n",
      "43891: reward: 200.00, mean_100: 153.08, episodes: 428\n",
      "44090: reward: 199.00, mean_100: 153.72, episodes: 429\n",
      "44290: reward: 200.00, mean_100: 154.64, episodes: 430\n",
      "44490: reward: 200.00, mean_100: 155.29, episodes: 431\n",
      "44690: reward: 200.00, mean_100: 156.12, episodes: 432\n",
      "44890: reward: 200.00, mean_100: 156.87, episodes: 433\n",
      "45090: reward: 200.00, mean_100: 157.50, episodes: 434\n",
      "45290: reward: 200.00, mean_100: 157.99, episodes: 435\n",
      "45490: reward: 200.00, mean_100: 158.76, episodes: 436\n",
      "45690: reward: 200.00, mean_100: 159.43, episodes: 437\n",
      "45890: reward: 200.00, mean_100: 160.25, episodes: 438\n",
      "46084: reward: 194.00, mean_100: 161.02, episodes: 439\n",
      "46284: reward: 200.00, mean_100: 161.94, episodes: 440\n",
      "46467: reward: 183.00, mean_100: 162.76, episodes: 441\n",
      "46667: reward: 200.00, mean_100: 163.55, episodes: 442\n",
      "46867: reward: 200.00, mean_100: 164.31, episodes: 443\n",
      "47067: reward: 200.00, mean_100: 165.25, episodes: 444\n",
      "47267: reward: 200.00, mean_100: 166.41, episodes: 445\n",
      "47467: reward: 200.00, mean_100: 167.23, episodes: 446\n",
      "47667: reward: 200.00, mean_100: 168.56, episodes: 447\n",
      "47867: reward: 200.00, mean_100: 169.46, episodes: 448\n",
      "48067: reward: 200.00, mean_100: 170.15, episodes: 449\n",
      "48267: reward: 200.00, mean_100: 170.91, episodes: 450\n",
      "48467: reward: 200.00, mean_100: 171.74, episodes: 451\n",
      "48667: reward: 200.00, mean_100: 172.60, episodes: 452\n",
      "48867: reward: 200.00, mean_100: 173.21, episodes: 453\n",
      "49067: reward: 200.00, mean_100: 174.18, episodes: 454\n",
      "49267: reward: 200.00, mean_100: 175.02, episodes: 455\n",
      "49467: reward: 200.00, mean_100: 175.94, episodes: 456\n",
      "49667: reward: 200.00, mean_100: 176.78, episodes: 457\n",
      "49867: reward: 200.00, mean_100: 177.48, episodes: 458\n",
      "50067: reward: 200.00, mean_100: 178.25, episodes: 459\n",
      "50267: reward: 200.00, mean_100: 178.95, episodes: 460\n",
      "50467: reward: 200.00, mean_100: 179.84, episodes: 461\n",
      "50667: reward: 200.00, mean_100: 180.42, episodes: 462\n",
      "50867: reward: 200.00, mean_100: 181.34, episodes: 463\n",
      "51067: reward: 200.00, mean_100: 182.14, episodes: 464\n",
      "51267: reward: 200.00, mean_100: 182.86, episodes: 465\n",
      "51467: reward: 200.00, mean_100: 183.71, episodes: 466\n",
      "51667: reward: 200.00, mean_100: 184.31, episodes: 467\n",
      "51867: reward: 200.00, mean_100: 185.02, episodes: 468\n",
      "52067: reward: 200.00, mean_100: 185.77, episodes: 469\n",
      "52267: reward: 200.00, mean_100: 186.51, episodes: 470\n",
      "52467: reward: 200.00, mean_100: 187.14, episodes: 471\n",
      "52667: reward: 200.00, mean_100: 187.67, episodes: 472\n",
      "52867: reward: 200.00, mean_100: 188.30, episodes: 473\n",
      "53067: reward: 200.00, mean_100: 188.89, episodes: 474\n",
      "53267: reward: 200.00, mean_100: 189.49, episodes: 475\n",
      "53467: reward: 200.00, mean_100: 190.05, episodes: 476\n",
      "53667: reward: 200.00, mean_100: 190.55, episodes: 477\n",
      "53867: reward: 200.00, mean_100: 190.99, episodes: 478\n",
      "54067: reward: 200.00, mean_100: 191.62, episodes: 479\n",
      "54267: reward: 200.00, mean_100: 192.16, episodes: 480\n",
      "54467: reward: 200.00, mean_100: 192.48, episodes: 481\n",
      "54667: reward: 200.00, mean_100: 192.62, episodes: 482\n",
      "54867: reward: 200.00, mean_100: 192.99, episodes: 483\n",
      "55067: reward: 200.00, mean_100: 193.56, episodes: 484\n",
      "55267: reward: 200.00, mean_100: 194.13, episodes: 485\n",
      "55467: reward: 200.00, mean_100: 194.58, episodes: 486\n",
      "55667: reward: 200.00, mean_100: 195.27, episodes: 487\n",
      "Solved in 55667 steps and 487 episodes!\n"
     ]
    }
   ],
   "source": [
    "for step_idx, exp in enumerate(exp_source):\n",
    "    batch_states.append(exp.state)\n",
    "    batch_actions.append(int(exp.action))\n",
    "    cur_rewards.append(exp.reward)\n",
    "    \n",
    "    if exp.last_state is None:\n",
    "        batch_qvals.extend(calc_qvals(cur_rewards))\n",
    "        cur_rewards.clear()\n",
    "        batch_episodes += 1\n",
    "    \n",
    "    # handle new rewards\n",
    "    new_rewards = exp_source.pop_rewards_steps()\n",
    "    if new_rewards:\n",
    "        done_episodes += 1\n",
    "        reward = new_rewards[0][0]\n",
    "        total_rewards.append(reward)\n",
    "        mean_rewards = float(np.mean(total_rewards[-100:]))\n",
    "        print(\"%d: reward: %6.2f, mean_100: %6.2f, episodes: %d\"\n",
    "              % (step_idx, reward, mean_rewards, done_episodes))\n",
    "        writer.add_scalar(\"reward\", reward, step_idx)\n",
    "        writer.add_scalar(\"reward_100\", mean_rewards, step_idx)\n",
    "        writer.add_scalar(\"episodes\", done_episodes, step_idx)\n",
    "        if mean_rewards > 195:\n",
    "            print(\"Solved in %d steps and %d episodes!\"\n",
    "                  %(step_idx, done_episodes))\n",
    "            break\n",
    "    \n",
    "    # when enough episodes have passed since the last training step,\n",
    "    # we perform optimiation on the gathered exmaples\n",
    "    # we convert states, actions, and Q-value into the appropriate PyTorch form\n",
    "    if batch_episodes < EPISODE_TO_TRAIN:\n",
    "        continue\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    states_v = torch.FloatTensor(batch_states)\n",
    "    batch_actions_t = torch.LongTensor(batch_actions)\n",
    "    batch_qvals_v = torch.FloatTensor(batch_qvals)\n",
    "    \n",
    "    # we calculate the loss from the steps.\n",
    "    logits_v = net(states_v)        # network calculates states into logits\n",
    "    log_prob_v = F.log_softmax(logits_v, dim=1)     # calculate the logartithm + softmax of them\n",
    "    log_prov_actions_v = batch_qvals_v * log_prob_v[range(len(batch_states)), batch_actions_t]      # select log probabilities from the action taken and scale them with Q-values\n",
    "    loss_v = -log_prov_actions_v.mean()         # average those scaled values and do negation to obtain the loss to minimize.\n",
    "    \n",
    "    loss_v.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    batch_episodes = 0\n",
    "    batch_states.clear()\n",
    "    batch_actions.clear()\n",
    "    batch_qvals.clear()\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reinforce",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
