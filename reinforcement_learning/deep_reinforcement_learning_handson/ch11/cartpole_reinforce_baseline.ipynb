{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import ptan\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMMA = 0.99\n",
    "LEARNING_RATE = 0.01\n",
    "EPISODES_TO_TRAIN = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PGN(nn.Module):\n",
    "    def __init__(self, input_size, n_actions):\n",
    "        super(PGN, self).__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, n_actions)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_qvals(rewards):\n",
    "    res = []\n",
    "    sum_r = 0.0\n",
    "    for r in reversed(rewards):\n",
    "        sum_r *= GAMMA\n",
    "        sum_r += r\n",
    "        res.append(sum_r)\n",
    "    res = list(reversed(res))\n",
    "    mean_q = np.mean(res)\n",
    "    return [q - mean_q for q in res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PGN(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v0\")\n",
    "writer = SummaryWriter(comment=\"-cartpole-reinforce-baseline\")\n",
    "\n",
    "net = PGN(env.observation_space.shape[0], env.action_space.n)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ptan.agent.PolicyAgent(net, preprocessor=ptan.agent.float32_preprocessor,\n",
    "                               apply_softmax=True)\n",
    "exp_source = ptan.experience.ExperienceSourceFirstLast(env, agent, gamma=GAMMA)\n",
    "optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rewards = []\n",
    "step_idx = 0\n",
    "done_episodes = 0\n",
    "\n",
    "batch_episodes = 0\n",
    "batch_states, batch_actions, batch_qvals = [], [], []\n",
    "cur_states, cur_actions, cur_rewards = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28: reward:  28.00, mean_100:  28.00, episodes: 1\n",
      "37: reward:   9.00, mean_100:  18.50, episodes: 2\n",
      "46: reward:   9.00, mean_100:  15.33, episodes: 3\n",
      "58: reward:  12.00, mean_100:  14.50, episodes: 4\n",
      "70: reward:  12.00, mean_100:  14.00, episodes: 5\n",
      "111: reward:  41.00, mean_100:  18.50, episodes: 6\n",
      "128: reward:  17.00, mean_100:  18.29, episodes: 7\n",
      "147: reward:  19.00, mean_100:  18.38, episodes: 8\n",
      "160: reward:  13.00, mean_100:  17.78, episodes: 9\n",
      "177: reward:  17.00, mean_100:  17.70, episodes: 10\n",
      "221: reward:  44.00, mean_100:  20.09, episodes: 11\n",
      "256: reward:  35.00, mean_100:  21.33, episodes: 12\n",
      "288: reward:  32.00, mean_100:  22.15, episodes: 13\n",
      "356: reward:  68.00, mean_100:  25.43, episodes: 14\n",
      "368: reward:  12.00, mean_100:  24.53, episodes: 15\n",
      "450: reward:  82.00, mean_100:  28.12, episodes: 16\n",
      "483: reward:  33.00, mean_100:  28.41, episodes: 17\n",
      "502: reward:  19.00, mean_100:  27.89, episodes: 18\n",
      "594: reward:  92.00, mean_100:  31.26, episodes: 19\n",
      "622: reward:  28.00, mean_100:  31.10, episodes: 20\n",
      "685: reward:  63.00, mean_100:  32.62, episodes: 21\n",
      "747: reward:  62.00, mean_100:  33.95, episodes: 22\n",
      "792: reward:  45.00, mean_100:  34.43, episodes: 23\n",
      "831: reward:  39.00, mean_100:  34.62, episodes: 24\n",
      "849: reward:  18.00, mean_100:  33.96, episodes: 25\n",
      "868: reward:  19.00, mean_100:  33.38, episodes: 26\n",
      "902: reward:  34.00, mean_100:  33.41, episodes: 27\n",
      "926: reward:  24.00, mean_100:  33.07, episodes: 28\n",
      "955: reward:  29.00, mean_100:  32.93, episodes: 29\n",
      "987: reward:  32.00, mean_100:  32.90, episodes: 30\n",
      "1002: reward:  15.00, mean_100:  32.32, episodes: 31\n",
      "1045: reward:  43.00, mean_100:  32.66, episodes: 32\n",
      "1102: reward:  57.00, mean_100:  33.39, episodes: 33\n",
      "1122: reward:  20.00, mean_100:  33.00, episodes: 34\n",
      "1137: reward:  15.00, mean_100:  32.49, episodes: 35\n",
      "1154: reward:  17.00, mean_100:  32.06, episodes: 36\n",
      "1202: reward:  48.00, mean_100:  32.49, episodes: 37\n",
      "1231: reward:  29.00, mean_100:  32.39, episodes: 38\n",
      "1253: reward:  22.00, mean_100:  32.13, episodes: 39\n",
      "1299: reward:  46.00, mean_100:  32.48, episodes: 40\n",
      "1343: reward:  44.00, mean_100:  32.76, episodes: 41\n",
      "1372: reward:  29.00, mean_100:  32.67, episodes: 42\n",
      "1402: reward:  30.00, mean_100:  32.60, episodes: 43\n",
      "1450: reward:  48.00, mean_100:  32.95, episodes: 44\n",
      "1525: reward:  75.00, mean_100:  33.89, episodes: 45\n",
      "1563: reward:  38.00, mean_100:  33.98, episodes: 46\n",
      "1601: reward:  38.00, mean_100:  34.06, episodes: 47\n",
      "1668: reward:  67.00, mean_100:  34.75, episodes: 48\n",
      "1711: reward:  43.00, mean_100:  34.92, episodes: 49\n",
      "1760: reward:  49.00, mean_100:  35.20, episodes: 50\n",
      "1777: reward:  17.00, mean_100:  34.84, episodes: 51\n",
      "1842: reward:  65.00, mean_100:  35.42, episodes: 52\n",
      "1942: reward: 100.00, mean_100:  36.64, episodes: 53\n",
      "2004: reward:  62.00, mean_100:  37.11, episodes: 54\n",
      "2018: reward:  14.00, mean_100:  36.69, episodes: 55\n",
      "2044: reward:  26.00, mean_100:  36.50, episodes: 56\n",
      "2171: reward: 127.00, mean_100:  38.09, episodes: 57\n",
      "2201: reward:  30.00, mean_100:  37.95, episodes: 58\n",
      "2277: reward:  76.00, mean_100:  38.59, episodes: 59\n",
      "2311: reward:  34.00, mean_100:  38.52, episodes: 60\n",
      "2332: reward:  21.00, mean_100:  38.23, episodes: 61\n",
      "2417: reward:  85.00, mean_100:  38.98, episodes: 62\n",
      "2459: reward:  42.00, mean_100:  39.03, episodes: 63\n",
      "2557: reward:  98.00, mean_100:  39.95, episodes: 64\n",
      "2582: reward:  25.00, mean_100:  39.72, episodes: 65\n",
      "2681: reward:  99.00, mean_100:  40.62, episodes: 66\n",
      "2709: reward:  28.00, mean_100:  40.43, episodes: 67\n",
      "2761: reward:  52.00, mean_100:  40.60, episodes: 68\n",
      "2847: reward:  86.00, mean_100:  41.26, episodes: 69\n",
      "2937: reward:  90.00, mean_100:  41.96, episodes: 70\n",
      "3004: reward:  67.00, mean_100:  42.31, episodes: 71\n",
      "3131: reward: 127.00, mean_100:  43.49, episodes: 72\n",
      "3244: reward: 113.00, mean_100:  44.44, episodes: 73\n",
      "3309: reward:  65.00, mean_100:  44.72, episodes: 74\n",
      "3356: reward:  47.00, mean_100:  44.75, episodes: 75\n",
      "3403: reward:  47.00, mean_100:  44.78, episodes: 76\n",
      "3476: reward:  73.00, mean_100:  45.14, episodes: 77\n",
      "3535: reward:  59.00, mean_100:  45.32, episodes: 78\n",
      "3605: reward:  70.00, mean_100:  45.63, episodes: 79\n",
      "3651: reward:  46.00, mean_100:  45.64, episodes: 80\n",
      "3779: reward: 128.00, mean_100:  46.65, episodes: 81\n",
      "3891: reward: 112.00, mean_100:  47.45, episodes: 82\n",
      "3934: reward:  43.00, mean_100:  47.40, episodes: 83\n",
      "3989: reward:  55.00, mean_100:  47.49, episodes: 84\n",
      "4036: reward:  47.00, mean_100:  47.48, episodes: 85\n",
      "4121: reward:  85.00, mean_100:  47.92, episodes: 86\n",
      "4158: reward:  37.00, mean_100:  47.79, episodes: 87\n",
      "4193: reward:  35.00, mean_100:  47.65, episodes: 88\n",
      "4226: reward:  33.00, mean_100:  47.48, episodes: 89\n",
      "4276: reward:  50.00, mean_100:  47.51, episodes: 90\n",
      "4344: reward:  68.00, mean_100:  47.74, episodes: 91\n",
      "4414: reward:  70.00, mean_100:  47.98, episodes: 92\n",
      "4508: reward:  94.00, mean_100:  48.47, episodes: 93\n",
      "4566: reward:  58.00, mean_100:  48.57, episodes: 94\n",
      "4601: reward:  35.00, mean_100:  48.43, episodes: 95\n",
      "4706: reward: 105.00, mean_100:  49.02, episodes: 96\n",
      "4836: reward: 130.00, mean_100:  49.86, episodes: 97\n",
      "4930: reward:  94.00, mean_100:  50.31, episodes: 98\n",
      "4999: reward:  69.00, mean_100:  50.49, episodes: 99\n",
      "5092: reward:  93.00, mean_100:  50.92, episodes: 100\n",
      "5177: reward:  85.00, mean_100:  51.49, episodes: 101\n",
      "5330: reward: 153.00, mean_100:  52.93, episodes: 102\n",
      "5485: reward: 155.00, mean_100:  54.39, episodes: 103\n",
      "5557: reward:  72.00, mean_100:  54.99, episodes: 104\n",
      "5616: reward:  59.00, mean_100:  55.46, episodes: 105\n",
      "5644: reward:  28.00, mean_100:  55.33, episodes: 106\n",
      "5795: reward: 151.00, mean_100:  56.67, episodes: 107\n",
      "5961: reward: 166.00, mean_100:  58.14, episodes: 108\n",
      "6015: reward:  54.00, mean_100:  58.55, episodes: 109\n",
      "6215: reward: 200.00, mean_100:  60.38, episodes: 110\n",
      "6335: reward: 120.00, mean_100:  61.14, episodes: 111\n",
      "6457: reward: 122.00, mean_100:  62.01, episodes: 112\n",
      "6530: reward:  73.00, mean_100:  62.42, episodes: 113\n",
      "6654: reward: 124.00, mean_100:  62.98, episodes: 114\n",
      "6726: reward:  72.00, mean_100:  63.58, episodes: 115\n",
      "6773: reward:  47.00, mean_100:  63.23, episodes: 116\n",
      "6942: reward: 169.00, mean_100:  64.59, episodes: 117\n",
      "7073: reward: 131.00, mean_100:  65.71, episodes: 118\n",
      "7137: reward:  64.00, mean_100:  65.43, episodes: 119\n",
      "7236: reward:  99.00, mean_100:  66.14, episodes: 120\n",
      "7403: reward: 167.00, mean_100:  67.18, episodes: 121\n",
      "7482: reward:  79.00, mean_100:  67.35, episodes: 122\n",
      "7553: reward:  71.00, mean_100:  67.61, episodes: 123\n",
      "7688: reward: 135.00, mean_100:  68.57, episodes: 124\n",
      "7845: reward: 157.00, mean_100:  69.96, episodes: 125\n",
      "7898: reward:  53.00, mean_100:  70.30, episodes: 126\n",
      "7977: reward:  79.00, mean_100:  70.75, episodes: 127\n",
      "8043: reward:  66.00, mean_100:  71.17, episodes: 128\n",
      "8174: reward: 131.00, mean_100:  72.19, episodes: 129\n",
      "8266: reward:  92.00, mean_100:  72.79, episodes: 130\n",
      "8376: reward: 110.00, mean_100:  73.74, episodes: 131\n",
      "8428: reward:  52.00, mean_100:  73.83, episodes: 132\n",
      "8523: reward:  95.00, mean_100:  74.21, episodes: 133\n",
      "8549: reward:  26.00, mean_100:  74.27, episodes: 134\n",
      "8660: reward: 111.00, mean_100:  75.23, episodes: 135\n",
      "8819: reward: 159.00, mean_100:  76.65, episodes: 136\n",
      "8894: reward:  75.00, mean_100:  76.92, episodes: 137\n",
      "9022: reward: 128.00, mean_100:  77.91, episodes: 138\n",
      "9176: reward: 154.00, mean_100:  79.23, episodes: 139\n",
      "9376: reward: 200.00, mean_100:  80.77, episodes: 140\n",
      "9513: reward: 137.00, mean_100:  81.70, episodes: 141\n",
      "9672: reward: 159.00, mean_100:  83.00, episodes: 142\n",
      "9793: reward: 121.00, mean_100:  83.91, episodes: 143\n",
      "9870: reward:  77.00, mean_100:  84.20, episodes: 144\n",
      "10024: reward: 154.00, mean_100:  84.99, episodes: 145\n",
      "10171: reward: 147.00, mean_100:  86.08, episodes: 146\n",
      "10330: reward: 159.00, mean_100:  87.29, episodes: 147\n",
      "10530: reward: 200.00, mean_100:  88.62, episodes: 148\n",
      "10659: reward: 129.00, mean_100:  89.48, episodes: 149\n",
      "10779: reward: 120.00, mean_100:  90.19, episodes: 150\n",
      "10979: reward: 200.00, mean_100:  92.02, episodes: 151\n",
      "11072: reward:  93.00, mean_100:  92.30, episodes: 152\n",
      "11261: reward: 189.00, mean_100:  93.19, episodes: 153\n",
      "11461: reward: 200.00, mean_100:  94.57, episodes: 154\n",
      "11651: reward: 190.00, mean_100:  96.33, episodes: 155\n",
      "11821: reward: 170.00, mean_100:  97.77, episodes: 156\n",
      "12021: reward: 200.00, mean_100:  98.50, episodes: 157\n",
      "12096: reward:  75.00, mean_100:  98.95, episodes: 158\n",
      "12296: reward: 200.00, mean_100: 100.19, episodes: 159\n",
      "12496: reward: 200.00, mean_100: 101.85, episodes: 160\n",
      "12696: reward: 200.00, mean_100: 103.64, episodes: 161\n",
      "12782: reward:  86.00, mean_100: 103.65, episodes: 162\n",
      "12969: reward: 187.00, mean_100: 105.10, episodes: 163\n",
      "13085: reward: 116.00, mean_100: 105.28, episodes: 164\n",
      "13207: reward: 122.00, mean_100: 106.25, episodes: 165\n",
      "13285: reward:  78.00, mean_100: 106.04, episodes: 166\n",
      "13485: reward: 200.00, mean_100: 107.76, episodes: 167\n",
      "13685: reward: 200.00, mean_100: 109.24, episodes: 168\n",
      "13838: reward: 153.00, mean_100: 109.91, episodes: 169\n",
      "13952: reward: 114.00, mean_100: 110.15, episodes: 170\n",
      "14152: reward: 200.00, mean_100: 111.48, episodes: 171\n",
      "14303: reward: 151.00, mean_100: 111.72, episodes: 172\n",
      "14503: reward: 200.00, mean_100: 112.59, episodes: 173\n",
      "14684: reward: 181.00, mean_100: 113.75, episodes: 174\n",
      "14848: reward: 164.00, mean_100: 114.92, episodes: 175\n",
      "15048: reward: 200.00, mean_100: 116.45, episodes: 176\n",
      "15248: reward: 200.00, mean_100: 117.72, episodes: 177\n",
      "15359: reward: 111.00, mean_100: 118.24, episodes: 178\n",
      "15559: reward: 200.00, mean_100: 119.54, episodes: 179\n",
      "15692: reward: 133.00, mean_100: 120.41, episodes: 180\n",
      "15843: reward: 151.00, mean_100: 120.64, episodes: 181\n",
      "16043: reward: 200.00, mean_100: 121.52, episodes: 182\n",
      "16230: reward: 187.00, mean_100: 122.96, episodes: 183\n",
      "16422: reward: 192.00, mean_100: 124.33, episodes: 184\n",
      "16622: reward: 200.00, mean_100: 125.86, episodes: 185\n",
      "16822: reward: 200.00, mean_100: 127.01, episodes: 186\n",
      "17022: reward: 200.00, mean_100: 128.64, episodes: 187\n",
      "17222: reward: 200.00, mean_100: 130.29, episodes: 188\n",
      "17422: reward: 200.00, mean_100: 131.96, episodes: 189\n",
      "17622: reward: 200.00, mean_100: 133.46, episodes: 190\n",
      "17822: reward: 200.00, mean_100: 134.78, episodes: 191\n",
      "18022: reward: 200.00, mean_100: 136.08, episodes: 192\n",
      "18222: reward: 200.00, mean_100: 137.14, episodes: 193\n",
      "18422: reward: 200.00, mean_100: 138.56, episodes: 194\n",
      "18622: reward: 200.00, mean_100: 140.21, episodes: 195\n",
      "18822: reward: 200.00, mean_100: 141.16, episodes: 196\n",
      "19022: reward: 200.00, mean_100: 141.86, episodes: 197\n",
      "19222: reward: 200.00, mean_100: 142.92, episodes: 198\n",
      "19365: reward: 143.00, mean_100: 143.66, episodes: 199\n",
      "19565: reward: 200.00, mean_100: 144.73, episodes: 200\n",
      "19765: reward: 200.00, mean_100: 145.88, episodes: 201\n",
      "19965: reward: 200.00, mean_100: 146.35, episodes: 202\n",
      "20165: reward: 200.00, mean_100: 146.80, episodes: 203\n",
      "20365: reward: 200.00, mean_100: 148.08, episodes: 204\n",
      "20565: reward: 200.00, mean_100: 149.49, episodes: 205\n",
      "20760: reward: 195.00, mean_100: 151.16, episodes: 206\n",
      "20960: reward: 200.00, mean_100: 151.65, episodes: 207\n",
      "21160: reward: 200.00, mean_100: 151.99, episodes: 208\n",
      "21310: reward: 150.00, mean_100: 152.95, episodes: 209\n",
      "21476: reward: 166.00, mean_100: 152.61, episodes: 210\n",
      "21670: reward: 194.00, mean_100: 153.35, episodes: 211\n",
      "21849: reward: 179.00, mean_100: 153.92, episodes: 212\n",
      "21959: reward: 110.00, mean_100: 154.29, episodes: 213\n",
      "22121: reward: 162.00, mean_100: 154.67, episodes: 214\n",
      "22234: reward: 113.00, mean_100: 155.08, episodes: 215\n",
      "22415: reward: 181.00, mean_100: 156.42, episodes: 216\n",
      "22548: reward: 133.00, mean_100: 156.06, episodes: 217\n",
      "22680: reward: 132.00, mean_100: 156.07, episodes: 218\n",
      "22789: reward: 109.00, mean_100: 156.52, episodes: 219\n",
      "22911: reward: 122.00, mean_100: 156.75, episodes: 220\n",
      "23033: reward: 122.00, mean_100: 156.30, episodes: 221\n",
      "23166: reward: 133.00, mean_100: 156.84, episodes: 222\n",
      "23283: reward: 117.00, mean_100: 157.30, episodes: 223\n",
      "23443: reward: 160.00, mean_100: 157.55, episodes: 224\n",
      "23588: reward: 145.00, mean_100: 157.43, episodes: 225\n",
      "23709: reward: 121.00, mean_100: 158.11, episodes: 226\n",
      "23849: reward: 140.00, mean_100: 158.72, episodes: 227\n",
      "23985: reward: 136.00, mean_100: 159.42, episodes: 228\n",
      "24121: reward: 136.00, mean_100: 159.47, episodes: 229\n",
      "24166: reward:  45.00, mean_100: 159.00, episodes: 230\n",
      "24306: reward: 140.00, mean_100: 159.30, episodes: 231\n",
      "24419: reward: 113.00, mean_100: 159.91, episodes: 232\n",
      "24537: reward: 118.00, mean_100: 160.14, episodes: 233\n",
      "24565: reward:  28.00, mean_100: 160.16, episodes: 234\n",
      "24681: reward: 116.00, mean_100: 160.21, episodes: 235\n",
      "24799: reward: 118.00, mean_100: 159.80, episodes: 236\n",
      "24917: reward: 118.00, mean_100: 160.23, episodes: 237\n",
      "25032: reward: 115.00, mean_100: 160.10, episodes: 238\n",
      "25158: reward: 126.00, mean_100: 159.82, episodes: 239\n",
      "25263: reward: 105.00, mean_100: 158.87, episodes: 240\n",
      "25368: reward: 105.00, mean_100: 158.55, episodes: 241\n",
      "25488: reward: 120.00, mean_100: 158.16, episodes: 242\n",
      "25621: reward: 133.00, mean_100: 158.28, episodes: 243\n",
      "25750: reward: 129.00, mean_100: 158.80, episodes: 244\n",
      "25863: reward: 113.00, mean_100: 158.39, episodes: 245\n",
      "25973: reward: 110.00, mean_100: 158.02, episodes: 246\n",
      "26086: reward: 113.00, mean_100: 157.56, episodes: 247\n",
      "26192: reward: 106.00, mean_100: 156.62, episodes: 248\n",
      "26303: reward: 111.00, mean_100: 156.44, episodes: 249\n",
      "26414: reward: 111.00, mean_100: 156.35, episodes: 250\n",
      "26511: reward:  97.00, mean_100: 155.32, episodes: 251\n",
      "26631: reward: 120.00, mean_100: 155.59, episodes: 252\n",
      "26740: reward: 109.00, mean_100: 154.79, episodes: 253\n",
      "26775: reward:  35.00, mean_100: 153.14, episodes: 254\n",
      "26889: reward: 114.00, mean_100: 152.38, episodes: 255\n",
      "27010: reward: 121.00, mean_100: 151.89, episodes: 256\n",
      "27131: reward: 121.00, mean_100: 151.10, episodes: 257\n",
      "27244: reward: 113.00, mean_100: 151.48, episodes: 258\n",
      "27367: reward: 123.00, mean_100: 150.71, episodes: 259\n",
      "27470: reward: 103.00, mean_100: 149.74, episodes: 260\n",
      "27599: reward: 129.00, mean_100: 149.03, episodes: 261\n",
      "27733: reward: 134.00, mean_100: 149.51, episodes: 262\n",
      "27871: reward: 138.00, mean_100: 149.02, episodes: 263\n",
      "27992: reward: 121.00, mean_100: 149.07, episodes: 264\n",
      "28122: reward: 130.00, mean_100: 149.15, episodes: 265\n",
      "28240: reward: 118.00, mean_100: 149.55, episodes: 266\n",
      "28370: reward: 130.00, mean_100: 148.85, episodes: 267\n",
      "28520: reward: 150.00, mean_100: 148.35, episodes: 268\n",
      "28662: reward: 142.00, mean_100: 148.24, episodes: 269\n",
      "28816: reward: 154.00, mean_100: 148.64, episodes: 270\n",
      "28945: reward: 129.00, mean_100: 147.93, episodes: 271\n",
      "29067: reward: 122.00, mean_100: 147.64, episodes: 272\n",
      "29227: reward: 160.00, mean_100: 147.24, episodes: 273\n",
      "29377: reward: 150.00, mean_100: 146.93, episodes: 274\n",
      "29544: reward: 167.00, mean_100: 146.96, episodes: 275\n",
      "29716: reward: 172.00, mean_100: 146.68, episodes: 276\n",
      "29878: reward: 162.00, mean_100: 146.30, episodes: 277\n",
      "30047: reward: 169.00, mean_100: 146.88, episodes: 278\n",
      "30213: reward: 166.00, mean_100: 146.54, episodes: 279\n",
      "30413: reward: 200.00, mean_100: 147.21, episodes: 280\n",
      "30613: reward: 200.00, mean_100: 147.70, episodes: 281\n",
      "30788: reward: 175.00, mean_100: 147.45, episodes: 282\n",
      "30984: reward: 196.00, mean_100: 147.54, episodes: 283\n",
      "31178: reward: 194.00, mean_100: 147.56, episodes: 284\n",
      "31374: reward: 196.00, mean_100: 147.52, episodes: 285\n",
      "31574: reward: 200.00, mean_100: 147.52, episodes: 286\n",
      "31767: reward: 193.00, mean_100: 147.45, episodes: 287\n",
      "31967: reward: 200.00, mean_100: 147.45, episodes: 288\n",
      "32167: reward: 200.00, mean_100: 147.45, episodes: 289\n",
      "32367: reward: 200.00, mean_100: 147.45, episodes: 290\n",
      "32559: reward: 192.00, mean_100: 147.37, episodes: 291\n",
      "32759: reward: 200.00, mean_100: 147.37, episodes: 292\n",
      "32959: reward: 200.00, mean_100: 147.37, episodes: 293\n",
      "33159: reward: 200.00, mean_100: 147.37, episodes: 294\n",
      "33359: reward: 200.00, mean_100: 147.37, episodes: 295\n",
      "33559: reward: 200.00, mean_100: 147.37, episodes: 296\n",
      "33759: reward: 200.00, mean_100: 147.37, episodes: 297\n",
      "33959: reward: 200.00, mean_100: 147.37, episodes: 298\n",
      "34159: reward: 200.00, mean_100: 147.94, episodes: 299\n",
      "34359: reward: 200.00, mean_100: 147.94, episodes: 300\n",
      "34559: reward: 200.00, mean_100: 147.94, episodes: 301\n",
      "34759: reward: 200.00, mean_100: 147.94, episodes: 302\n",
      "34959: reward: 200.00, mean_100: 147.94, episodes: 303\n",
      "35159: reward: 200.00, mean_100: 147.94, episodes: 304\n",
      "35359: reward: 200.00, mean_100: 147.94, episodes: 305\n",
      "35559: reward: 200.00, mean_100: 147.99, episodes: 306\n",
      "35759: reward: 200.00, mean_100: 147.99, episodes: 307\n",
      "35959: reward: 200.00, mean_100: 147.99, episodes: 308\n",
      "36159: reward: 200.00, mean_100: 148.49, episodes: 309\n",
      "36359: reward: 200.00, mean_100: 148.83, episodes: 310\n",
      "36559: reward: 200.00, mean_100: 148.89, episodes: 311\n",
      "36759: reward: 200.00, mean_100: 149.10, episodes: 312\n",
      "36959: reward: 200.00, mean_100: 150.00, episodes: 313\n",
      "37159: reward: 200.00, mean_100: 150.38, episodes: 314\n",
      "37359: reward: 200.00, mean_100: 151.25, episodes: 315\n",
      "37559: reward: 200.00, mean_100: 151.44, episodes: 316\n",
      "37759: reward: 200.00, mean_100: 152.11, episodes: 317\n",
      "37959: reward: 200.00, mean_100: 152.79, episodes: 318\n",
      "38159: reward: 200.00, mean_100: 153.70, episodes: 319\n",
      "38359: reward: 200.00, mean_100: 154.48, episodes: 320\n",
      "38559: reward: 200.00, mean_100: 155.26, episodes: 321\n",
      "38759: reward: 200.00, mean_100: 155.93, episodes: 322\n",
      "38959: reward: 200.00, mean_100: 156.76, episodes: 323\n",
      "39159: reward: 200.00, mean_100: 157.16, episodes: 324\n",
      "39359: reward: 200.00, mean_100: 157.71, episodes: 325\n",
      "39559: reward: 200.00, mean_100: 158.50, episodes: 326\n",
      "39759: reward: 200.00, mean_100: 159.10, episodes: 327\n",
      "39959: reward: 200.00, mean_100: 159.74, episodes: 328\n",
      "40159: reward: 200.00, mean_100: 160.38, episodes: 329\n",
      "40359: reward: 200.00, mean_100: 161.93, episodes: 330\n",
      "40559: reward: 200.00, mean_100: 162.53, episodes: 331\n",
      "40759: reward: 200.00, mean_100: 163.40, episodes: 332\n",
      "40959: reward: 200.00, mean_100: 164.22, episodes: 333\n",
      "41159: reward: 200.00, mean_100: 165.94, episodes: 334\n",
      "41359: reward: 200.00, mean_100: 166.78, episodes: 335\n",
      "41559: reward: 200.00, mean_100: 167.60, episodes: 336\n",
      "41759: reward: 200.00, mean_100: 168.42, episodes: 337\n",
      "41959: reward: 200.00, mean_100: 169.27, episodes: 338\n",
      "42159: reward: 200.00, mean_100: 170.01, episodes: 339\n",
      "42359: reward: 200.00, mean_100: 170.96, episodes: 340\n",
      "42559: reward: 200.00, mean_100: 171.91, episodes: 341\n",
      "42759: reward: 200.00, mean_100: 172.71, episodes: 342\n",
      "42959: reward: 200.00, mean_100: 173.38, episodes: 343\n",
      "43159: reward: 200.00, mean_100: 174.09, episodes: 344\n",
      "43359: reward: 200.00, mean_100: 174.96, episodes: 345\n",
      "43559: reward: 200.00, mean_100: 175.86, episodes: 346\n",
      "43759: reward: 200.00, mean_100: 176.73, episodes: 347\n",
      "43959: reward: 200.00, mean_100: 177.67, episodes: 348\n",
      "44159: reward: 200.00, mean_100: 178.56, episodes: 349\n",
      "44359: reward: 200.00, mean_100: 179.45, episodes: 350\n",
      "44559: reward: 200.00, mean_100: 180.48, episodes: 351\n",
      "44759: reward: 200.00, mean_100: 181.28, episodes: 352\n",
      "44959: reward: 200.00, mean_100: 182.19, episodes: 353\n",
      "45159: reward: 200.00, mean_100: 183.84, episodes: 354\n",
      "45359: reward: 200.00, mean_100: 184.70, episodes: 355\n",
      "45559: reward: 200.00, mean_100: 185.49, episodes: 356\n",
      "45759: reward: 200.00, mean_100: 186.28, episodes: 357\n",
      "45959: reward: 200.00, mean_100: 187.15, episodes: 358\n",
      "46159: reward: 200.00, mean_100: 187.92, episodes: 359\n",
      "46359: reward: 200.00, mean_100: 188.89, episodes: 360\n",
      "46559: reward: 200.00, mean_100: 189.60, episodes: 361\n",
      "46759: reward: 200.00, mean_100: 190.26, episodes: 362\n",
      "46959: reward: 200.00, mean_100: 190.88, episodes: 363\n",
      "47159: reward: 200.00, mean_100: 191.67, episodes: 364\n",
      "47359: reward: 200.00, mean_100: 192.37, episodes: 365\n",
      "47559: reward: 200.00, mean_100: 193.19, episodes: 366\n",
      "47759: reward: 200.00, mean_100: 193.89, episodes: 367\n",
      "47959: reward: 200.00, mean_100: 194.39, episodes: 368\n",
      "48159: reward: 200.00, mean_100: 194.97, episodes: 369\n",
      "48359: reward: 200.00, mean_100: 195.43, episodes: 370\n",
      "Solved in 48359 steps and 370 episodes!\n"
     ]
    }
   ],
   "source": [
    "for step_idx, exp in enumerate(exp_source):\n",
    "    cur_states.append(exp.state)\n",
    "    cur_actions.append(int(exp.action))\n",
    "    cur_rewards.append(exp.reward)\n",
    "    \n",
    "    if exp.last_state is None:\n",
    "        batch_states.extend(cur_states)\n",
    "        batch_actions.extend(cur_actions)\n",
    "        batch_qvals.extend(calc_qvals(cur_rewards))\n",
    "        cur_states.clear()\n",
    "        cur_actions.clear()\n",
    "        cur_rewards.clear()\n",
    "        batch_episodes += 1\n",
    "        \n",
    "    # handle new rewards\n",
    "    new_rewards = exp_source.pop_total_rewards()\n",
    "    if new_rewards:\n",
    "        done_episodes += 1\n",
    "        reward = new_rewards[0]\n",
    "        total_rewards.append(reward)\n",
    "        mean_reward = float(np.mean(total_rewards[-100:]))\n",
    "        print(\"%d: reward: %6.2f, mean_100: %6.2f, episodes: %d\"\n",
    "              % (step_idx, reward, mean_reward, done_episodes))\n",
    "        writer.add_scalar(\"reward\", reward, step_idx)\n",
    "        writer.add_scalar(\"reward_100\", mean_reward, step_idx)\n",
    "        writer.add_scalar(\"episodes\", done_episodes, step_idx)\n",
    "        if mean_reward > 195:\n",
    "            print(\"Solved in %d steps and %d episodes!\"\n",
    "                  % (step_idx, done_episodes))\n",
    "            break\n",
    "    \n",
    "    if batch_episodes < EPISODES_TO_TRAIN:\n",
    "        continue\n",
    "    \n",
    "    states_v = torch.FloatTensor(batch_states)\n",
    "    batch_actions_t = torch.LongTensor(batch_actions)\n",
    "    batch_qvals_v = torch.FloatTensor(batch_qvals)\n",
    "    \n",
    "    optimizer.zero_grad()  \n",
    "    logits_v = net(states_v)\n",
    "    log_prob_v = F.log_softmax(logits_v, dim=1)\n",
    "    log_prob_actions_v = batch_qvals_v * log_prob_v[range(len(batch_states)), batch_actions_t]\n",
    "    loss_v = -log_prob_actions_v.mean()\n",
    "    \n",
    "    loss_v.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    batch_episodes = 0\n",
    "    batch_states.clear()\n",
    "    batch_actions.clear()\n",
    "    batch_qvals.clear()\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reinforce",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
