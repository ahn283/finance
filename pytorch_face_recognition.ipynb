{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyOb8USAxqB7w0xrEuoZl5iX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahn283/finance/blob/main/pytorch_face_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 학습 코드를 실행하기 전에 <b>[런타임]</b> - <b>[런타임 유형 변경]</b>에서 하드웨어 가속기를 <b>[GPU]</b>로 설정한다.\n",
        "\n",
        "### <b>데이터 세트 다운로드</b>\n",
        "\n",
        "* 딥러닝 모델 학습 과정에서 필요한 데이터 세트를 불러온다."
      ],
      "metadata": {
        "id": "0QLh4ct6lPjF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQqF2NfblATv"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/ndb796/korean_face_age_dataset custom_korean_family_dataset_resolution_128"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <b>라이브러리 불러오기(Load Libraries)</b>\n",
        "\n",
        "* 딥러닝 모델 학습 과정에서 필요한 라이브러리를 불러온다."
      ],
      "metadata": {
        "id": "2BNwYXHMlsxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import os"
      ],
      "metadata": {
        "id": "p7j0gm9pl5sV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <b>데이터 세트 불러오기(Load Dataset)</b>\n",
        "\n",
        "1. <b>데이터 증진(data augmentation)</b>을 명시하여 초기화할 수 있다.\n",
        "  * 이미지를 불러올 때 어떤 방법(회전, 자르기, 뒤집기 등)을 사용할 것인지 명시한다.\n",
        "2. 이후에 <b>DataLoader()</b>를 이용하여 실질적으로 데이터를 불러올 수 있다.\n",
        "  * 어떤 데이터를 사용할 것인지, 배치 크기(batch size), 데이터 셔플(shuffle) 여부 등을 명시한다.\n",
        "  * <b>next() 함수</b>를 이용하여 tensor 형태로 데이터를 배치 단위로 얻을 수 있다.\n",
        "* <b>Reference</b>: https://github.com/ndb796/korean_face_age_classification (AI Hub)"
      ],
      "metadata": {
        "id": "ZSwb_E1zpBUk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 데이터 세트를 확인한다.\n",
        "  * <b>Training dataset</b>: (F0001 ~ F0299) folders have 10,025 images.\n",
        "  * <b>Validation dataset</b>: (F0801 ~ F0850) folders have 1,539 images.\n",
        "  * <b>Test dataset</b>: (F0851 ~ F0900) folders have 1,504 images."
      ],
      "metadata": {
        "id": "tffXYpA8pKSz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "> [Function] Parse the metadata.\n",
        "* image_age_list[0] = [\"F0001_AGE_D_18_a1.jpg\"] = \"a\"\n",
        "* image_age_list[1] = [\"F0001_AGE_D_18_a2.jpg\"] = \"a\"\n",
        "* image_age_list[2] = [\"F0001_AGE_D_18_a3.jpg\"] = \"a\"\n",
        "* image_age_list[3] = [\"F0001_AGE_D_18_a4.jpg\"] = \"a\"\n",
        "* image_age_list[4] = [\"F0001_AGE_D_18_b1.jpg\"] = \"b\"\n",
        "...\n",
        "\"\"\"\n",
        "def parsing(meta_data):\n",
        "    image_age_list = []\n",
        "    # iterate all rows in the metadata file\n",
        "    for idx, row in meta_data.iterrows():\n",
        "        image_path = row['image_path']\n",
        "        age_class = row['age_class']\n",
        "        image_age_list.append([image_path, age_class])\n",
        "    return image_age_list"
      ],
      "metadata": {
        "id": "D52MwiC1pFV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset(Dataset):\n",
        "  def __init__(self, meta_data, image_directory, transform=None):\n",
        "    self.meta_data = meta_data\n",
        "    self.image_directory = image_directory\n",
        "    self.transform = transform\n",
        "\n",
        "    # process the meta data\n",
        "    image_age_list = parsing(meta_data)\n",
        "\n",
        "    self.image_age_list = image_age_list\n",
        "    self.age_class_to_label = {\n",
        "        'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4, 'f': 5, 'g': 6, 'h': 7\n",
        "    }\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.meta_data)\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    image_path, age_class = self.image_age_list[idx]\n",
        "    img = Image.open(os.path.join(self.image_directory, image_path))\n",
        "    label = self.age_class_to_label[age_class]\n",
        "\n",
        "    if self.transform:\n",
        "      img = self.transform(img)\n",
        "    \n",
        "    return img, label"
      ],
      "metadata": {
        "id": "d4vqU586p4iA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_to_age = {\n",
        "    0: \"0-6 years old\",\n",
        "    1: \"7-12 years old\",\n",
        "    2: \"13-19 years old\",\n",
        "    3: \"20-30 years old\",\n",
        "    4: \"31-45 years old\",\n",
        "    5: \"46-55 years old\",\n",
        "    6: \"56-66 years old\",\n",
        "    7: \"67-80 years old\"\n",
        "}\n",
        "\n",
        "train_meta_data_path = \"./custom_korean_family_dataset_resolution_128/custom_train_dataset.csv\"\n",
        "train_meta_data = pd.read_csv(train_meta_data_path)\n",
        "train_image_directory = \"./custom_korean_family_dataset_resolution_128/train_images\"\n",
        "\n",
        "val_meta_data_path = \"./custom_korean_family_dataset_resolution_128/custom_val_dataset.csv\"\n",
        "val_meta_data = pd.read_csv(val_meta_data_path)\n",
        "val_image_directory = \"./custom_korean_family_dataset_resolution_128/val_images\"\n",
        "\n",
        "test_meta_data_path = \"./custom_korean_family_dataset_resolution_128/custom_test_dataset.csv\"\n",
        "test_meta_data = pd.read_csv(test_meta_data_path)\n",
        "test_image_directory = \"./custom_korean_family_dataset_resolution_128/test_images\"\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(128),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]) \n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize(128),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]) \n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize(128),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]) \n",
        "])\n",
        "\n",
        "train_dataset = Dataset(train_meta_data, train_image_directory, train_transform)\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "val_dataset = Dataset(val_meta_data, val_image_directory, val_transform)\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "test_dataset = Dataset(test_meta_data, test_image_directory, test_transform)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "hogxcVAorIrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <b>데이터 시각화(Data Visualization)</b>"
      ],
      "metadata": {
        "id": "eNrvRH1pt9dh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams['figure.figsize'] = [12, 8]\n",
        "plt.rcParams['figure.dpi'] = 60\n",
        "plt.rcParams.update({'font.size': 20})\n",
        "\n",
        "\n",
        "def imshow(input):\n",
        "    # torch.Tensor => numpy\n",
        "    input = input.numpy().transpose((1, 2, 0))\n",
        "    # undo image normalization\n",
        "    mean = np.array([0.5, 0.5, 0.5])\n",
        "    std = np.array([0.5, 0.5, 0.5])\n",
        "    input = std * input + mean\n",
        "    input = np.clip(input, 0, 1)\n",
        "    # display images\n",
        "    plt.imshow(input)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# load a batch of train image\n",
        "iterator = iter(train_dataloader)\n",
        "\n",
        "# visualize a batch of train image\n",
        "imgs, labels = next(iterator)\n",
        "out = torchvision.utils.make_grid(imgs[:4])\n",
        "imshow(out)\n",
        "print([label_to_age[labels[i].item()] for i in range(4)])"
      ],
      "metadata": {
        "id": "zlsMUBbLuCT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <b>딥러닝 모델 학습(Training)</b>\n",
        "\n",
        "* 사전 학습된(pre-trained) 모델(model)을 이용하여 가지고 있는 데이터 세트에 대한 학습이 가능하다.\n",
        "  * 네트워크의 마지막에 FC 레이어를 적용하여 클래스 개수를 일치시킨다."
      ],
      "metadata": {
        "id": "9AosuJvRyLlR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.01\n",
        "log_step = 20\n",
        "\n",
        "model = models.resnet50(pretrained=True)\n",
        "num_features = model.fc.in_features\n",
        "model.fc = nn.Linear(num_features, 8) # transfer learning\n",
        "model = model.cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)"
      ],
      "metadata": {
        "id": "z7WJWG0vyNcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "\n",
        "def train():\n",
        "    start_time = time.time()\n",
        "    print(f'[Epoch: {epoch + 1} - Training]')\n",
        "    model.train()\n",
        "    total = 0\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "\n",
        "    for i, batch in enumerate(train_dataloader):\n",
        "        imgs, labels = batch\n",
        "        imgs, labels = imgs.cuda(), labels.cuda()\n",
        "\n",
        "        outputs = model(imgs)\n",
        "        optimizer.zero_grad()\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        total += labels.shape[0]\n",
        "        running_loss += loss.item()\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "        \n",
        "        if i % log_step == log_step - 1:\n",
        "            print(f'[Batch: {i + 1}] running train loss: {running_loss / total}, running train accuracy: {running_corrects / total}')\n",
        "\n",
        "    print(f'train loss: {running_loss / total}, accuracy: {running_corrects / total}')\n",
        "    print(\"elapsed time:\", time.time() - start_time)\n",
        "    return running_loss / total, (running_corrects / total).item()\n",
        "\n",
        "\n",
        "def validate():\n",
        "    start_time = time.time()\n",
        "    print(f'[Epoch: {epoch + 1} - Validation]')\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "\n",
        "    for i, batch in enumerate(val_dataloader):\n",
        "        imgs, labels = batch\n",
        "        imgs, labels = imgs.cuda(), labels.cuda()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(imgs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "        total += labels.shape[0]\n",
        "        running_loss += loss.item()\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        if (i == 0) or (i % log_step == log_step - 1):\n",
        "            print(f'[Batch: {i + 1}] running val loss: {running_loss / total}, running val accuracy: {running_corrects / total}')\n",
        "\n",
        "    print(f'val loss: {running_loss / total}, accuracy: {running_corrects / total}')\n",
        "    print(\"elapsed time:\", time.time() - start_time)\n",
        "    return running_loss / total, (running_corrects / total).item()\n",
        "\n",
        "\n",
        "def test():\n",
        "    start_time = time.time()\n",
        "    print(f'[Test]')\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "\n",
        "    for i, batch in enumerate(test_dataloader):\n",
        "        imgs, labels = batch\n",
        "        imgs, labels = imgs.cuda(), labels.cuda()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(imgs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "        total += labels.shape[0]\n",
        "        running_loss += loss.item()\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        if (i == 0) or (i % log_step == log_step - 1):\n",
        "            print(f'[Batch: {i + 1}] running test loss: {running_loss / total}, running test accuracy: {running_corrects / total}')\n",
        "\n",
        "    print(f'test loss: {running_loss / total}, accuracy: {running_corrects / total}')\n",
        "    print(\"elapsed time:\", time.time() - start_time)\n",
        "    return running_loss / total, (running_corrects / total).item()"
      ],
      "metadata": {
        "id": "oRrbXcrDy4gb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def adjust_learning_rate(optimizer, epoch):\n",
        "    lr = learning_rate\n",
        "    if epoch >= 3:\n",
        "        lr /= 10\n",
        "    if epoch >= 7:\n",
        "        lr /= 10\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "\n",
        "num_epochs = 10\n",
        "best_val_acc = 0\n",
        "best_epoch = 0\n",
        "\n",
        "history = []\n",
        "accuracy = []\n",
        "for epoch in range(num_epochs):\n",
        "    adjust_learning_rate(optimizer, epoch)\n",
        "    train_loss, train_acc = train()\n",
        "    val_loss, val_acc = validate()\n",
        "    history.append((train_loss, val_loss))\n",
        "    accuracy.append((train_acc, val_acc))\n",
        "\n",
        "    if val_acc > best_val_acc:\n",
        "        print(\"[Info] best validation accuracy!\")\n",
        "        best_val_acc = val_acc\n",
        "        best_epoch = epoch\n",
        "        torch.save(model.state_dict(), f'best_checkpoint_epoch_{epoch + 1}.pth')\n",
        "\n",
        "torch.save(model.state_dict(), f'last_checkpoint_epoch_{num_epochs}.pth')"
      ],
      "metadata": {
        "id": "j8aEm9_C2On6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <b>학습 결과 확인하기</b>\n",
        "\n",
        "* 학습 결과를 시각화하여 정상적으로 모델이 학습되었는지 확인한다."
      ],
      "metadata": {
        "id": "N_lZMAND3G3t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot([x[0] for x in history], 'b', label='train')\n",
        "plt.plot([x[1] for x in history], 'r--',label='validation')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "AYzW4_rZ3HhP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot([x[0] for x in accuracy], 'b', label='train')\n",
        "plt.plot([x[1] for x in accuracy], 'r--',label='validation')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "Ye2qWVN93M6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet50(pretrained=True)\n",
        "num_features = model.fc.in_features\n",
        "model.fc = nn.Linear(num_features, 8) # transfer learning\n",
        "model = model.cuda()\n",
        "model_path = 'best_checkpoint_epoch_7.pth'\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "\n",
        "test_loss, test_accuracy = test()\n",
        "print(f\"Test loss: {test_loss:.8f}\")\n",
        "print(f\"Test accuracy: {test_accuracy * 100.:.2f}%\")"
      ],
      "metadata": {
        "id": "N2lmFhsD3RJd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}