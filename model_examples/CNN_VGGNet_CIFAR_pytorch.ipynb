{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyMnuZGYramLO2valfXvHIgI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahn283/finance/blob/main/CNN_VGGNet_CIFAR_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VGGNet"
      ],
      "metadata": {
        "id": "xnob9Dpmu7NX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 실습 목표\n",
        "-----\n",
        "- VGGNet을 사용하여 이미지를 학습하고 10개의 카테고리를 갖는 이미지를 분류하는 이미지 분류기를 생성한다. (데이터셋: [CIFAR](https://pytorch.org/vision/0.9/datasets.html#cifar))\n",
        "- Pre-training 모델의 사용방법을 이해한다."
      ],
      "metadata": {
        "id": "kkkRkscTCf7Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 문제 정의\n",
        "----\n",
        "- VGGNet 구조 살펴보기\n",
        "\n",
        "\n",
        "\n",
        "![VGG](https://miro.medium.com/max/1100/0*6VP81rFoLWp10FcG)"
      ],
      "metadata": {
        "id": "hXsMYBDcCgbu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 주요 코드\n",
        "----\n"
      ],
      "metadata": {
        "id": "RK6YCJ4uCjAH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 1. VGGNet\n",
        "\n",
        "```\n",
        "# Model\n",
        "cfg = {\n",
        "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
        "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
        "}\n",
        "\n",
        "class VGG(nn.Module):\n",
        "    def __init__(self, vgg_name):\n",
        "        super(VGG, self).__init__()\n",
        "        self.features = self._make_layers(cfg[vgg_name])\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512 * 1 * 1, 360),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(360, 100),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(100, 10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.features(x)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.classifier(out)\n",
        "        return out\n",
        "\n",
        "    # 'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    def _make_layers(self, cfg):\n",
        "        layers = []\n",
        "        in_channels = 3\n",
        "        for x in cfg:\n",
        "            if x == 'M':\n",
        "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "            else:\n",
        "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
        "                           nn.BatchNorm2d(x),\n",
        "                           nn.ReLU(inplace=True)]\n",
        "                in_channels = x\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "YpiBQnzACje8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Pretrained model\n",
        "\n",
        "```\n",
        "from torchvision import models\n",
        "\n",
        "vgg16 = models.vgg16(pretrained=True)\n",
        "vgg16.to(DEVICE)\n",
        "\n",
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(vgg16.classifier.parameters(), lr = LEARNING_RATE, momentum=0.9)\n",
        "```"
      ],
      "metadata": {
        "id": "aPANWHr8CmZ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CIFAR Classifier(VGGNet)\n",
        "----\n",
        "CIFAR 데이터셋을 사용하여 이미지에 포함된 object가 무엇인지 분류하는 이미지 분류기를 생성해봅니다.\n"
      ],
      "metadata": {
        "id": "mC94QxkXCoeR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Step1] Load libraries & Datasets"
      ],
      "metadata": {
        "id": "-2oeZzkICuPx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bLrklQjMuvnz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn\n",
        "\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import transforms\n",
        "from torchvision.transforms.functional import to_pil_image"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Step2] Data preprocessing\n",
        "\n",
        "불러온 이미지의 증강을 통해 학습 정확도를 향상시키도록 합니다.\n",
        "\n",
        "* RandomCrop\n",
        "* RandomHorizontalFlip\n",
        "* Normalize"
      ],
      "metadata": {
        "id": "espChQLPDHGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),   \n",
        "])\n",
        "\n",
        "train_img = datasets.CIFAR10(\n",
        "    root = 'data',\n",
        "    train = True,\n",
        "    download = True,\n",
        "    transform = transform,\n",
        ")\n",
        "\n",
        "test_img = datasets.CIFAR10(\n",
        "    root = 'data',\n",
        "    train = False,\n",
        "    download = True,\n",
        "    transform = transform,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APt9Zx1uDGS7",
        "outputId": "36dc9c69-5137-47ef-d6db-62c1359a747f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:01<00:00, 95090115.08it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/cifar-10-python.tar.gz to data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Step3] Set hyperparameters"
      ],
      "metadata": {
        "id": "PNwe6repMqDM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCH = 10\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 1e-3\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using Device:\", DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSptJYyPMrRV",
        "outputId": "73934816-45b1-4608-9823-044dbefdacac"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Step4] Create DataLoader"
      ],
      "metadata": {
        "id": "fcw2ouzTM-nh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_img, batch_size = BATCH_SIZE, shuffle = True)\n",
        "test_loader = DataLoader(test_img, batch_size = BATCH_SIZE, shuffle = False)"
      ],
      "metadata": {
        "id": "Uxf4LMJzM9QN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Step5] Set Network Structure"
      ],
      "metadata": {
        "id": "MWf7M8sDNNTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model\n",
        "cfg = {\n",
        "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
        "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
        "}\n",
        "\n",
        "class VGG(nn.Module):\n",
        "    def __init__(self, vgg_name):\n",
        "        super(VGG, self).__init__()\n",
        "        self.features = self._make_layers(cfg[vgg_name])\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512 * 1 * 1, 360),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(360, 100),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(100, 10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.features(x)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.classifier(out)\n",
        "        return out\n",
        "\n",
        "    def _make_layers(self, cfg):\n",
        "        layers = []\n",
        "        in_channels = 3\n",
        "        for x in cfg:\n",
        "            if x == 'M':\n",
        "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "            else:\n",
        "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
        "                           nn.BatchNorm2d(x),\n",
        "                           nn.ReLU(inplace=True)]\n",
        "                in_channels = x\n",
        "        return nn.Sequential(*layers)\n"
      ],
      "metadata": {
        "id": "g5uMGyPBNMlW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Step6] Create Model instance"
      ],
      "metadata": {
        "id": "pSY7yyuYPixz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = VGG('VGG16').to(DEVICE)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMch-WpNPPvO",
        "outputId": "e0f197b0-5ecc-4fc8-fa8b-7f349fe45b51"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=360, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=360, out_features=100, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=100, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Step7] Model compile"
      ],
      "metadata": {
        "id": "XwVJb1QcPuDb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = LEARNING_RATE, momentum=0.9)"
      ],
      "metadata": {
        "id": "7n4Co7IrPveN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Step8] Set train loop"
      ],
      "metadata": {
        "id": "Lp3GQzpmP7XN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_loader, model, loss_fn, optimizer):\n",
        "    model.train()\n",
        "    \n",
        "    size = len(train_loader.dataset)\n",
        "    \n",
        "    for batch, (X, y) in enumerate(train_loader):\n",
        "        X, y = X.to(DEVICE), y.to(DEVICE)\n",
        "        pred = model(X)\n",
        "\n",
        "        # 손실 계산\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # 역전파\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f'loss: {loss:>7f}  [{current:>5d}]/{size:5d}')"
      ],
      "metadata": {
        "id": "augny0woP6A_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# 코드로 형식 지정됨\n",
        "```\n",
        "\n",
        "### [Step9] Set test loop"
      ],
      "metadata": {
        "id": "LGbJFSndQjGt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(test_loader, model, loss_fn):\n",
        "    model.eval()\n",
        "\n",
        "    size = len(test_loader.dataset)\n",
        "    num_batches = len(test_loader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in test_loader:\n",
        "            X, y = X.to(DEVICE), y.to(DEVICE)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:8f}\\n\")"
      ],
      "metadata": {
        "id": "vp3_8qxsQhtN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Step10] Run model"
      ],
      "metadata": {
        "id": "DD3hXIYGRPG3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(EPOCH) :\n",
        "    print(f\"Epoch {i+1} \\n------------------------\")\n",
        "    train(train_loader, model, loss, optimizer)\n",
        "    test(test_loader, model, loss)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "id": "oU9YsQuBROhD",
        "outputId": "7a11ff84-2c26-404a-c321-8969b4025c63"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 \n",
            "------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-652c68beacef>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCH\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {i+1} \\n------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-021069f7cbe9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# 손실 계산\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-493bd4926539>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (32x25088 and 512x360)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CIFAR Classifier(Pretrained VGGNet)\n",
        "----\n",
        "ImageNet 데이터로 학습한 VGGNet을 사용하여 주어진 데이터 셋에서 사용할 수 있도록 Fine tuning 해봅니다.\n"
      ],
      "metadata": {
        "id": "ljSdz_f0RgHN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "\n",
        "vgg16 = models.vgg16(pretrained=True)\n",
        "vgg16.to(DEVICE)\n",
        "print(vgg16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ascWKvuFRfJz",
        "outputId": "90a3fb3e-da5f-4811-aea6-4fde99ed1c15"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:01<00:00, 279MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): ReLU(inplace=True)\n",
            "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): ReLU(inplace=True)\n",
            "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16.classifier[6].out_features = 10\n",
        "\n",
        "for param in vgg16.features.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "B3nFTDjHF5f4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(vgg16.classifier.parameters(), lr=LEARNING_RATE, momentum=0.9)"
      ],
      "metadata": {
        "id": "iNq7l0hoGP3A"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(EPOCH):\n",
        "    print(f'Epoch {i+1} \\n---------------------------')\n",
        "    train(train_loader, vgg16, loss, optimizer)\n",
        "    test(test_loader, vgg16, loss)\n",
        "print('Done!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSNcpK6SGEqe",
        "outputId": "2dfd8495-f63f-4d1e-ced6-e52d586cda0a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 \n",
            "---------------------------\n",
            "loss: 13.217981  [    0]/50000\n",
            "loss: 1.312221  [ 3200]/50000\n",
            "loss: 0.935735  [ 6400]/50000\n",
            "loss: 1.102420  [ 9600]/50000\n",
            "loss: 0.945925  [12800]/50000\n",
            "loss: 0.891180  [16000]/50000\n",
            "loss: 0.499880  [19200]/50000\n",
            "loss: 0.832524  [22400]/50000\n",
            "loss: 0.444618  [25600]/50000\n",
            "loss: 0.794000  [28800]/50000\n",
            "loss: 0.355705  [32000]/50000\n",
            "loss: 0.408312  [35200]/50000\n",
            "loss: 0.586389  [38400]/50000\n",
            "loss: 0.782853  [41600]/50000\n",
            "loss: 0.413677  [44800]/50000\n",
            "loss: 0.704019  [48000]/50000\n",
            "Test Error: \n",
            " Accuracy: 82.1%, Avg loss: 0.508351\n",
            "\n",
            "Epoch 2 \n",
            "---------------------------\n",
            "loss: 0.644956  [    0]/50000\n",
            "loss: 0.268401  [ 3200]/50000\n",
            "loss: 0.280275  [ 6400]/50000\n",
            "loss: 0.411861  [ 9600]/50000\n",
            "loss: 0.340337  [12800]/50000\n",
            "loss: 0.557503  [16000]/50000\n",
            "loss: 0.276656  [19200]/50000\n",
            "loss: 0.801786  [22400]/50000\n",
            "loss: 0.648922  [25600]/50000\n",
            "loss: 0.217646  [28800]/50000\n",
            "loss: 0.249855  [32000]/50000\n",
            "loss: 0.539579  [35200]/50000\n",
            "loss: 0.723250  [38400]/50000\n",
            "loss: 0.589285  [41600]/50000\n",
            "loss: 0.618392  [44800]/50000\n",
            "loss: 0.246765  [48000]/50000\n",
            "Test Error: \n",
            " Accuracy: 85.2%, Avg loss: 0.431836\n",
            "\n",
            "Epoch 3 \n",
            "---------------------------\n",
            "loss: 0.215809  [    0]/50000\n",
            "loss: 0.325274  [ 3200]/50000\n",
            "loss: 0.420800  [ 6400]/50000\n",
            "loss: 0.341726  [ 9600]/50000\n",
            "loss: 0.596499  [12800]/50000\n",
            "loss: 0.404911  [16000]/50000\n",
            "loss: 0.418169  [19200]/50000\n",
            "loss: 0.171548  [22400]/50000\n",
            "loss: 0.336102  [25600]/50000\n",
            "loss: 0.345906  [28800]/50000\n",
            "loss: 0.317744  [32000]/50000\n",
            "loss: 0.316808  [35200]/50000\n",
            "loss: 0.239757  [38400]/50000\n",
            "loss: 0.352254  [41600]/50000\n",
            "loss: 0.352104  [44800]/50000\n",
            "loss: 0.209881  [48000]/50000\n",
            "Test Error: \n",
            " Accuracy: 85.7%, Avg loss: 0.416675\n",
            "\n",
            "Epoch 4 \n",
            "---------------------------\n",
            "loss: 0.314179  [    0]/50000\n",
            "loss: 0.254901  [ 3200]/50000\n",
            "loss: 0.331408  [ 6400]/50000\n",
            "loss: 0.262964  [ 9600]/50000\n",
            "loss: 0.235322  [12800]/50000\n",
            "loss: 0.318700  [16000]/50000\n",
            "loss: 0.107426  [19200]/50000\n",
            "loss: 0.338165  [22400]/50000\n",
            "loss: 0.148404  [25600]/50000\n",
            "loss: 0.272750  [28800]/50000\n",
            "loss: 0.180532  [32000]/50000\n",
            "loss: 0.289913  [35200]/50000\n",
            "loss: 0.217056  [38400]/50000\n",
            "loss: 0.502136  [41600]/50000\n",
            "loss: 0.365515  [44800]/50000\n",
            "loss: 0.213348  [48000]/50000\n",
            "Test Error: \n",
            " Accuracy: 86.7%, Avg loss: 0.401831\n",
            "\n",
            "Epoch 5 \n",
            "---------------------------\n",
            "loss: 0.171783  [    0]/50000\n",
            "loss: 0.132974  [ 3200]/50000\n",
            "loss: 0.181542  [ 6400]/50000\n",
            "loss: 0.240336  [ 9600]/50000\n",
            "loss: 0.168614  [12800]/50000\n",
            "loss: 0.224673  [16000]/50000\n",
            "loss: 0.240806  [19200]/50000\n",
            "loss: 0.110810  [22400]/50000\n",
            "loss: 0.183804  [25600]/50000\n",
            "loss: 0.315230  [28800]/50000\n",
            "loss: 0.115349  [32000]/50000\n",
            "loss: 0.196117  [35200]/50000\n",
            "loss: 0.159180  [38400]/50000\n",
            "loss: 0.110931  [41600]/50000\n",
            "loss: 0.257220  [44800]/50000\n",
            "loss: 0.233561  [48000]/50000\n",
            "Test Error: \n",
            " Accuracy: 87.0%, Avg loss: 0.392753\n",
            "\n",
            "Epoch 6 \n",
            "---------------------------\n",
            "loss: 0.134980  [    0]/50000\n",
            "loss: 0.255743  [ 3200]/50000\n",
            "loss: 0.344686  [ 6400]/50000\n",
            "loss: 0.144779  [ 9600]/50000\n",
            "loss: 0.069804  [12800]/50000\n",
            "loss: 0.125986  [16000]/50000\n",
            "loss: 0.116749  [19200]/50000\n",
            "loss: 0.242764  [22400]/50000\n",
            "loss: 0.197131  [25600]/50000\n",
            "loss: 0.039554  [28800]/50000\n",
            "loss: 0.214652  [32000]/50000\n",
            "loss: 0.125351  [35200]/50000\n",
            "loss: 0.142446  [38400]/50000\n",
            "loss: 0.209419  [41600]/50000\n",
            "loss: 0.050764  [44800]/50000\n",
            "loss: 0.086807  [48000]/50000\n",
            "Test Error: \n",
            " Accuracy: 87.0%, Avg loss: 0.399777\n",
            "\n",
            "Epoch 7 \n",
            "---------------------------\n",
            "loss: 0.258193  [    0]/50000\n",
            "loss: 0.196795  [ 3200]/50000\n",
            "loss: 0.062004  [ 6400]/50000\n",
            "loss: 0.059340  [ 9600]/50000\n",
            "loss: 0.097504  [12800]/50000\n",
            "loss: 0.109705  [16000]/50000\n",
            "loss: 0.193711  [19200]/50000\n",
            "loss: 0.081866  [22400]/50000\n",
            "loss: 0.181929  [25600]/50000\n",
            "loss: 0.136273  [28800]/50000\n",
            "loss: 0.110516  [32000]/50000\n",
            "loss: 0.192122  [35200]/50000\n",
            "loss: 0.065707  [38400]/50000\n",
            "loss: 0.047113  [41600]/50000\n",
            "loss: 0.062301  [44800]/50000\n",
            "loss: 0.039911  [48000]/50000\n",
            "Test Error: \n",
            " Accuracy: 87.2%, Avg loss: 0.416982\n",
            "\n",
            "Epoch 8 \n",
            "---------------------------\n",
            "loss: 0.122078  [    0]/50000\n",
            "loss: 0.145368  [ 3200]/50000\n",
            "loss: 0.029500  [ 6400]/50000\n",
            "loss: 0.108490  [ 9600]/50000\n",
            "loss: 0.126461  [12800]/50000\n",
            "loss: 0.140177  [16000]/50000\n",
            "loss: 0.197873  [19200]/50000\n",
            "loss: 0.120764  [22400]/50000\n",
            "loss: 0.110169  [25600]/50000\n",
            "loss: 0.081667  [28800]/50000\n",
            "loss: 0.111393  [32000]/50000\n",
            "loss: 0.141992  [35200]/50000\n",
            "loss: 0.197522  [38400]/50000\n",
            "loss: 0.217157  [41600]/50000\n",
            "loss: 0.031320  [44800]/50000\n",
            "loss: 0.020716  [48000]/50000\n",
            "Test Error: \n",
            " Accuracy: 87.1%, Avg loss: 0.438525\n",
            "\n",
            "Epoch 9 \n",
            "---------------------------\n",
            "loss: 0.096492  [    0]/50000\n",
            "loss: 0.046640  [ 3200]/50000\n",
            "loss: 0.075708  [ 6400]/50000\n",
            "loss: 0.015572  [ 9600]/50000\n",
            "loss: 0.091312  [12800]/50000\n",
            "loss: 0.078543  [16000]/50000\n",
            "loss: 0.168803  [19200]/50000\n",
            "loss: 0.058153  [22400]/50000\n",
            "loss: 0.105724  [25600]/50000\n",
            "loss: 0.059621  [28800]/50000\n",
            "loss: 0.025608  [32000]/50000\n",
            "loss: 0.034662  [35200]/50000\n",
            "loss: 0.138158  [38400]/50000\n",
            "loss: 0.068409  [41600]/50000\n",
            "loss: 0.029482  [44800]/50000\n",
            "loss: 0.151832  [48000]/50000\n",
            "Test Error: \n",
            " Accuracy: 87.4%, Avg loss: 0.445778\n",
            "\n",
            "Epoch 10 \n",
            "---------------------------\n",
            "loss: 0.022080  [    0]/50000\n",
            "loss: 0.155735  [ 3200]/50000\n",
            "loss: 0.019660  [ 6400]/50000\n",
            "loss: 0.102726  [ 9600]/50000\n",
            "loss: 0.013497  [12800]/50000\n",
            "loss: 0.034754  [16000]/50000\n",
            "loss: 0.026755  [19200]/50000\n",
            "loss: 0.042013  [22400]/50000\n",
            "loss: 0.030073  [25600]/50000\n",
            "loss: 0.086868  [28800]/50000\n",
            "loss: 0.009967  [32000]/50000\n",
            "loss: 0.024719  [35200]/50000\n",
            "loss: 0.060633  [38400]/50000\n",
            "loss: 0.132884  [41600]/50000\n",
            "loss: 0.064242  [44800]/50000\n",
            "loss: 0.032025  [48000]/50000\n",
            "Test Error: \n",
            " Accuracy: 87.5%, Avg loss: 0.460401\n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    }
  ]
}
